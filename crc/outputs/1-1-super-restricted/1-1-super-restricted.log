/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/envs/registration.py:555: UserWarning: [33mWARN: The environment SuperMarioBros-1-1-v0 is out of date. You should consider upgrading to version `v3`.[0m
  logger.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/envs/registration.py:555: UserWarning: [33mWARN: The environment SuperMarioBros-1-1-v0 is out of date. You should consider upgrading to version `v3`.[0m
  logger.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/envs/registration.py:555: UserWarning: [33mWARN: The environment SuperMarioBros-1-1-v0 is out of date. You should consider upgrading to version `v3`.[0m
  logger.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/envs/registration.py:555: UserWarning: [33mWARN: The environment SuperMarioBros-1-1-v0 is out of date. You should consider upgrading to version `v3`.[0m
  logger.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/envs/registration.py:555: UserWarning: [33mWARN: The environment SuperMarioBros-1-1-v0 is out of date. You should consider upgrading to version `v3`.[0m
  logger.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/envs/registration.py:555: UserWarning: [33mWARN: The environment SuperMarioBros-1-1-v0 is out of date. You should consider upgrading to version `v3`.[0m
  logger.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/envs/registration.py:555: UserWarning: [33mWARN: The environment SuperMarioBros-1-1-v0 is out of date. You should consider upgrading to version `v3`.[0m
  logger.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/envs/registration.py:555: UserWarning: [33mWARN: The environment SuperMarioBros-1-1-v0 is out of date. You should consider upgrading to version `v3`.[0m
  logger.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/envs/registration.py:555: UserWarning: [33mWARN: The environment SuperMarioBros-1-1-v0 is out of date. You should consider upgrading to version `v3`.[0m
  logger.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/envs/registration.py:555: UserWarning: [33mWARN: The environment SuperMarioBros-1-1-v0 is out of date. You should consider upgrading to version `v3`.[0m
  logger.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/envs/registration.py:555: UserWarning: [33mWARN: The environment SuperMarioBros-1-1-v0 is out of date. You should consider upgrading to version `v3`.[0m
  logger.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/envs/registration.py:555: UserWarning: [33mWARN: The environment SuperMarioBros-1-1-v0 is out of date. You should consider upgrading to version `v3`.[0m
  logger.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/envs/registration.py:555: UserWarning: [33mWARN: The environment SuperMarioBros-1-1-v0 is out of date. You should consider upgrading to version `v3`.[0m
  logger.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/envs/registration.py:555: UserWarning: [33mWARN: The environment SuperMarioBros-1-1-v0 is out of date. You should consider upgrading to version `v3`.[0m
  logger.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/envs/registration.py:555: UserWarning: [33mWARN: The environment SuperMarioBros-1-1-v0 is out of date. You should consider upgrading to version `v3`.[0m
  logger.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/envs/registration.py:555: UserWarning: [33mWARN: The environment SuperMarioBros-1-1-v0 is out of date. You should consider upgrading to version `v3`.[0m
  logger.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/envs/registration.py:555: UserWarning: [33mWARN: The environment SuperMarioBros-1-1-v0 is out of date. You should consider upgrading to version `v3`.[0m
  logger.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/envs/registration.py:555: UserWarning: [33mWARN: The environment SuperMarioBros-1-1-v0 is out of date. You should consider upgrading to version `v3`.[0m
  logger.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/envs/registration.py:555: UserWarning: [33mWARN: The environment SuperMarioBros-1-1-v0 is out of date. You should consider upgrading to version `v3`.[0m
  logger.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/envs/registration.py:555: UserWarning: [33mWARN: The environment SuperMarioBros-1-1-v0 is out of date. You should consider upgrading to version `v3`.[0m
  logger.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/envs/registration.py:555: UserWarning: [33mWARN: The environment SuperMarioBros-1-1-v0 is out of date. You should consider upgrading to version `v3`.[0m
  logger.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/envs/registration.py:555: UserWarning: [33mWARN: The environment SuperMarioBros-1-1-v0 is out of date. You should consider upgrading to version `v3`.[0m
  logger.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/envs/registration.py:555: UserWarning: [33mWARN: The environment SuperMarioBros-1-1-v0 is out of date. You should consider upgrading to version `v3`.[0m
  logger.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/envs/registration.py:555: UserWarning: [33mWARN: The environment SuperMarioBros-1-1-v0 is out of date. You should consider upgrading to version `v3`.[0m
  logger.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.
  warnings.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.
  warnings.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.
  warnings.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.
  warnings.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.
  warnings.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.
  warnings.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.
  warnings.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.
  warnings.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.
  warnings.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.
  warnings.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.
  warnings.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.
  warnings.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.
  warnings.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.
  warnings.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.
  warnings.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.
  warnings.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.
  warnings.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.
  warnings.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.
  warnings.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.
  warnings.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.
  warnings.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.
  warnings.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.
  warnings.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.
  warnings.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/stable_baselines3/common/callbacks.py:403: UserWarning: Training and eval env are not of the same type<stable_baselines3.common.vec_env.vec_transpose.VecTransposeImage object at 0x14d59e48b2b0> != <stable_baselines3.common.vec_env.vec_monitor.VecMonitor object at 0x14d59e489ab0>
  warnings.warn("Training and eval env are not of the same type" f"{self.training_env} != {self.eval_env}")
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(terminated, (bool, np.bool8)):
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(terminated, (bool, np.bool8)):
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(terminated, (bool, np.bool8)):
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(terminated, (bool, np.bool8)):
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(terminated, (bool, np.bool8)):
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(terminated, (bool, np.bool8)):
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(terminated, (bool, np.bool8)):
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(terminated, (bool, np.bool8)):
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(terminated, (bool, np.bool8)):
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(terminated, (bool, np.bool8)):
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(terminated, (bool, np.bool8)):
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(terminated, (bool, np.bool8)):
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(terminated, (bool, np.bool8)):
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(terminated, (bool, np.bool8)):
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(terminated, (bool, np.bool8)):
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(terminated, (bool, np.bool8)):
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(terminated, (bool, np.bool8)):
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(terminated, (bool, np.bool8)):
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(terminated, (bool, np.bool8)):
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(terminated, (bool, np.bool8)):
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(terminated, (bool, np.bool8)):
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(terminated, (bool, np.bool8)):
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(terminated, (bool, np.bool8)):
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(terminated, (bool, np.bool8)):
Training model!
World: 1
Stage: 1
Vectors: 24
Steps: 10000000
Learning rate: 0.0003
Eval num_timesteps=24000, episode_reward=252.00 +/- 0.00
Episode length: 27.00 +/- 0.00
New best mean reward!
Eval num_timesteps=48000, episode_reward=252.00 +/- 0.00
Episode length: 27.00 +/- 0.00
Eval num_timesteps=72000, episode_reward=252.00 +/- 0.00
Episode length: 27.00 +/- 0.00
Eval num_timesteps=96000, episode_reward=252.00 +/- 0.00
Episode length: 27.00 +/- 0.00
Eval num_timesteps=120000, episode_reward=194.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=144000, episode_reward=194.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=168000, episode_reward=252.00 +/- 0.00
Episode length: 27.00 +/- 0.00
Eval num_timesteps=192000, episode_reward=252.00 +/- 0.00
Episode length: 27.00 +/- 0.00
Eval num_timesteps=216000, episode_reward=354.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
New best mean reward!
Eval num_timesteps=240000, episode_reward=354.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=264000, episode_reward=482.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
New best mean reward!
Eval num_timesteps=288000, episode_reward=482.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=312000, episode_reward=602.00 +/- 0.00
Episode length: 68.00 +/- 0.00
New best mean reward!
Eval num_timesteps=336000, episode_reward=602.00 +/- 0.00
Episode length: 68.00 +/- 0.00
Eval num_timesteps=360000, episode_reward=194.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=384000, episode_reward=194.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=408000, episode_reward=194.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=432000, episode_reward=194.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=456000, episode_reward=194.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=480000, episode_reward=194.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=504000, episode_reward=194.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=528000, episode_reward=194.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=552000, episode_reward=194.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=576000, episode_reward=194.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=600000, episode_reward=194.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=624000, episode_reward=194.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=648000, episode_reward=250.00 +/- 0.00
Episode length: 30.00 +/- 0.00
Eval num_timesteps=672000, episode_reward=250.00 +/- 0.00
Episode length: 30.00 +/- 0.00
Eval num_timesteps=696000, episode_reward=250.00 +/- 0.00
Episode length: 30.00 +/- 0.00
Eval num_timesteps=720000, episode_reward=250.00 +/- 0.00
Episode length: 30.00 +/- 0.00
Eval num_timesteps=744000, episode_reward=250.00 +/- 0.00
Episode length: 30.00 +/- 0.00
Eval num_timesteps=768000, episode_reward=250.00 +/- 0.00
Episode length: 30.00 +/- 0.00
Eval num_timesteps=792000, episode_reward=250.00 +/- 0.00
Episode length: 30.00 +/- 0.00
Eval num_timesteps=816000, episode_reward=250.00 +/- 0.00
Episode length: 30.00 +/- 0.00
Eval num_timesteps=840000, episode_reward=250.00 +/- 0.00
Episode length: 30.00 +/- 0.00
Eval num_timesteps=864000, episode_reward=250.00 +/- 0.00
Episode length: 30.00 +/- 0.00
Eval num_timesteps=888000, episode_reward=250.00 +/- 0.00
Episode length: 30.00 +/- 0.00
Eval num_timesteps=912000, episode_reward=250.00 +/- 0.00
Episode length: 30.00 +/- 0.00
Eval num_timesteps=936000, episode_reward=250.00 +/- 0.00
Episode length: 30.00 +/- 0.00
Eval num_timesteps=960000, episode_reward=250.00 +/- 0.00
Episode length: 30.00 +/- 0.00
Eval num_timesteps=984000, episode_reward=194.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=1008000, episode_reward=194.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=1032000, episode_reward=194.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=1056000, episode_reward=354.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=1080000, episode_reward=354.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=1104000, episode_reward=250.00 +/- 0.00
Episode length: 30.00 +/- 0.00
Eval num_timesteps=1128000, episode_reward=250.00 +/- 0.00
Episode length: 30.00 +/- 0.00
Eval num_timesteps=1152000, episode_reward=250.00 +/- 0.00
Episode length: 30.00 +/- 0.00
Eval num_timesteps=1176000, episode_reward=250.00 +/- 0.00
Episode length: 30.00 +/- 0.00
Eval num_timesteps=1200000, episode_reward=250.00 +/- 0.00
Episode length: 30.00 +/- 0.00
Eval num_timesteps=1224000, episode_reward=250.00 +/- 0.00
Episode length: 30.00 +/- 0.00
Eval num_timesteps=1248000, episode_reward=252.00 +/- 0.00
Episode length: 31.00 +/- 0.00
Eval num_timesteps=1272000, episode_reward=252.00 +/- 0.00
Episode length: 31.00 +/- 0.00
Eval num_timesteps=1296000, episode_reward=252.00 +/- 0.00
Episode length: 31.00 +/- 0.00
Eval num_timesteps=1320000, episode_reward=252.00 +/- 0.00
Episode length: 31.00 +/- 0.00
Eval num_timesteps=1344000, episode_reward=252.00 +/- 0.00
Episode length: 27.00 +/- 0.00
Eval num_timesteps=1368000, episode_reward=252.00 +/- 0.00
Episode length: 27.00 +/- 0.00
Eval num_timesteps=1392000, episode_reward=252.00 +/- 0.00
Episode length: 27.00 +/- 0.00
Eval num_timesteps=1416000, episode_reward=252.00 +/- 0.00
Episode length: 27.00 +/- 0.00
Eval num_timesteps=1440000, episode_reward=252.00 +/- 0.00
Episode length: 27.00 +/- 0.00
Eval num_timesteps=1464000, episode_reward=252.00 +/- 0.00
Episode length: 27.00 +/- 0.00
Eval num_timesteps=1488000, episode_reward=252.00 +/- 0.00
Episode length: 27.00 +/- 0.00
Eval num_timesteps=1512000, episode_reward=252.00 +/- 0.00
Episode length: 27.00 +/- 0.00
Eval num_timesteps=1536000, episode_reward=252.00 +/- 0.00
Episode length: 27.00 +/- 0.00
Eval num_timesteps=1560000, episode_reward=252.00 +/- 0.00
Episode length: 27.00 +/- 0.00
Eval num_timesteps=1584000, episode_reward=252.00 +/- 0.00
Episode length: 27.00 +/- 0.00
Eval num_timesteps=1608000, episode_reward=252.00 +/- 0.00
Episode length: 27.00 +/- 0.00
Eval num_timesteps=1632000, episode_reward=252.00 +/- 0.00
Episode length: 27.00 +/- 0.00
Eval num_timesteps=1656000, episode_reward=252.00 +/- 0.00
Episode length: 27.00 +/- 0.00
Eval num_timesteps=1680000, episode_reward=252.00 +/- 0.00
Episode length: 27.00 +/- 0.00
Eval num_timesteps=1704000, episode_reward=252.00 +/- 0.00
Episode length: 27.00 +/- 0.00
Eval num_timesteps=1728000, episode_reward=252.00 +/- 0.00
Episode length: 27.00 +/- 0.00
Eval num_timesteps=1752000, episode_reward=252.00 +/- 0.00
Episode length: 27.00 +/- 0.00
Eval num_timesteps=1776000, episode_reward=252.00 +/- 0.00
Episode length: 27.00 +/- 0.00
Eval num_timesteps=1800000, episode_reward=252.00 +/- 0.00
Episode length: 27.00 +/- 0.00
Eval num_timesteps=1824000, episode_reward=252.00 +/- 0.00
Episode length: 27.00 +/- 0.00
Eval num_timesteps=1848000, episode_reward=252.00 +/- 0.00
Episode length: 27.00 +/- 0.00
Eval num_timesteps=1872000, episode_reward=252.00 +/- 0.00
Episode length: 27.00 +/- 0.00
Eval num_timesteps=1896000, episode_reward=252.00 +/- 0.00
Episode length: 27.00 +/- 0.00
Eval num_timesteps=1920000, episode_reward=252.00 +/- 0.00
Episode length: 27.00 +/- 0.00
Eval num_timesteps=1944000, episode_reward=252.00 +/- 0.00
Episode length: 27.00 +/- 0.00
Eval num_timesteps=1968000, episode_reward=252.00 +/- 0.00
Episode length: 27.00 +/- 0.00
Eval num_timesteps=1992000, episode_reward=252.00 +/- 0.00
Episode length: 27.00 +/- 0.00
Eval num_timesteps=2016000, episode_reward=252.00 +/- 0.00
Episode length: 27.00 +/- 0.00
Eval num_timesteps=2040000, episode_reward=252.00 +/- 0.00
Episode length: 27.00 +/- 0.00
Eval num_timesteps=2064000, episode_reward=252.00 +/- 0.00
Episode length: 27.00 +/- 0.00
Eval num_timesteps=2088000, episode_reward=252.00 +/- 0.00
Episode length: 27.00 +/- 0.00
Eval num_timesteps=2112000, episode_reward=252.00 +/- 0.00
Episode length: 27.00 +/- 0.00
Eval num_timesteps=2136000, episode_reward=252.00 +/- 0.00
Episode length: 27.00 +/- 0.00
Eval num_timesteps=2160000, episode_reward=252.00 +/- 0.00
Episode length: 27.00 +/- 0.00
Eval num_timesteps=2184000, episode_reward=252.00 +/- 0.00
Episode length: 27.00 +/- 0.00
Eval num_timesteps=2208000, episode_reward=252.00 +/- 0.00
Episode length: 27.00 +/- 0.00
Eval num_timesteps=2232000, episode_reward=252.00 +/- 0.00
Episode length: 27.00 +/- 0.00
Eval num_timesteps=2256000, episode_reward=252.00 +/- 0.00
Episode length: 27.00 +/- 0.00
Eval num_timesteps=2280000, episode_reward=252.00 +/- 0.00
Episode length: 27.00 +/- 0.00
Eval num_timesteps=2304000, episode_reward=252.00 +/- 0.00
Episode length: 27.00 +/- 0.00
Eval num_timesteps=2328000, episode_reward=252.00 +/- 0.00
Episode length: 27.00 +/- 0.00
Eval num_timesteps=2352000, episode_reward=252.00 +/- 0.00
Episode length: 27.00 +/- 0.00
Eval num_timesteps=2376000, episode_reward=252.00 +/- 0.00
Episode length: 27.00 +/- 0.00
Eval num_timesteps=2400000, episode_reward=252.00 +/- 0.00
Episode length: 27.00 +/- 0.00
Eval num_timesteps=2424000, episode_reward=252.00 +/- 0.00
Episode length: 27.00 +/- 0.00
Eval num_timesteps=2448000, episode_reward=252.00 +/- 0.00
Episode length: 27.00 +/- 0.00
Eval num_timesteps=2472000, episode_reward=252.00 +/- 0.00
Episode length: 27.00 +/- 0.00
Eval num_timesteps=2496000, episode_reward=252.00 +/- 0.00
Episode length: 27.00 +/- 0.00
Eval num_timesteps=2520000, episode_reward=252.00 +/- 0.00
Episode length: 27.00 +/- 0.00
Eval num_timesteps=2544000, episode_reward=252.00 +/- 0.00
Episode length: 27.00 +/- 0.00
Eval num_timesteps=2568000, episode_reward=252.00 +/- 0.00
Episode length: 27.00 +/- 0.00
Eval num_timesteps=2592000, episode_reward=252.00 +/- 0.00
Episode length: 27.00 +/- 0.00
Eval num_timesteps=2616000, episode_reward=252.00 +/- 0.00
Episode length: 27.00 +/- 0.00
Eval num_timesteps=2640000, episode_reward=252.00 +/- 0.00
Episode length: 27.00 +/- 0.00
Eval num_timesteps=2664000, episode_reward=252.00 +/- 0.00
Episode length: 27.00 +/- 0.00
Eval num_timesteps=2688000, episode_reward=252.00 +/- 0.00
Episode length: 27.00 +/- 0.00
Eval num_timesteps=2712000, episode_reward=252.00 +/- 0.00
Episode length: 27.00 +/- 0.00
Eval num_timesteps=2736000, episode_reward=252.00 +/- 0.00
Episode length: 27.00 +/- 0.00
Eval num_timesteps=2760000, episode_reward=252.00 +/- 0.00
Episode length: 27.00 +/- 0.00
Eval num_timesteps=2784000, episode_reward=252.00 +/- 0.00
Episode length: 27.00 +/- 0.00
Eval num_timesteps=2808000, episode_reward=252.00 +/- 0.00
Episode length: 27.00 +/- 0.00
Eval num_timesteps=2832000, episode_reward=252.00 +/- 0.00
Episode length: 27.00 +/- 0.00
Eval num_timesteps=2856000, episode_reward=252.00 +/- 0.00
Episode length: 27.00 +/- 0.00
Eval num_timesteps=2880000, episode_reward=252.00 +/- 0.00
Episode length: 27.00 +/- 0.00
Eval num_timesteps=2904000, episode_reward=252.00 +/- 0.00
Episode length: 27.00 +/- 0.00
Eval num_timesteps=2928000, episode_reward=252.00 +/- 0.00
Episode length: 27.00 +/- 0.00
Eval num_timesteps=2952000, episode_reward=252.00 +/- 0.00
Episode length: 27.00 +/- 0.00
Eval num_timesteps=2976000, episode_reward=252.00 +/- 0.00
Episode length: 27.00 +/- 0.00
Eval num_timesteps=3000000, episode_reward=252.00 +/- 0.00
Episode length: 27.00 +/- 0.00
Eval num_timesteps=3024000, episode_reward=252.00 +/- 0.00
Episode length: 27.00 +/- 0.00
Eval num_timesteps=3048000, episode_reward=252.00 +/- 0.00
Episode length: 27.00 +/- 0.00
Eval num_timesteps=3072000, episode_reward=252.00 +/- 0.00
Episode length: 27.00 +/- 0.00
Eval num_timesteps=3096000, episode_reward=252.00 +/- 0.00
Episode length: 27.00 +/- 0.00
Eval num_timesteps=3120000, episode_reward=252.00 +/- 0.00
Episode length: 27.00 +/- 0.00
Eval num_timesteps=3144000, episode_reward=252.00 +/- 0.00
Episode length: 27.00 +/- 0.00
Eval num_timesteps=3168000, episode_reward=252.00 +/- 0.00
Episode length: 27.00 +/- 0.00
Eval num_timesteps=3192000, episode_reward=252.00 +/- 0.00
Episode length: 27.00 +/- 0.00
Eval num_timesteps=3216000, episode_reward=354.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=3240000, episode_reward=354.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=3264000, episode_reward=252.00 +/- 0.00
Episode length: 27.00 +/- 0.00
Eval num_timesteps=3288000, episode_reward=252.00 +/- 0.00
Episode length: 27.00 +/- 0.00
Eval num_timesteps=3312000, episode_reward=252.00 +/- 0.00
Episode length: 27.00 +/- 0.00
Eval num_timesteps=3336000, episode_reward=252.00 +/- 0.00
Episode length: 27.00 +/- 0.00
Eval num_timesteps=3360000, episode_reward=252.00 +/- 0.00
Episode length: 27.00 +/- 0.00
Eval num_timesteps=3384000, episode_reward=252.00 +/- 0.00
Episode length: 27.00 +/- 0.00
Eval num_timesteps=3408000, episode_reward=252.00 +/- 0.00
Episode length: 27.00 +/- 0.00
Eval num_timesteps=3432000, episode_reward=252.00 +/- 0.00
Episode length: 27.00 +/- 0.00
Eval num_timesteps=3456000, episode_reward=1044.00 +/- 0.00
Episode length: 138.00 +/- 0.00
New best mean reward!
Eval num_timesteps=3480000, episode_reward=1044.00 +/- 0.00
Episode length: 138.00 +/- 0.00
Eval num_timesteps=3504000, episode_reward=658.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=3528000, episode_reward=658.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=3552000, episode_reward=628.00 +/- 0.00
Episode length: 86.00 +/- 0.00
Eval num_timesteps=3576000, episode_reward=628.00 +/- 0.00
Episode length: 86.00 +/- 0.00
Eval num_timesteps=3600000, episode_reward=354.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=3624000, episode_reward=354.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=3648000, episode_reward=446.00 +/- 0.00
Episode length: 979.00 +/- 0.00
Eval num_timesteps=3672000, episode_reward=446.00 +/- 0.00
Episode length: 979.00 +/- 0.00
Eval num_timesteps=3696000, episode_reward=252.00 +/- 0.00
Episode length: 27.00 +/- 0.00
Eval num_timesteps=3720000, episode_reward=252.00 +/- 0.00
Episode length: 27.00 +/- 0.00
Eval num_timesteps=3744000, episode_reward=551.00 +/- 0.00
Episode length: 584.00 +/- 0.00
Eval num_timesteps=3768000, episode_reward=551.00 +/- 0.00
Episode length: 584.00 +/- 0.00
Eval num_timesteps=3792000, episode_reward=354.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=3816000, episode_reward=354.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=3840000, episode_reward=619.00 +/- 0.00
Episode length: 669.00 +/- 0.00
Eval num_timesteps=3864000, episode_reward=619.00 +/- 0.00
Episode length: 669.00 +/- 0.00
Eval num_timesteps=3888000, episode_reward=939.00 +/- 0.00
Episode length: 680.00 +/- 0.00
Eval num_timesteps=3912000, episode_reward=939.00 +/- 0.00
Episode length: 680.00 +/- 0.00
Eval num_timesteps=3936000, episode_reward=354.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=3960000, episode_reward=354.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=3984000, episode_reward=520.00 +/- 0.00
Episode length: 595.00 +/- 0.00
Eval num_timesteps=4008000, episode_reward=520.00 +/- 0.00
Episode length: 595.00 +/- 0.00
Eval num_timesteps=4032000, episode_reward=492.00 +/- 0.00
Episode length: 723.00 +/- 0.00
Eval num_timesteps=4056000, episode_reward=492.00 +/- 0.00
Episode length: 723.00 +/- 0.00
Eval num_timesteps=4080000, episode_reward=1021.00 +/- 0.00
Episode length: 254.00 +/- 0.00
Eval num_timesteps=4104000, episode_reward=1021.00 +/- 0.00
Episode length: 254.00 +/- 0.00
Eval num_timesteps=4128000, episode_reward=1021.00 +/- 0.00
Episode length: 254.00 +/- 0.00
Eval num_timesteps=4152000, episode_reward=582.00 +/- 0.00
Episode length: 212.00 +/- 0.00
Eval num_timesteps=4176000, episode_reward=582.00 +/- 0.00
Episode length: 212.00 +/- 0.00
Eval num_timesteps=4200000, episode_reward=252.00 +/- 0.00
Episode length: 27.00 +/- 0.00
Eval num_timesteps=4224000, episode_reward=252.00 +/- 0.00
Episode length: 27.00 +/- 0.00
Eval num_timesteps=4248000, episode_reward=252.00 +/- 0.00
Episode length: 27.00 +/- 0.00
Eval num_timesteps=4272000, episode_reward=252.00 +/- 0.00
Episode length: 27.00 +/- 0.00
Eval num_timesteps=4296000, episode_reward=252.00 +/- 0.00
Episode length: 27.00 +/- 0.00
Eval num_timesteps=4320000, episode_reward=252.00 +/- 0.00
Episode length: 27.00 +/- 0.00
Eval num_timesteps=4344000, episode_reward=252.00 +/- 0.00
Episode length: 27.00 +/- 0.00
Eval num_timesteps=4368000, episode_reward=252.00 +/- 0.00
Episode length: 27.00 +/- 0.00
Eval num_timesteps=4392000, episode_reward=252.00 +/- 0.00
Episode length: 27.00 +/- 0.00
Eval num_timesteps=4416000, episode_reward=252.00 +/- 0.00
Episode length: 27.00 +/- 0.00
Eval num_timesteps=4440000, episode_reward=252.00 +/- 0.00
Episode length: 27.00 +/- 0.00
Eval num_timesteps=4464000, episode_reward=252.00 +/- 0.00
Episode length: 27.00 +/- 0.00
Eval num_timesteps=4488000, episode_reward=252.00 +/- 0.00
Episode length: 27.00 +/- 0.00
Eval num_timesteps=4512000, episode_reward=252.00 +/- 0.00
Episode length: 27.00 +/- 0.00
Eval num_timesteps=4536000, episode_reward=252.00 +/- 0.00
Episode length: 27.00 +/- 0.00
Eval num_timesteps=4560000, episode_reward=252.00 +/- 0.00
Episode length: 27.00 +/- 0.00
Eval num_timesteps=4584000, episode_reward=252.00 +/- 0.00
Episode length: 27.00 +/- 0.00
Eval num_timesteps=4608000, episode_reward=252.00 +/- 0.00
Episode length: 27.00 +/- 0.00
Eval num_timesteps=4632000, episode_reward=194.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=4656000, episode_reward=194.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=4680000, episode_reward=194.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=4704000, episode_reward=194.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=4728000, episode_reward=354.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=4752000, episode_reward=354.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=4776000, episode_reward=354.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=4800000, episode_reward=354.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=4824000, episode_reward=194.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=4848000, episode_reward=194.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=4872000, episode_reward=252.00 +/- 0.00
Episode length: 27.00 +/- 0.00
Eval num_timesteps=4896000, episode_reward=252.00 +/- 0.00
Episode length: 27.00 +/- 0.00
Eval num_timesteps=4920000, episode_reward=194.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=4944000, episode_reward=194.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=4968000, episode_reward=194.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=4992000, episode_reward=194.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=5016000, episode_reward=354.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=5040000, episode_reward=354.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=5064000, episode_reward=354.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=5088000, episode_reward=354.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=5112000, episode_reward=354.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=5136000, episode_reward=354.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=5160000, episode_reward=354.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=5184000, episode_reward=354.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=5208000, episode_reward=354.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=5232000, episode_reward=354.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=5256000, episode_reward=354.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=5280000, episode_reward=354.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=5304000, episode_reward=354.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=5328000, episode_reward=194.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=5352000, episode_reward=194.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=5376000, episode_reward=354.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=5400000, episode_reward=354.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=5424000, episode_reward=461.00 +/- 0.00
Episode length: 905.00 +/- 0.00
Eval num_timesteps=5448000, episode_reward=461.00 +/- 0.00
Episode length: 905.00 +/- 0.00
Eval num_timesteps=5472000, episode_reward=354.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=5496000, episode_reward=354.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=5520000, episode_reward=713.00 +/- 0.00
Episode length: 652.00 +/- 0.00
Eval num_timesteps=5544000, episode_reward=713.00 +/- 0.00
Episode length: 652.00 +/- 0.00
Eval num_timesteps=5568000, episode_reward=194.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=5592000, episode_reward=194.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=5616000, episode_reward=653.00 +/- 0.00
Episode length: 72.00 +/- 0.00
Eval num_timesteps=5640000, episode_reward=653.00 +/- 0.00
Episode length: 72.00 +/- 0.00
Eval num_timesteps=5664000, episode_reward=745.00 +/- 0.00
Episode length: 116.00 +/- 0.00
Eval num_timesteps=5688000, episode_reward=745.00 +/- 0.00
Episode length: 116.00 +/- 0.00
Eval num_timesteps=5712000, episode_reward=1344.00 +/- 0.00
Episode length: 167.00 +/- 0.00
New best mean reward!
Eval num_timesteps=5736000, episode_reward=1344.00 +/- 0.00
Episode length: 167.00 +/- 0.00
Eval num_timesteps=5760000, episode_reward=1345.00 +/- 0.00
Episode length: 153.00 +/- 0.00
New best mean reward!
Eval num_timesteps=5784000, episode_reward=1345.00 +/- 0.00
Episode length: 153.00 +/- 0.00
Eval num_timesteps=5808000, episode_reward=1345.00 +/- 0.00
Episode length: 153.00 +/- 0.00
Eval num_timesteps=5832000, episode_reward=1345.00 +/- 0.00
Episode length: 153.00 +/- 0.00
Eval num_timesteps=5856000, episode_reward=1345.00 +/- 0.00
Episode length: 153.00 +/- 0.00
Eval num_timesteps=5880000, episode_reward=1345.00 +/- 0.00
Episode length: 153.00 +/- 0.00
Eval num_timesteps=5904000, episode_reward=1345.00 +/- 0.00
Episode length: 153.00 +/- 0.00
Eval num_timesteps=5928000, episode_reward=1345.00 +/- 0.00
Episode length: 153.00 +/- 0.00
Eval num_timesteps=5952000, episode_reward=1345.00 +/- 0.00
Episode length: 153.00 +/- 0.00
Eval num_timesteps=5976000, episode_reward=1345.00 +/- 0.00
Episode length: 153.00 +/- 0.00
Eval num_timesteps=6000000, episode_reward=1345.00 +/- 0.00
Episode length: 153.00 +/- 0.00
Eval num_timesteps=6024000, episode_reward=1345.00 +/- 0.00
Episode length: 153.00 +/- 0.00
Eval num_timesteps=6048000, episode_reward=1425.00 +/- 0.00
Episode length: 238.00 +/- 0.00
New best mean reward!
Eval num_timesteps=6072000, episode_reward=1425.00 +/- 0.00
Episode length: 238.00 +/- 0.00
Eval num_timesteps=6096000, episode_reward=1584.00 +/- 0.00
Episode length: 173.00 +/- 0.00
New best mean reward!
Eval num_timesteps=6120000, episode_reward=1584.00 +/- 0.00
Episode length: 173.00 +/- 0.00
Eval num_timesteps=6144000, episode_reward=1584.00 +/- 0.00
Episode length: 173.00 +/- 0.00
Eval num_timesteps=6168000, episode_reward=1436.00 +/- 0.00
Episode length: 161.00 +/- 0.00
Eval num_timesteps=6192000, episode_reward=1436.00 +/- 0.00
Episode length: 161.00 +/- 0.00
Eval num_timesteps=6216000, episode_reward=1689.00 +/- 0.00
Episode length: 188.00 +/- 0.00
New best mean reward!
Eval num_timesteps=6240000, episode_reward=1689.00 +/- 0.00
Episode length: 188.00 +/- 0.00
Eval num_timesteps=6264000, episode_reward=194.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=6288000, episode_reward=194.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=6312000, episode_reward=250.00 +/- 0.00
Episode length: 30.00 +/- 0.00
Eval num_timesteps=6336000, episode_reward=250.00 +/- 0.00
Episode length: 30.00 +/- 0.00
Eval num_timesteps=6360000, episode_reward=251.00 +/- 0.00
Episode length: 30.00 +/- 0.00
Eval num_timesteps=6384000, episode_reward=251.00 +/- 0.00
Episode length: 30.00 +/- 0.00
Eval num_timesteps=6408000, episode_reward=252.00 +/- 0.00
Episode length: 27.00 +/- 0.00
Eval num_timesteps=6432000, episode_reward=252.00 +/- 0.00
Episode length: 27.00 +/- 0.00
Eval num_timesteps=6456000, episode_reward=354.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=6480000, episode_reward=354.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=6504000, episode_reward=1288.00 +/- 0.00
Episode length: 891.00 +/- 0.00
Eval num_timesteps=6528000, episode_reward=1288.00 +/- 0.00
Episode length: 891.00 +/- 0.00
Eval num_timesteps=6552000, episode_reward=498.00 +/- 0.00
Episode length: 846.00 +/- 0.00
Eval num_timesteps=6576000, episode_reward=498.00 +/- 0.00
Episode length: 846.00 +/- 0.00
Eval num_timesteps=6600000, episode_reward=550.00 +/- 0.00
Episode length: 588.00 +/- 0.00
Eval num_timesteps=6624000, episode_reward=550.00 +/- 0.00
Episode length: 588.00 +/- 0.00
Eval num_timesteps=6648000, episode_reward=700.00 +/- 0.00
Episode length: 405.00 +/- 0.00
Eval num_timesteps=6672000, episode_reward=700.00 +/- 0.00
Episode length: 405.00 +/- 0.00
Eval num_timesteps=6696000, episode_reward=605.00 +/- 0.00
Episode length: 85.00 +/- 0.00
Eval num_timesteps=6720000, episode_reward=605.00 +/- 0.00
Episode length: 85.00 +/- 0.00
Eval num_timesteps=6744000, episode_reward=605.00 +/- 0.00
Episode length: 85.00 +/- 0.00
Eval num_timesteps=6768000, episode_reward=605.00 +/- 0.00
Episode length: 85.00 +/- 0.00
Eval num_timesteps=6792000, episode_reward=1431.00 +/- 0.00
Episode length: 186.00 +/- 0.00
Eval num_timesteps=6816000, episode_reward=1431.00 +/- 0.00
Episode length: 186.00 +/- 0.00
Eval num_timesteps=6840000, episode_reward=252.00 +/- 0.00
Episode length: 27.00 +/- 0.00
Eval num_timesteps=6864000, episode_reward=252.00 +/- 0.00
Episode length: 27.00 +/- 0.00
Eval num_timesteps=6888000, episode_reward=977.00 +/- 0.00
Episode length: 487.00 +/- 0.00
Eval num_timesteps=6912000, episode_reward=977.00 +/- 0.00
Episode length: 487.00 +/- 0.00
Eval num_timesteps=6936000, episode_reward=544.00 +/- 0.00
Episode length: 450.00 +/- 0.00
Eval num_timesteps=6960000, episode_reward=544.00 +/- 0.00
Episode length: 450.00 +/- 0.00
Eval num_timesteps=6984000, episode_reward=716.00 +/- 0.00
Episode length: 410.00 +/- 0.00
Eval num_timesteps=7008000, episode_reward=716.00 +/- 0.00
Episode length: 410.00 +/- 0.00
Eval num_timesteps=7032000, episode_reward=707.00 +/- 0.00
Episode length: 485.00 +/- 0.00
Eval num_timesteps=7056000, episode_reward=707.00 +/- 0.00
Episode length: 485.00 +/- 0.00
Eval num_timesteps=7080000, episode_reward=668.00 +/- 0.00
Episode length: 504.00 +/- 0.00
Eval num_timesteps=7104000, episode_reward=668.00 +/- 0.00
Episode length: 504.00 +/- 0.00
Eval num_timesteps=7128000, episode_reward=1221.00 +/- 0.00
Episode length: 688.00 +/- 0.00
Eval num_timesteps=7152000, episode_reward=1221.00 +/- 0.00
Episode length: 688.00 +/- 0.00
Eval num_timesteps=7176000, episode_reward=1221.00 +/- 0.00
Episode length: 688.00 +/- 0.00
Eval num_timesteps=7200000, episode_reward=995.00 +/- 0.00
Episode length: 393.00 +/- 0.00
Eval num_timesteps=7224000, episode_reward=995.00 +/- 0.00
Episode length: 393.00 +/- 0.00
Eval num_timesteps=7248000, episode_reward=791.00 +/- 0.00
Episode length: 264.00 +/- 0.00
Eval num_timesteps=7272000, episode_reward=791.00 +/- 0.00
Episode length: 264.00 +/- 0.00
Eval num_timesteps=7296000, episode_reward=1433.00 +/- 0.00
Episode length: 163.00 +/- 0.00
Eval num_timesteps=7320000, episode_reward=1433.00 +/- 0.00
Episode length: 163.00 +/- 0.00
Eval num_timesteps=7344000, episode_reward=1338.00 +/- 0.00
Episode length: 187.00 +/- 0.00
Eval num_timesteps=7368000, episode_reward=1338.00 +/- 0.00
Episode length: 187.00 +/- 0.00
Eval num_timesteps=7392000, episode_reward=1433.00 +/- 0.00
Episode length: 163.00 +/- 0.00
Eval num_timesteps=7416000, episode_reward=1433.00 +/- 0.00
Episode length: 163.00 +/- 0.00
Eval num_timesteps=7440000, episode_reward=1146.00 +/- 0.00
Episode length: 151.00 +/- 0.00
Eval num_timesteps=7464000, episode_reward=1146.00 +/- 0.00
Episode length: 151.00 +/- 0.00
Eval num_timesteps=7488000, episode_reward=1862.00 +/- 0.00
Episode length: 205.00 +/- 0.00
New best mean reward!
Eval num_timesteps=7512000, episode_reward=1862.00 +/- 0.00
Episode length: 205.00 +/- 0.00
Eval num_timesteps=7536000, episode_reward=194.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=7560000, episode_reward=194.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=7584000, episode_reward=1344.00 +/- 0.00
Episode length: 155.00 +/- 0.00
Eval num_timesteps=7608000, episode_reward=1344.00 +/- 0.00
Episode length: 155.00 +/- 0.00
Eval num_timesteps=7632000, episode_reward=638.00 +/- 0.00
Episode length: 72.00 +/- 0.00
Eval num_timesteps=7656000, episode_reward=638.00 +/- 0.00
Episode length: 72.00 +/- 0.00
Eval num_timesteps=7680000, episode_reward=1433.00 +/- 0.00
Episode length: 163.00 +/- 0.00
Eval num_timesteps=7704000, episode_reward=1433.00 +/- 0.00
Episode length: 163.00 +/- 0.00
Eval num_timesteps=7728000, episode_reward=1427.00 +/- 0.00
Episode length: 166.00 +/- 0.00
Eval num_timesteps=7752000, episode_reward=1427.00 +/- 0.00
Episode length: 166.00 +/- 0.00
Eval num_timesteps=7776000, episode_reward=1580.00 +/- 0.00
Episode length: 175.00 +/- 0.00
Eval num_timesteps=7800000, episode_reward=1580.00 +/- 0.00
Episode length: 175.00 +/- 0.00
Eval num_timesteps=7824000, episode_reward=354.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=7848000, episode_reward=354.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=7872000, episode_reward=1344.00 +/- 0.00
Episode length: 169.00 +/- 0.00
Eval num_timesteps=7896000, episode_reward=1344.00 +/- 0.00
Episode length: 169.00 +/- 0.00
Eval num_timesteps=7920000, episode_reward=1580.00 +/- 0.00
Episode length: 175.00 +/- 0.00
Eval num_timesteps=7944000, episode_reward=1580.00 +/- 0.00
Episode length: 175.00 +/- 0.00
Eval num_timesteps=7968000, episode_reward=1695.00 +/- 0.00
Episode length: 188.00 +/- 0.00
Eval num_timesteps=7992000, episode_reward=1695.00 +/- 0.00
Episode length: 188.00 +/- 0.00
Eval num_timesteps=8016000, episode_reward=1695.00 +/- 0.00
Episode length: 188.00 +/- 0.00
Eval num_timesteps=8040000, episode_reward=1695.00 +/- 0.00
Episode length: 188.00 +/- 0.00
Eval num_timesteps=8064000, episode_reward=2291.00 +/- 0.00
Episode length: 627.00 +/- 0.00
New best mean reward!
Eval num_timesteps=8088000, episode_reward=2291.00 +/- 0.00
Episode length: 627.00 +/- 0.00
Eval num_timesteps=8112000, episode_reward=1854.00 +/- 0.00
Episode length: 203.00 +/- 0.00
Eval num_timesteps=8136000, episode_reward=1854.00 +/- 0.00
Episode length: 203.00 +/- 0.00
Eval num_timesteps=8160000, episode_reward=252.00 +/- 0.00
Episode length: 27.00 +/- 0.00
Eval num_timesteps=8184000, episode_reward=252.00 +/- 0.00
Episode length: 27.00 +/- 0.00
Eval num_timesteps=8208000, episode_reward=252.00 +/- 0.00
Episode length: 27.00 +/- 0.00
Eval num_timesteps=8232000, episode_reward=616.00 +/- 0.00
Episode length: 256.00 +/- 0.00
Eval num_timesteps=8256000, episode_reward=616.00 +/- 0.00
Episode length: 256.00 +/- 0.00
Eval num_timesteps=8280000, episode_reward=1350.00 +/- 0.00
Episode length: 138.00 +/- 0.00
Eval num_timesteps=8304000, episode_reward=1350.00 +/- 0.00
Episode length: 138.00 +/- 0.00
Eval num_timesteps=8328000, episode_reward=637.00 +/- 0.00
Episode length: 72.00 +/- 0.00
Eval num_timesteps=8352000, episode_reward=637.00 +/- 0.00
Episode length: 72.00 +/- 0.00
Eval num_timesteps=8376000, episode_reward=770.00 +/- 0.00
Episode length: 121.00 +/- 0.00
Eval num_timesteps=8400000, episode_reward=770.00 +/- 0.00
Episode length: 121.00 +/- 0.00
Eval num_timesteps=8424000, episode_reward=1046.00 +/- 0.00
Episode length: 138.00 +/- 0.00
Eval num_timesteps=8448000, episode_reward=1046.00 +/- 0.00
Episode length: 138.00 +/- 0.00
Eval num_timesteps=8472000, episode_reward=635.00 +/- 0.00
Episode length: 69.00 +/- 0.00
Eval num_timesteps=8496000, episode_reward=635.00 +/- 0.00
Episode length: 69.00 +/- 0.00
Eval num_timesteps=8520000, episode_reward=1049.00 +/- 0.00
Episode length: 122.00 +/- 0.00
Eval num_timesteps=8544000, episode_reward=1049.00 +/- 0.00
Episode length: 122.00 +/- 0.00
Eval num_timesteps=8568000, episode_reward=1024.00 +/- 0.00
Episode length: 246.00 +/- 0.00
Eval num_timesteps=8592000, episode_reward=1024.00 +/- 0.00
Episode length: 246.00 +/- 0.00
Eval num_timesteps=8616000, episode_reward=641.00 +/- 0.00
Episode length: 132.00 +/- 0.00
Eval num_timesteps=8640000, episode_reward=641.00 +/- 0.00
Episode length: 132.00 +/- 0.00
Eval num_timesteps=8664000, episode_reward=1040.00 +/- 0.00
Episode length: 159.00 +/- 0.00
Eval num_timesteps=8688000, episode_reward=1040.00 +/- 0.00
Episode length: 159.00 +/- 0.00
Eval num_timesteps=8712000, episode_reward=634.00 +/- 0.00
Episode length: 101.00 +/- 0.00
Eval num_timesteps=8736000, episode_reward=634.00 +/- 0.00
Episode length: 101.00 +/- 0.00
Eval num_timesteps=8760000, episode_reward=1248.00 +/- 0.00
Episode length: 640.00 +/- 0.00
Eval num_timesteps=8784000, episode_reward=1248.00 +/- 0.00
Episode length: 640.00 +/- 0.00
Eval num_timesteps=8808000, episode_reward=252.00 +/- 0.00
Episode length: 27.00 +/- 0.00
Eval num_timesteps=8832000, episode_reward=252.00 +/- 0.00
Episode length: 27.00 +/- 0.00
Eval num_timesteps=8856000, episode_reward=1045.00 +/- 0.00
Episode length: 148.00 +/- 0.00
Eval num_timesteps=8880000, episode_reward=1045.00 +/- 0.00
Episode length: 148.00 +/- 0.00
Eval num_timesteps=8904000, episode_reward=809.00 +/- 0.00
Episode length: 171.00 +/- 0.00
Eval num_timesteps=8928000, episode_reward=809.00 +/- 0.00
Episode length: 171.00 +/- 0.00
Eval num_timesteps=8952000, episode_reward=1339.00 +/- 0.00
Episode length: 189.00 +/- 0.00
Eval num_timesteps=8976000, episode_reward=1339.00 +/- 0.00
Episode length: 189.00 +/- 0.00
Eval num_timesteps=9000000, episode_reward=1427.00 +/- 0.00
Episode length: 198.00 +/- 0.00
Eval num_timesteps=9024000, episode_reward=1427.00 +/- 0.00
Episode length: 198.00 +/- 0.00
Eval num_timesteps=9048000, episode_reward=1339.00 +/- 0.00
Episode length: 192.00 +/- 0.00
Eval num_timesteps=9072000, episode_reward=1339.00 +/- 0.00
Episode length: 192.00 +/- 0.00
Eval num_timesteps=9096000, episode_reward=1339.00 +/- 0.00
Episode length: 192.00 +/- 0.00
Eval num_timesteps=9120000, episode_reward=1339.00 +/- 0.00
Episode length: 192.00 +/- 0.00
Eval num_timesteps=9144000, episode_reward=1338.00 +/- 0.00
Episode length: 190.00 +/- 0.00
Eval num_timesteps=9168000, episode_reward=1338.00 +/- 0.00
Episode length: 190.00 +/- 0.00
Eval num_timesteps=9192000, episode_reward=810.00 +/- 0.00
Episode length: 167.00 +/- 0.00
Eval num_timesteps=9216000, episode_reward=810.00 +/- 0.00
Episode length: 167.00 +/- 0.00
Eval num_timesteps=9240000, episode_reward=810.00 +/- 0.00
Episode length: 167.00 +/- 0.00
Eval num_timesteps=9264000, episode_reward=810.00 +/- 0.00
Episode length: 167.00 +/- 0.00
Eval num_timesteps=9288000, episode_reward=810.00 +/- 0.00
Episode length: 167.00 +/- 0.00
Eval num_timesteps=9312000, episode_reward=810.00 +/- 0.00
Episode length: 167.00 +/- 0.00
Eval num_timesteps=9336000, episode_reward=810.00 +/- 0.00
Episode length: 167.00 +/- 0.00
Eval num_timesteps=9360000, episode_reward=658.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=9384000, episode_reward=658.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=9408000, episode_reward=694.00 +/- 0.00
Episode length: 749.00 +/- 0.00
Eval num_timesteps=9432000, episode_reward=694.00 +/- 0.00
Episode length: 749.00 +/- 0.00
Eval num_timesteps=9456000, episode_reward=551.00 +/- 0.00
Episode length: 584.00 +/- 0.00
Eval num_timesteps=9480000, episode_reward=551.00 +/- 0.00
Episode length: 584.00 +/- 0.00
Eval num_timesteps=9504000, episode_reward=551.00 +/- 0.00
Episode length: 584.00 +/- 0.00
Eval num_timesteps=9528000, episode_reward=551.00 +/- 0.00
Episode length: 584.00 +/- 0.00
Eval num_timesteps=9552000, episode_reward=719.00 +/- 0.00
Episode length: 622.00 +/- 0.00
Eval num_timesteps=9576000, episode_reward=719.00 +/- 0.00
Episode length: 622.00 +/- 0.00
Eval num_timesteps=9600000, episode_reward=240.00 +/- 0.00
Episode length: 30.00 +/- 0.00
Eval num_timesteps=9624000, episode_reward=240.00 +/- 0.00
Episode length: 30.00 +/- 0.00
Eval num_timesteps=9648000, episode_reward=641.00 +/- 0.00
Episode length: 132.00 +/- 0.00
Eval num_timesteps=9672000, episode_reward=641.00 +/- 0.00
Episode length: 132.00 +/- 0.00
Eval num_timesteps=9696000, episode_reward=641.00 +/- 0.00
Episode length: 132.00 +/- 0.00
Eval num_timesteps=9720000, episode_reward=641.00 +/- 0.00
Episode length: 132.00 +/- 0.00
Eval num_timesteps=9744000, episode_reward=768.00 +/- 0.00
Episode length: 187.00 +/- 0.00
Eval num_timesteps=9768000, episode_reward=768.00 +/- 0.00
Episode length: 187.00 +/- 0.00
Eval num_timesteps=9792000, episode_reward=798.00 +/- 0.00
Episode length: 226.00 +/- 0.00
Eval num_timesteps=9816000, episode_reward=798.00 +/- 0.00
Episode length: 226.00 +/- 0.00
Eval num_timesteps=9840000, episode_reward=625.00 +/- 0.00
Episode length: 63.00 +/- 0.00
Eval num_timesteps=9864000, episode_reward=625.00 +/- 0.00
Episode length: 63.00 +/- 0.00
Eval num_timesteps=9888000, episode_reward=240.00 +/- 0.00
Episode length: 30.00 +/- 0.00
Eval num_timesteps=9912000, episode_reward=240.00 +/- 0.00
Episode length: 30.00 +/- 0.00
Eval num_timesteps=9936000, episode_reward=252.00 +/- 0.00
Episode length: 27.00 +/- 0.00
Eval num_timesteps=9960000, episode_reward=252.00 +/- 0.00
Episode length: 27.00 +/- 0.00
Eval num_timesteps=9984000, episode_reward=252.00 +/- 0.00
Episode length: 27.00 +/- 0.00
Eval num_timesteps=10008000, episode_reward=252.00 +/- 0.00
Episode length: 27.00 +/- 0.00
 100% ━━━━━━━━━━━━━━━━━ 10,027,008/10,00… [ 1 day, 10:12:02 < 0:00:00 , ? it/s ]
