/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/envs/registration.py:555: UserWarning: [33mWARN: The environment SuperMarioBros-1-3-v0 is out of date. You should consider upgrading to version `v3`.[0m
  logger.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/envs/registration.py:555: UserWarning: [33mWARN: The environment SuperMarioBros-1-3-v0 is out of date. You should consider upgrading to version `v3`.[0m
  logger.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/envs/registration.py:555: UserWarning: [33mWARN: The environment SuperMarioBros-1-3-v0 is out of date. You should consider upgrading to version `v3`.[0m
  logger.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/envs/registration.py:555: UserWarning: [33mWARN: The environment SuperMarioBros-1-3-v0 is out of date. You should consider upgrading to version `v3`.[0m
  logger.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/envs/registration.py:555: UserWarning: [33mWARN: The environment SuperMarioBros-1-3-v0 is out of date. You should consider upgrading to version `v3`.[0m
  logger.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/envs/registration.py:555: UserWarning: [33mWARN: The environment SuperMarioBros-1-3-v0 is out of date. You should consider upgrading to version `v3`.[0m
  logger.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/envs/registration.py:555: UserWarning: [33mWARN: The environment SuperMarioBros-1-3-v0 is out of date. You should consider upgrading to version `v3`.[0m
  logger.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/envs/registration.py:555: UserWarning: [33mWARN: The environment SuperMarioBros-1-3-v0 is out of date. You should consider upgrading to version `v3`.[0m
  logger.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/envs/registration.py:555: UserWarning: [33mWARN: The environment SuperMarioBros-1-3-v0 is out of date. You should consider upgrading to version `v3`.[0m
  logger.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/envs/registration.py:555: UserWarning: [33mWARN: The environment SuperMarioBros-1-3-v0 is out of date. You should consider upgrading to version `v3`.[0m
  logger.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/envs/registration.py:555: UserWarning: [33mWARN: The environment SuperMarioBros-1-3-v0 is out of date. You should consider upgrading to version `v3`.[0m
  logger.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/envs/registration.py:555: UserWarning: [33mWARN: The environment SuperMarioBros-1-3-v0 is out of date. You should consider upgrading to version `v3`.[0m
  logger.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/envs/registration.py:555: UserWarning: [33mWARN: The environment SuperMarioBros-1-3-v0 is out of date. You should consider upgrading to version `v3`.[0m
  logger.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/envs/registration.py:555: UserWarning: [33mWARN: The environment SuperMarioBros-1-3-v0 is out of date. You should consider upgrading to version `v3`.[0m
  logger.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/envs/registration.py:555: UserWarning: [33mWARN: The environment SuperMarioBros-1-3-v0 is out of date. You should consider upgrading to version `v3`.[0m
  logger.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/envs/registration.py:555: UserWarning: [33mWARN: The environment SuperMarioBros-1-3-v0 is out of date. You should consider upgrading to version `v3`.[0m
  logger.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/envs/registration.py:555: UserWarning: [33mWARN: The environment SuperMarioBros-1-3-v0 is out of date. You should consider upgrading to version `v3`.[0m
  logger.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/envs/registration.py:555: UserWarning: [33mWARN: The environment SuperMarioBros-1-3-v0 is out of date. You should consider upgrading to version `v3`.[0m
  logger.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/envs/registration.py:555: UserWarning: [33mWARN: The environment SuperMarioBros-1-3-v0 is out of date. You should consider upgrading to version `v3`.[0m
  logger.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/envs/registration.py:555: UserWarning: [33mWARN: The environment SuperMarioBros-1-3-v0 is out of date. You should consider upgrading to version `v3`.[0m
  logger.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/envs/registration.py:555: UserWarning: [33mWARN: The environment SuperMarioBros-1-3-v0 is out of date. You should consider upgrading to version `v3`.[0m
  logger.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/envs/registration.py:555: UserWarning: [33mWARN: The environment SuperMarioBros-1-3-v0 is out of date. You should consider upgrading to version `v3`.[0m
  logger.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/envs/registration.py:555: UserWarning: [33mWARN: The environment SuperMarioBros-1-3-v0 is out of date. You should consider upgrading to version `v3`.[0m
  logger.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/envs/registration.py:555: UserWarning: [33mWARN: The environment SuperMarioBros-1-3-v0 is out of date. You should consider upgrading to version `v3`.[0m
  logger.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.
  warnings.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.
  warnings.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.
  warnings.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.
  warnings.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.
  warnings.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.
  warnings.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.
  warnings.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.
  warnings.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.
  warnings.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.
  warnings.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.
  warnings.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.
  warnings.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.
  warnings.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.
  warnings.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.
  warnings.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.
  warnings.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.
  warnings.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.
  warnings.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.
  warnings.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.
  warnings.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.
  warnings.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.
  warnings.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.
  warnings.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.
  warnings.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/stable_baselines3/common/callbacks.py:403: UserWarning: Training and eval env are not of the same type<stable_baselines3.common.vec_env.vec_transpose.VecTransposeImage object at 0x148f0bcf72b0> != <stable_baselines3.common.vec_env.vec_monitor.VecMonitor object at 0x148f0bcf5ab0>
  warnings.warn("Training and eval env are not of the same type" f"{self.training_env} != {self.eval_env}")
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(terminated, (bool, np.bool8)):
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(terminated, (bool, np.bool8)):
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(terminated, (bool, np.bool8)):
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(terminated, (bool, np.bool8)):
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(terminated, (bool, np.bool8)):
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(terminated, (bool, np.bool8)):
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(terminated, (bool, np.bool8)):
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(terminated, (bool, np.bool8)):
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(terminated, (bool, np.bool8)):
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(terminated, (bool, np.bool8)):
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(terminated, (bool, np.bool8)):
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(terminated, (bool, np.bool8)):
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(terminated, (bool, np.bool8)):
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(terminated, (bool, np.bool8)):
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(terminated, (bool, np.bool8)):
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(terminated, (bool, np.bool8)):
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(terminated, (bool, np.bool8)):
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(terminated, (bool, np.bool8)):
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(terminated, (bool, np.bool8)):
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(terminated, (bool, np.bool8)):
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(terminated, (bool, np.bool8)):
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(terminated, (bool, np.bool8)):
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(terminated, (bool, np.bool8)):
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(terminated, (bool, np.bool8)):
Training model!
World: 1
Stage: 3
Vectors: 24
Steps: 10000000
Learning rate: 0.0003
Eval num_timesteps=24000, episode_reward=253.00 +/- 0.00
Episode length: 32.00 +/- 0.00
New best mean reward!
Eval num_timesteps=48000, episode_reward=253.00 +/- 0.00
Episode length: 32.00 +/- 0.00
Eval num_timesteps=72000, episode_reward=252.00 +/- 0.00
Episode length: 34.00 +/- 0.00
Eval num_timesteps=96000, episode_reward=252.00 +/- 0.00
Episode length: 34.00 +/- 0.00
Eval num_timesteps=120000, episode_reward=354.00 +/- 0.00
Episode length: 38.00 +/- 0.00
New best mean reward!
Eval num_timesteps=144000, episode_reward=354.00 +/- 0.00
Episode length: 38.00 +/- 0.00
Eval num_timesteps=168000, episode_reward=354.00 +/- 0.00
Episode length: 37.00 +/- 0.00
Eval num_timesteps=192000, episode_reward=354.00 +/- 0.00
Episode length: 37.00 +/- 0.00
Eval num_timesteps=216000, episode_reward=354.00 +/- 0.00
Episode length: 38.00 +/- 0.00
Eval num_timesteps=240000, episode_reward=354.00 +/- 0.00
Episode length: 38.00 +/- 0.00
Eval num_timesteps=264000, episode_reward=630.00 +/- 0.00
Episode length: 68.00 +/- 0.00
New best mean reward!
Eval num_timesteps=288000, episode_reward=630.00 +/- 0.00
Episode length: 68.00 +/- 0.00
Eval num_timesteps=312000, episode_reward=354.00 +/- 0.00
Episode length: 38.00 +/- 0.00
Eval num_timesteps=336000, episode_reward=354.00 +/- 0.00
Episode length: 38.00 +/- 0.00
Eval num_timesteps=360000, episode_reward=630.00 +/- 0.00
Episode length: 70.00 +/- 0.00
Eval num_timesteps=384000, episode_reward=630.00 +/- 0.00
Episode length: 70.00 +/- 0.00
Eval num_timesteps=408000, episode_reward=251.00 +/- 0.00
Episode length: 29.00 +/- 0.00
Eval num_timesteps=432000, episode_reward=251.00 +/- 0.00
Episode length: 29.00 +/- 0.00
Eval num_timesteps=456000, episode_reward=675.00 +/- 0.00
Episode length: 67.00 +/- 0.00
New best mean reward!
Eval num_timesteps=480000, episode_reward=675.00 +/- 0.00
Episode length: 67.00 +/- 0.00
Eval num_timesteps=504000, episode_reward=674.00 +/- 0.00
Episode length: 66.00 +/- 0.00
Eval num_timesteps=528000, episode_reward=674.00 +/- 0.00
Episode length: 66.00 +/- 0.00
Eval num_timesteps=552000, episode_reward=674.00 +/- 0.00
Episode length: 66.00 +/- 0.00
Eval num_timesteps=576000, episode_reward=674.00 +/- 0.00
Episode length: 66.00 +/- 0.00
Eval num_timesteps=600000, episode_reward=676.00 +/- 0.00
Episode length: 66.00 +/- 0.00
New best mean reward!
Eval num_timesteps=624000, episode_reward=676.00 +/- 0.00
Episode length: 66.00 +/- 0.00
Eval num_timesteps=648000, episode_reward=351.00 +/- 0.00
Episode length: 39.00 +/- 0.00
Eval num_timesteps=672000, episode_reward=351.00 +/- 0.00
Episode length: 39.00 +/- 0.00
Eval num_timesteps=696000, episode_reward=675.00 +/- 0.00
Episode length: 66.00 +/- 0.00
Eval num_timesteps=720000, episode_reward=675.00 +/- 0.00
Episode length: 66.00 +/- 0.00
Eval num_timesteps=744000, episode_reward=675.00 +/- 0.00
Episode length: 66.00 +/- 0.00
Eval num_timesteps=768000, episode_reward=675.00 +/- 0.00
Episode length: 66.00 +/- 0.00
Eval num_timesteps=792000, episode_reward=674.00 +/- 0.00
Episode length: 66.00 +/- 0.00
Eval num_timesteps=816000, episode_reward=674.00 +/- 0.00
Episode length: 66.00 +/- 0.00
Eval num_timesteps=840000, episode_reward=258.00 +/- 0.00
Episode length: 27.00 +/- 0.00
Eval num_timesteps=864000, episode_reward=258.00 +/- 0.00
Episode length: 27.00 +/- 0.00
Eval num_timesteps=888000, episode_reward=258.00 +/- 0.00
Episode length: 27.00 +/- 0.00
Eval num_timesteps=912000, episode_reward=258.00 +/- 0.00
Episode length: 27.00 +/- 0.00
Eval num_timesteps=936000, episode_reward=258.00 +/- 0.00
Episode length: 27.00 +/- 0.00
Eval num_timesteps=960000, episode_reward=258.00 +/- 0.00
Episode length: 27.00 +/- 0.00
Eval num_timesteps=984000, episode_reward=258.00 +/- 0.00
Episode length: 27.00 +/- 0.00
Eval num_timesteps=1008000, episode_reward=258.00 +/- 0.00
Episode length: 27.00 +/- 0.00
Eval num_timesteps=1032000, episode_reward=258.00 +/- 0.00
Episode length: 27.00 +/- 0.00
Eval num_timesteps=1056000, episode_reward=258.00 +/- 0.00
Episode length: 27.00 +/- 0.00
Eval num_timesteps=1080000, episode_reward=258.00 +/- 0.00
Episode length: 27.00 +/- 0.00
Eval num_timesteps=1104000, episode_reward=258.00 +/- 0.00
Episode length: 27.00 +/- 0.00
Eval num_timesteps=1128000, episode_reward=258.00 +/- 0.00
Episode length: 27.00 +/- 0.00
Eval num_timesteps=1152000, episode_reward=258.00 +/- 0.00
Episode length: 27.00 +/- 0.00
Eval num_timesteps=1176000, episode_reward=258.00 +/- 0.00
Episode length: 27.00 +/- 0.00
Eval num_timesteps=1200000, episode_reward=258.00 +/- 0.00
Episode length: 27.00 +/- 0.00
Eval num_timesteps=1224000, episode_reward=258.00 +/- 0.00
Episode length: 27.00 +/- 0.00
Eval num_timesteps=1248000, episode_reward=258.00 +/- 0.00
Episode length: 27.00 +/- 0.00
Eval num_timesteps=1272000, episode_reward=258.00 +/- 0.00
Episode length: 27.00 +/- 0.00
Eval num_timesteps=1296000, episode_reward=258.00 +/- 0.00
Episode length: 27.00 +/- 0.00
Eval num_timesteps=1320000, episode_reward=258.00 +/- 0.00
Episode length: 27.00 +/- 0.00
Eval num_timesteps=1344000, episode_reward=258.00 +/- 0.00
Episode length: 27.00 +/- 0.00
Eval num_timesteps=1368000, episode_reward=258.00 +/- 0.00
Episode length: 27.00 +/- 0.00
Eval num_timesteps=1392000, episode_reward=258.00 +/- 0.00
Episode length: 27.00 +/- 0.00
Eval num_timesteps=1416000, episode_reward=258.00 +/- 0.00
Episode length: 27.00 +/- 0.00
Eval num_timesteps=1440000, episode_reward=258.00 +/- 0.00
Episode length: 27.00 +/- 0.00
Eval num_timesteps=1464000, episode_reward=258.00 +/- 0.00
Episode length: 27.00 +/- 0.00
Eval num_timesteps=1488000, episode_reward=258.00 +/- 0.00
Episode length: 27.00 +/- 0.00
Eval num_timesteps=1512000, episode_reward=258.00 +/- 0.00
Episode length: 27.00 +/- 0.00
Eval num_timesteps=1536000, episode_reward=-14.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=1560000, episode_reward=-14.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=1584000, episode_reward=-2.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=1608000, episode_reward=-2.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=1632000, episode_reward=-2.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=1656000, episode_reward=-2.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=1680000, episode_reward=-2.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=1704000, episode_reward=-2.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=1728000, episode_reward=-2.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=1752000, episode_reward=-2.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=1776000, episode_reward=10.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=1800000, episode_reward=10.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=1824000, episode_reward=10.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=1848000, episode_reward=10.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=1872000, episode_reward=221.00 +/- 0.00
Episode length: 29.00 +/- 0.00
Eval num_timesteps=1896000, episode_reward=221.00 +/- 0.00
Episode length: 29.00 +/- 0.00
Eval num_timesteps=1920000, episode_reward=316.00 +/- 0.00
Episode length: 53.00 +/- 0.00
Eval num_timesteps=1944000, episode_reward=316.00 +/- 0.00
Episode length: 53.00 +/- 0.00
Eval num_timesteps=1968000, episode_reward=336.00 +/- 0.00
Episode length: 58.00 +/- 0.00
Eval num_timesteps=1992000, episode_reward=336.00 +/- 0.00
Episode length: 58.00 +/- 0.00
Eval num_timesteps=2016000, episode_reward=676.00 +/- 0.00
Episode length: 68.00 +/- 0.00
Eval num_timesteps=2040000, episode_reward=676.00 +/- 0.00
Episode length: 68.00 +/- 0.00
Eval num_timesteps=2064000, episode_reward=676.00 +/- 0.00
Episode length: 68.00 +/- 0.00
Eval num_timesteps=2088000, episode_reward=677.00 +/- 0.00
Episode length: 64.00 +/- 0.00
New best mean reward!
Eval num_timesteps=2112000, episode_reward=677.00 +/- 0.00
Episode length: 64.00 +/- 0.00
Eval num_timesteps=2136000, episode_reward=675.00 +/- 0.00
Episode length: 69.00 +/- 0.00
Eval num_timesteps=2160000, episode_reward=675.00 +/- 0.00
Episode length: 69.00 +/- 0.00
Eval num_timesteps=2184000, episode_reward=673.00 +/- 0.00
Episode length: 69.00 +/- 0.00
Eval num_timesteps=2208000, episode_reward=673.00 +/- 0.00
Episode length: 69.00 +/- 0.00
Eval num_timesteps=2232000, episode_reward=677.00 +/- 0.00
Episode length: 65.00 +/- 0.00
Eval num_timesteps=2256000, episode_reward=677.00 +/- 0.00
Episode length: 65.00 +/- 0.00
Eval num_timesteps=2280000, episode_reward=709.00 +/- 0.00
Episode length: 68.00 +/- 0.00
New best mean reward!
Eval num_timesteps=2304000, episode_reward=709.00 +/- 0.00
Episode length: 68.00 +/- 0.00
Eval num_timesteps=2328000, episode_reward=712.00 +/- 0.00
Episode length: 70.00 +/- 0.00
New best mean reward!
Eval num_timesteps=2352000, episode_reward=712.00 +/- 0.00
Episode length: 70.00 +/- 0.00
Eval num_timesteps=2376000, episode_reward=709.00 +/- 0.00
Episode length: 68.00 +/- 0.00
Eval num_timesteps=2400000, episode_reward=709.00 +/- 0.00
Episode length: 68.00 +/- 0.00
Eval num_timesteps=2424000, episode_reward=698.00 +/- 0.00
Episode length: 69.00 +/- 0.00
Eval num_timesteps=2448000, episode_reward=698.00 +/- 0.00
Episode length: 69.00 +/- 0.00
Eval num_timesteps=2472000, episode_reward=358.00 +/- 0.00
Episode length: 36.00 +/- 0.00
Eval num_timesteps=2496000, episode_reward=358.00 +/- 0.00
Episode length: 36.00 +/- 0.00
Eval num_timesteps=2520000, episode_reward=355.00 +/- 0.00
Episode length: 36.00 +/- 0.00
Eval num_timesteps=2544000, episode_reward=355.00 +/- 0.00
Episode length: 36.00 +/- 0.00
Eval num_timesteps=2568000, episode_reward=712.00 +/- 0.00
Episode length: 66.00 +/- 0.00
Eval num_timesteps=2592000, episode_reward=712.00 +/- 0.00
Episode length: 66.00 +/- 0.00
Eval num_timesteps=2616000, episode_reward=712.00 +/- 0.00
Episode length: 66.00 +/- 0.00
Eval num_timesteps=2640000, episode_reward=712.00 +/- 0.00
Episode length: 66.00 +/- 0.00
Eval num_timesteps=2664000, episode_reward=712.00 +/- 0.00
Episode length: 66.00 +/- 0.00
Eval num_timesteps=2688000, episode_reward=712.00 +/- 0.00
Episode length: 66.00 +/- 0.00
Eval num_timesteps=2712000, episode_reward=712.00 +/- 0.00
Episode length: 66.00 +/- 0.00
Eval num_timesteps=2736000, episode_reward=712.00 +/- 0.00
Episode length: 66.00 +/- 0.00
Eval num_timesteps=2760000, episode_reward=258.00 +/- 0.00
Episode length: 27.00 +/- 0.00
Eval num_timesteps=2784000, episode_reward=258.00 +/- 0.00
Episode length: 27.00 +/- 0.00
Eval num_timesteps=2808000, episode_reward=-38.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=2832000, episode_reward=-38.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=2856000, episode_reward=-2.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=2880000, episode_reward=-2.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=2904000, episode_reward=-200.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=2928000, episode_reward=-200.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=2952000, episode_reward=-200.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=2976000, episode_reward=-200.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=3000000, episode_reward=-200.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=3024000, episode_reward=-200.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=3048000, episode_reward=-200.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=3072000, episode_reward=-200.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=3096000, episode_reward=-200.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=3120000, episode_reward=-200.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=3144000, episode_reward=-200.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=3168000, episode_reward=-200.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=3192000, episode_reward=-200.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=3216000, episode_reward=-200.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=3240000, episode_reward=-200.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=3264000, episode_reward=-200.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=3288000, episode_reward=-200.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=3312000, episode_reward=-200.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=3336000, episode_reward=-200.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=3360000, episode_reward=-200.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=3384000, episode_reward=-200.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=3408000, episode_reward=-200.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=3432000, episode_reward=-200.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=3456000, episode_reward=-200.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=3480000, episode_reward=-200.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=3504000, episode_reward=-200.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=3528000, episode_reward=-200.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=3552000, episode_reward=-200.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=3576000, episode_reward=-200.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=3600000, episode_reward=-200.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=3624000, episode_reward=-200.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=3648000, episode_reward=-200.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=3672000, episode_reward=-200.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=3696000, episode_reward=-200.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=3720000, episode_reward=-200.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=3744000, episode_reward=-200.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=3768000, episode_reward=-200.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=3792000, episode_reward=-200.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=3816000, episode_reward=-200.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=3840000, episode_reward=-200.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=3864000, episode_reward=-200.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=3888000, episode_reward=-200.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=3912000, episode_reward=-200.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=3936000, episode_reward=-200.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=3960000, episode_reward=-200.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=3984000, episode_reward=-200.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=4008000, episode_reward=-200.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=4032000, episode_reward=-200.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=4056000, episode_reward=-200.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=4080000, episode_reward=-200.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=4104000, episode_reward=-200.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=4128000, episode_reward=-200.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=4152000, episode_reward=-194.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=4176000, episode_reward=-194.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=4200000, episode_reward=-194.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=4224000, episode_reward=-194.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=4248000, episode_reward=-180.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=4272000, episode_reward=-180.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=4296000, episode_reward=180.00 +/- 0.00
Episode length: 160.00 +/- 0.00
Eval num_timesteps=4320000, episode_reward=180.00 +/- 0.00
Episode length: 160.00 +/- 0.00
Eval num_timesteps=4344000, episode_reward=312.00 +/- 0.00
Episode length: 102.00 +/- 0.00
Eval num_timesteps=4368000, episode_reward=312.00 +/- 0.00
Episode length: 102.00 +/- 0.00
Eval num_timesteps=4392000, episode_reward=238.00 +/- 0.00
Episode length: 55.00 +/- 0.00
Eval num_timesteps=4416000, episode_reward=238.00 +/- 0.00
Episode length: 55.00 +/- 0.00
Eval num_timesteps=4440000, episode_reward=328.00 +/- 0.00
Episode length: 57.00 +/- 0.00
Eval num_timesteps=4464000, episode_reward=328.00 +/- 0.00
Episode length: 57.00 +/- 0.00
Eval num_timesteps=4488000, episode_reward=349.00 +/- 0.00
Episode length: 64.00 +/- 0.00
Eval num_timesteps=4512000, episode_reward=349.00 +/- 0.00
Episode length: 64.00 +/- 0.00
Eval num_timesteps=4536000, episode_reward=222.00 +/- 0.00
Episode length: 42.00 +/- 0.00
Eval num_timesteps=4560000, episode_reward=222.00 +/- 0.00
Episode length: 42.00 +/- 0.00
Eval num_timesteps=4584000, episode_reward=568.00 +/- 0.00
Episode length: 237.00 +/- 0.00
Eval num_timesteps=4608000, episode_reward=568.00 +/- 0.00
Episode length: 237.00 +/- 0.00
Eval num_timesteps=4632000, episode_reward=142.00 +/- 0.00
Episode length: 411.00 +/- 0.00
Eval num_timesteps=4656000, episode_reward=142.00 +/- 0.00
Episode length: 411.00 +/- 0.00
Eval num_timesteps=4680000, episode_reward=557.00 +/- 0.00
Episode length: 75.00 +/- 0.00
Eval num_timesteps=4704000, episode_reward=557.00 +/- 0.00
Episode length: 75.00 +/- 0.00
Eval num_timesteps=4728000, episode_reward=248.00 +/- 0.00
Episode length: 31.00 +/- 0.00
Eval num_timesteps=4752000, episode_reward=248.00 +/- 0.00
Episode length: 31.00 +/- 0.00
Eval num_timesteps=4776000, episode_reward=656.00 +/- 0.00
Episode length: 134.00 +/- 0.00
Eval num_timesteps=4800000, episode_reward=656.00 +/- 0.00
Episode length: 134.00 +/- 0.00
Eval num_timesteps=4824000, episode_reward=247.00 +/- 0.00
Episode length: 31.00 +/- 0.00
Eval num_timesteps=4848000, episode_reward=247.00 +/- 0.00
Episode length: 31.00 +/- 0.00
Eval num_timesteps=4872000, episode_reward=642.00 +/- 0.00
Episode length: 73.00 +/- 0.00
Eval num_timesteps=4896000, episode_reward=642.00 +/- 0.00
Episode length: 73.00 +/- 0.00
Eval num_timesteps=4920000, episode_reward=629.00 +/- 0.00
Episode length: 74.00 +/- 0.00
Eval num_timesteps=4944000, episode_reward=629.00 +/- 0.00
Episode length: 74.00 +/- 0.00
Eval num_timesteps=4968000, episode_reward=640.00 +/- 0.00
Episode length: 72.00 +/- 0.00
Eval num_timesteps=4992000, episode_reward=640.00 +/- 0.00
Episode length: 72.00 +/- 0.00
Eval num_timesteps=5016000, episode_reward=584.00 +/- 0.00
Episode length: 66.00 +/- 0.00
Eval num_timesteps=5040000, episode_reward=584.00 +/- 0.00
Episode length: 66.00 +/- 0.00
Eval num_timesteps=5064000, episode_reward=590.00 +/- 0.00
Episode length: 61.00 +/- 0.00
Eval num_timesteps=5088000, episode_reward=590.00 +/- 0.00
Episode length: 61.00 +/- 0.00
Eval num_timesteps=5112000, episode_reward=702.00 +/- 0.00
Episode length: 70.00 +/- 0.00
Eval num_timesteps=5136000, episode_reward=702.00 +/- 0.00
Episode length: 70.00 +/- 0.00
Eval num_timesteps=5160000, episode_reward=702.00 +/- 0.00
Episode length: 70.00 +/- 0.00
Eval num_timesteps=5184000, episode_reward=693.00 +/- 0.00
Episode length: 69.00 +/- 0.00
Eval num_timesteps=5208000, episode_reward=693.00 +/- 0.00
Episode length: 69.00 +/- 0.00
Eval num_timesteps=5232000, episode_reward=699.00 +/- 0.00
Episode length: 69.00 +/- 0.00
Eval num_timesteps=5256000, episode_reward=699.00 +/- 0.00
Episode length: 69.00 +/- 0.00
Eval num_timesteps=5280000, episode_reward=701.00 +/- 0.00
Episode length: 71.00 +/- 0.00
Eval num_timesteps=5304000, episode_reward=701.00 +/- 0.00
Episode length: 71.00 +/- 0.00
Eval num_timesteps=5328000, episode_reward=703.00 +/- 0.00
Episode length: 70.00 +/- 0.00
Eval num_timesteps=5352000, episode_reward=703.00 +/- 0.00
Episode length: 70.00 +/- 0.00
Eval num_timesteps=5376000, episode_reward=700.00 +/- 0.00
Episode length: 70.00 +/- 0.00
Eval num_timesteps=5400000, episode_reward=700.00 +/- 0.00
Episode length: 70.00 +/- 0.00
Eval num_timesteps=5424000, episode_reward=698.00 +/- 0.00
Episode length: 69.00 +/- 0.00
Eval num_timesteps=5448000, episode_reward=698.00 +/- 0.00
Episode length: 69.00 +/- 0.00
Eval num_timesteps=5472000, episode_reward=697.00 +/- 0.00
Episode length: 69.00 +/- 0.00
Eval num_timesteps=5496000, episode_reward=697.00 +/- 0.00
Episode length: 69.00 +/- 0.00
Eval num_timesteps=5520000, episode_reward=701.00 +/- 0.00
Episode length: 71.00 +/- 0.00
Eval num_timesteps=5544000, episode_reward=701.00 +/- 0.00
Episode length: 71.00 +/- 0.00
Eval num_timesteps=5568000, episode_reward=701.00 +/- 0.00
Episode length: 71.00 +/- 0.00
Eval num_timesteps=5592000, episode_reward=701.00 +/- 0.00
Episode length: 71.00 +/- 0.00
Eval num_timesteps=5616000, episode_reward=701.00 +/- 0.00
Episode length: 71.00 +/- 0.00
Eval num_timesteps=5640000, episode_reward=701.00 +/- 0.00
Episode length: 71.00 +/- 0.00
Eval num_timesteps=5664000, episode_reward=701.00 +/- 0.00
Episode length: 70.00 +/- 0.00
Eval num_timesteps=5688000, episode_reward=701.00 +/- 0.00
Episode length: 70.00 +/- 0.00
Eval num_timesteps=5712000, episode_reward=710.00 +/- 0.00
Episode length: 71.00 +/- 0.00
Eval num_timesteps=5736000, episode_reward=710.00 +/- 0.00
Episode length: 71.00 +/- 0.00
Eval num_timesteps=5760000, episode_reward=710.00 +/- 0.00
Episode length: 71.00 +/- 0.00
Eval num_timesteps=5784000, episode_reward=710.00 +/- 0.00
Episode length: 71.00 +/- 0.00
Eval num_timesteps=5808000, episode_reward=710.00 +/- 0.00
Episode length: 71.00 +/- 0.00
Eval num_timesteps=5832000, episode_reward=710.00 +/- 0.00
Episode length: 71.00 +/- 0.00
Eval num_timesteps=5856000, episode_reward=710.00 +/- 0.00
Episode length: 71.00 +/- 0.00
Eval num_timesteps=5880000, episode_reward=710.00 +/- 0.00
Episode length: 71.00 +/- 0.00
Eval num_timesteps=5904000, episode_reward=710.00 +/- 0.00
Episode length: 71.00 +/- 0.00
Eval num_timesteps=5928000, episode_reward=710.00 +/- 0.00
Episode length: 71.00 +/- 0.00
Eval num_timesteps=5952000, episode_reward=710.00 +/- 0.00
Episode length: 71.00 +/- 0.00
Eval num_timesteps=5976000, episode_reward=710.00 +/- 0.00
Episode length: 71.00 +/- 0.00
Eval num_timesteps=6000000, episode_reward=711.00 +/- 0.00
Episode length: 70.00 +/- 0.00
Eval num_timesteps=6024000, episode_reward=711.00 +/- 0.00
Episode length: 70.00 +/- 0.00
Eval num_timesteps=6048000, episode_reward=-47.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=6072000, episode_reward=-47.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=6096000, episode_reward=-51.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=6120000, episode_reward=-51.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=6144000, episode_reward=-51.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=6168000, episode_reward=-50.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=6192000, episode_reward=-50.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=6216000, episode_reward=-50.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=6240000, episode_reward=-50.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=6264000, episode_reward=-50.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=6288000, episode_reward=-50.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=6312000, episode_reward=-50.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=6336000, episode_reward=-50.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=6360000, episode_reward=235.00 +/- 0.00
Episode length: 38.00 +/- 0.00
Eval num_timesteps=6384000, episode_reward=235.00 +/- 0.00
Episode length: 38.00 +/- 0.00
Eval num_timesteps=6408000, episode_reward=220.00 +/- 0.00
Episode length: 32.00 +/- 0.00
Eval num_timesteps=6432000, episode_reward=220.00 +/- 0.00
Episode length: 32.00 +/- 0.00
Eval num_timesteps=6456000, episode_reward=635.00 +/- 0.00
Episode length: 110.00 +/- 0.00
Eval num_timesteps=6480000, episode_reward=635.00 +/- 0.00
Episode length: 110.00 +/- 0.00
Eval num_timesteps=6504000, episode_reward=702.00 +/- 0.00
Episode length: 100.00 +/- 0.00
Eval num_timesteps=6528000, episode_reward=702.00 +/- 0.00
Episode length: 100.00 +/- 0.00
Eval num_timesteps=6552000, episode_reward=581.00 +/- 0.00
Episode length: 95.00 +/- 0.00
Eval num_timesteps=6576000, episode_reward=581.00 +/- 0.00
Episode length: 95.00 +/- 0.00
Eval num_timesteps=6600000, episode_reward=558.00 +/- 0.00
Episode length: 85.00 +/- 0.00
Eval num_timesteps=6624000, episode_reward=558.00 +/- 0.00
Episode length: 85.00 +/- 0.00
Eval num_timesteps=6648000, episode_reward=699.00 +/- 0.00
Episode length: 101.00 +/- 0.00
Eval num_timesteps=6672000, episode_reward=699.00 +/- 0.00
Episode length: 101.00 +/- 0.00
Eval num_timesteps=6696000, episode_reward=672.00 +/- 0.00
Episode length: 98.00 +/- 0.00
Eval num_timesteps=6720000, episode_reward=672.00 +/- 0.00
Episode length: 98.00 +/- 0.00
Eval num_timesteps=6744000, episode_reward=852.00 +/- 0.00
Episode length: 118.00 +/- 0.00
New best mean reward!
Eval num_timesteps=6768000, episode_reward=852.00 +/- 0.00
Episode length: 118.00 +/- 0.00
Eval num_timesteps=6792000, episode_reward=854.00 +/- 0.00
Episode length: 118.00 +/- 0.00
New best mean reward!
Eval num_timesteps=6816000, episode_reward=854.00 +/- 0.00
Episode length: 118.00 +/- 0.00
Eval num_timesteps=6840000, episode_reward=885.00 +/- 0.00
Episode length: 117.00 +/- 0.00
New best mean reward!
Eval num_timesteps=6864000, episode_reward=885.00 +/- 0.00
Episode length: 117.00 +/- 0.00
Eval num_timesteps=6888000, episode_reward=885.00 +/- 0.00
Episode length: 117.00 +/- 0.00
Eval num_timesteps=6912000, episode_reward=885.00 +/- 0.00
Episode length: 117.00 +/- 0.00
Eval num_timesteps=6936000, episode_reward=885.00 +/- 0.00
Episode length: 117.00 +/- 0.00
Eval num_timesteps=6960000, episode_reward=885.00 +/- 0.00
Episode length: 117.00 +/- 0.00
Eval num_timesteps=6984000, episode_reward=1139.00 +/- 0.00
Episode length: 143.00 +/- 0.00
New best mean reward!
Eval num_timesteps=7008000, episode_reward=1139.00 +/- 0.00
Episode length: 143.00 +/- 0.00
Eval num_timesteps=7032000, episode_reward=1179.00 +/- 0.00
Episode length: 143.00 +/- 0.00
New best mean reward!
Eval num_timesteps=7056000, episode_reward=1179.00 +/- 0.00
Episode length: 143.00 +/- 0.00
Eval num_timesteps=7080000, episode_reward=1179.00 +/- 0.00
Episode length: 143.00 +/- 0.00
Eval num_timesteps=7104000, episode_reward=1179.00 +/- 0.00
Episode length: 143.00 +/- 0.00
Eval num_timesteps=7128000, episode_reward=341.00 +/- 0.00
Episode length: 45.00 +/- 0.00
Eval num_timesteps=7152000, episode_reward=341.00 +/- 0.00
Episode length: 45.00 +/- 0.00
Eval num_timesteps=7176000, episode_reward=341.00 +/- 0.00
Episode length: 45.00 +/- 0.00
Eval num_timesteps=7200000, episode_reward=1404.00 +/- 0.00
Episode length: 164.00 +/- 0.00
New best mean reward!
Eval num_timesteps=7224000, episode_reward=1404.00 +/- 0.00
Episode length: 164.00 +/- 0.00
Eval num_timesteps=7248000, episode_reward=1404.00 +/- 0.00
Episode length: 164.00 +/- 0.00
Eval num_timesteps=7272000, episode_reward=1404.00 +/- 0.00
Episode length: 164.00 +/- 0.00
Eval num_timesteps=7296000, episode_reward=1404.00 +/- 0.00
Episode length: 163.00 +/- 0.00
Eval num_timesteps=7320000, episode_reward=1404.00 +/- 0.00
Episode length: 163.00 +/- 0.00
Eval num_timesteps=7344000, episode_reward=672.00 +/- 0.00
Episode length: 97.00 +/- 0.00
Eval num_timesteps=7368000, episode_reward=672.00 +/- 0.00
Episode length: 97.00 +/- 0.00
Eval num_timesteps=7392000, episode_reward=1404.00 +/- 0.00
Episode length: 163.00 +/- 0.00
Eval num_timesteps=7416000, episode_reward=1404.00 +/- 0.00
Episode length: 163.00 +/- 0.00
Eval num_timesteps=7440000, episode_reward=1404.00 +/- 0.00
Episode length: 163.00 +/- 0.00
Eval num_timesteps=7464000, episode_reward=1404.00 +/- 0.00
Episode length: 163.00 +/- 0.00
Eval num_timesteps=7488000, episode_reward=1511.00 +/- 0.00
Episode length: 172.00 +/- 0.00
New best mean reward!
Eval num_timesteps=7512000, episode_reward=1511.00 +/- 0.00
Episode length: 172.00 +/- 0.00
Eval num_timesteps=7536000, episode_reward=1403.00 +/- 0.00
Episode length: 164.00 +/- 0.00
Eval num_timesteps=7560000, episode_reward=1403.00 +/- 0.00
Episode length: 164.00 +/- 0.00
Eval num_timesteps=7584000, episode_reward=1404.00 +/- 0.00
Episode length: 164.00 +/- 0.00
Eval num_timesteps=7608000, episode_reward=1404.00 +/- 0.00
Episode length: 164.00 +/- 0.00
Eval num_timesteps=7632000, episode_reward=1580.00 +/- 0.00
Episode length: 183.00 +/- 0.00
New best mean reward!
Eval num_timesteps=7656000, episode_reward=1580.00 +/- 0.00
Episode length: 183.00 +/- 0.00
Eval num_timesteps=7680000, episode_reward=1639.00 +/- 0.00
Episode length: 184.00 +/- 0.00
New best mean reward!
Eval num_timesteps=7704000, episode_reward=1639.00 +/- 0.00
Episode length: 184.00 +/- 0.00
Eval num_timesteps=7728000, episode_reward=1578.00 +/- 0.00
Episode length: 183.00 +/- 0.00
Eval num_timesteps=7752000, episode_reward=1578.00 +/- 0.00
Episode length: 183.00 +/- 0.00
Eval num_timesteps=7776000, episode_reward=1851.00 +/- 0.00
Episode length: 208.00 +/- 0.00
New best mean reward!
Eval num_timesteps=7800000, episode_reward=1851.00 +/- 0.00
Episode length: 208.00 +/- 0.00
Eval num_timesteps=7824000, episode_reward=1959.00 +/- 0.00
Episode length: 222.00 +/- 0.00
New best mean reward!
Eval num_timesteps=7848000, episode_reward=1959.00 +/- 0.00
Episode length: 222.00 +/- 0.00
Eval num_timesteps=7872000, episode_reward=1959.00 +/- 0.00
Episode length: 222.00 +/- 0.00
Eval num_timesteps=7896000, episode_reward=1959.00 +/- 0.00
Episode length: 222.00 +/- 0.00
Eval num_timesteps=7920000, episode_reward=1877.00 +/- 0.00
Episode length: 209.00 +/- 0.00
Eval num_timesteps=7944000, episode_reward=1877.00 +/- 0.00
Episode length: 209.00 +/- 0.00
Eval num_timesteps=7968000, episode_reward=2327.00 +/- 0.00
Episode length: 263.00 +/- 0.00
New best mean reward!
Eval num_timesteps=7992000, episode_reward=2327.00 +/- 0.00
Episode length: 263.00 +/- 0.00
Eval num_timesteps=8016000, episode_reward=2083.00 +/- 0.00
Episode length: 283.00 +/- 0.00
Eval num_timesteps=8040000, episode_reward=2083.00 +/- 0.00
Episode length: 283.00 +/- 0.00
Eval num_timesteps=8064000, episode_reward=2083.00 +/- 0.00
Episode length: 283.00 +/- 0.00
Eval num_timesteps=8088000, episode_reward=2083.00 +/- 0.00
Episode length: 283.00 +/- 0.00
Eval num_timesteps=8112000, episode_reward=2329.00 +/- 0.00
Episode length: 285.00 +/- 0.00
New best mean reward!
Eval num_timesteps=8136000, episode_reward=2329.00 +/- 0.00
Episode length: 285.00 +/- 0.00
Eval num_timesteps=8160000, episode_reward=1810.00 +/- 0.00
Episode length: 200.00 +/- 0.00
Eval num_timesteps=8184000, episode_reward=1810.00 +/- 0.00
Episode length: 200.00 +/- 0.00
Eval num_timesteps=8208000, episode_reward=1810.00 +/- 0.00
Episode length: 200.00 +/- 0.00
Eval num_timesteps=8232000, episode_reward=2083.00 +/- 0.00
Episode length: 283.00 +/- 0.00
Eval num_timesteps=8256000, episode_reward=2083.00 +/- 0.00
Episode length: 283.00 +/- 0.00
Eval num_timesteps=8280000, episode_reward=2018.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=8304000, episode_reward=2018.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=8328000, episode_reward=2083.00 +/- 0.00
Episode length: 283.00 +/- 0.00
Eval num_timesteps=8352000, episode_reward=2083.00 +/- 0.00
Episode length: 283.00 +/- 0.00
Eval num_timesteps=8376000, episode_reward=1810.00 +/- 0.00
Episode length: 199.00 +/- 0.00
Eval num_timesteps=8400000, episode_reward=1810.00 +/- 0.00
Episode length: 199.00 +/- 0.00
Eval num_timesteps=8424000, episode_reward=1908.00 +/- 0.00
Episode length: 209.00 +/- 0.00
Eval num_timesteps=8448000, episode_reward=1908.00 +/- 0.00
Episode length: 209.00 +/- 0.00
Eval num_timesteps=8472000, episode_reward=2018.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=8496000, episode_reward=2018.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=8520000, episode_reward=2290.00 +/- 0.00
Episode length: 478.00 +/- 0.00
Eval num_timesteps=8544000, episode_reward=2290.00 +/- 0.00
Episode length: 478.00 +/- 0.00
Eval num_timesteps=8568000, episode_reward=2330.00 +/- 0.00
Episode length: 277.00 +/- 0.00
New best mean reward!
Eval num_timesteps=8592000, episode_reward=2330.00 +/- 0.00
Episode length: 277.00 +/- 0.00
Eval num_timesteps=8616000, episode_reward=2327.00 +/- 0.00
Episode length: 295.00 +/- 0.00
Eval num_timesteps=8640000, episode_reward=2327.00 +/- 0.00
Episode length: 295.00 +/- 0.00
Eval num_timesteps=8664000, episode_reward=330.00 +/- 0.00
Episode length: 56.00 +/- 0.00
Eval num_timesteps=8688000, episode_reward=330.00 +/- 0.00
Episode length: 56.00 +/- 0.00
Eval num_timesteps=8712000, episode_reward=555.00 +/- 0.00
Episode length: 85.00 +/- 0.00
Eval num_timesteps=8736000, episode_reward=555.00 +/- 0.00
Episode length: 85.00 +/- 0.00
Eval num_timesteps=8760000, episode_reward=673.00 +/- 0.00
Episode length: 68.00 +/- 0.00
Eval num_timesteps=8784000, episode_reward=673.00 +/- 0.00
Episode length: 68.00 +/- 0.00
Eval num_timesteps=8808000, episode_reward=668.00 +/- 0.00
Episode length: 109.00 +/- 0.00
Eval num_timesteps=8832000, episode_reward=668.00 +/- 0.00
Episode length: 109.00 +/- 0.00
Eval num_timesteps=8856000, episode_reward=240.00 +/- 0.00
Episode length: 39.00 +/- 0.00
Eval num_timesteps=8880000, episode_reward=240.00 +/- 0.00
Episode length: 39.00 +/- 0.00
Eval num_timesteps=8904000, episode_reward=341.00 +/- 0.00
Episode length: 47.00 +/- 0.00
Eval num_timesteps=8928000, episode_reward=341.00 +/- 0.00
Episode length: 47.00 +/- 0.00
Eval num_timesteps=8952000, episode_reward=675.00 +/- 0.00
Episode length: 73.00 +/- 0.00
Eval num_timesteps=8976000, episode_reward=675.00 +/- 0.00
Episode length: 73.00 +/- 0.00
Eval num_timesteps=9000000, episode_reward=708.00 +/- 0.00
Episode length: 80.00 +/- 0.00
Eval num_timesteps=9024000, episode_reward=708.00 +/- 0.00
Episode length: 80.00 +/- 0.00
Eval num_timesteps=9048000, episode_reward=674.00 +/- 0.00
Episode length: 76.00 +/- 0.00
Eval num_timesteps=9072000, episode_reward=674.00 +/- 0.00
Episode length: 76.00 +/- 0.00
Eval num_timesteps=9096000, episode_reward=703.00 +/- 0.00
Episode length: 79.00 +/- 0.00
Eval num_timesteps=9120000, episode_reward=703.00 +/- 0.00
Episode length: 79.00 +/- 0.00
Eval num_timesteps=9144000, episode_reward=703.00 +/- 0.00
Episode length: 79.00 +/- 0.00
Eval num_timesteps=9168000, episode_reward=703.00 +/- 0.00
Episode length: 79.00 +/- 0.00
Eval num_timesteps=9192000, episode_reward=672.00 +/- 0.00
Episode length: 67.00 +/- 0.00
Eval num_timesteps=9216000, episode_reward=672.00 +/- 0.00
Episode length: 67.00 +/- 0.00
Eval num_timesteps=9240000, episode_reward=672.00 +/- 0.00
Episode length: 67.00 +/- 0.00
Eval num_timesteps=9264000, episode_reward=672.00 +/- 0.00
Episode length: 67.00 +/- 0.00
Eval num_timesteps=9288000, episode_reward=672.00 +/- 0.00
Episode length: 67.00 +/- 0.00
Eval num_timesteps=9312000, episode_reward=708.00 +/- 0.00
Episode length: 70.00 +/- 0.00
Eval num_timesteps=9336000, episode_reward=708.00 +/- 0.00
Episode length: 70.00 +/- 0.00
Eval num_timesteps=9360000, episode_reward=708.00 +/- 0.00
Episode length: 70.00 +/- 0.00
Eval num_timesteps=9384000, episode_reward=708.00 +/- 0.00
Episode length: 70.00 +/- 0.00
Eval num_timesteps=9408000, episode_reward=675.00 +/- 0.00
Episode length: 67.00 +/- 0.00
Eval num_timesteps=9432000, episode_reward=675.00 +/- 0.00
Episode length: 67.00 +/- 0.00
Eval num_timesteps=9456000, episode_reward=699.00 +/- 0.00
Episode length: 69.00 +/- 0.00
Eval num_timesteps=9480000, episode_reward=699.00 +/- 0.00
Episode length: 69.00 +/- 0.00
Eval num_timesteps=9504000, episode_reward=708.00 +/- 0.00
Episode length: 70.00 +/- 0.00
Eval num_timesteps=9528000, episode_reward=708.00 +/- 0.00
Episode length: 70.00 +/- 0.00
Eval num_timesteps=9552000, episode_reward=708.00 +/- 0.00
Episode length: 70.00 +/- 0.00
Eval num_timesteps=9576000, episode_reward=708.00 +/- 0.00
Episode length: 70.00 +/- 0.00
Eval num_timesteps=9600000, episode_reward=557.00 +/- 0.00
Episode length: 57.00 +/- 0.00
Eval num_timesteps=9624000, episode_reward=557.00 +/- 0.00
Episode length: 57.00 +/- 0.00
Eval num_timesteps=9648000, episode_reward=708.00 +/- 0.00
Episode length: 70.00 +/- 0.00
Eval num_timesteps=9672000, episode_reward=708.00 +/- 0.00
Episode length: 70.00 +/- 0.00
Eval num_timesteps=9696000, episode_reward=708.00 +/- 0.00
Episode length: 70.00 +/- 0.00
Eval num_timesteps=9720000, episode_reward=708.00 +/- 0.00
Episode length: 70.00 +/- 0.00
Eval num_timesteps=9744000, episode_reward=708.00 +/- 0.00
Episode length: 70.00 +/- 0.00
Eval num_timesteps=9768000, episode_reward=708.00 +/- 0.00
Episode length: 70.00 +/- 0.00
Eval num_timesteps=9792000, episode_reward=708.00 +/- 0.00
Episode length: 70.00 +/- 0.00
Eval num_timesteps=9816000, episode_reward=708.00 +/- 0.00
Episode length: 70.00 +/- 0.00
Eval num_timesteps=9840000, episode_reward=708.00 +/- 0.00
Episode length: 70.00 +/- 0.00
Eval num_timesteps=9864000, episode_reward=708.00 +/- 0.00
Episode length: 70.00 +/- 0.00
Eval num_timesteps=9888000, episode_reward=708.00 +/- 0.00
Episode length: 70.00 +/- 0.00
Eval num_timesteps=9912000, episode_reward=708.00 +/- 0.00
Episode length: 70.00 +/- 0.00
Eval num_timesteps=9936000, episode_reward=355.00 +/- 0.00
Episode length: 39.00 +/- 0.00
Eval num_timesteps=9960000, episode_reward=355.00 +/- 0.00
Episode length: 39.00 +/- 0.00
Eval num_timesteps=9984000, episode_reward=559.00 +/- 0.00
Episode length: 57.00 +/- 0.00
Eval num_timesteps=10008000, episode_reward=559.00 +/- 0.00
Episode length: 57.00 +/- 0.00
 100% ━━━━━━━━━━━━━━━━━━ 10,027,008/10,00… [ 1 day, 8:46:27 < 0:00:00 , ? it/s ]
