/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/envs/registration.py:555: UserWarning: [33mWARN: The environment SuperMarioBros-2-3-v0 is out of date. You should consider upgrading to version `v3`.[0m
  logger.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/envs/registration.py:555: UserWarning: [33mWARN: The environment SuperMarioBros-2-3-v0 is out of date. You should consider upgrading to version `v3`.[0m
  logger.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/envs/registration.py:555: UserWarning: [33mWARN: The environment SuperMarioBros-2-3-v0 is out of date. You should consider upgrading to version `v3`.[0m
  logger.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/envs/registration.py:555: UserWarning: [33mWARN: The environment SuperMarioBros-2-3-v0 is out of date. You should consider upgrading to version `v3`.[0m
  logger.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/envs/registration.py:555: UserWarning: [33mWARN: The environment SuperMarioBros-2-3-v0 is out of date. You should consider upgrading to version `v3`.[0m
  logger.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/envs/registration.py:555: UserWarning: [33mWARN: The environment SuperMarioBros-2-3-v0 is out of date. You should consider upgrading to version `v3`.[0m
  logger.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/envs/registration.py:555: UserWarning: [33mWARN: The environment SuperMarioBros-2-3-v0 is out of date. You should consider upgrading to version `v3`.[0m
  logger.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/envs/registration.py:555: UserWarning: [33mWARN: The environment SuperMarioBros-2-3-v0 is out of date. You should consider upgrading to version `v3`.[0m
  logger.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/envs/registration.py:555: UserWarning: [33mWARN: The environment SuperMarioBros-2-3-v0 is out of date. You should consider upgrading to version `v3`.[0m
  logger.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/envs/registration.py:555: UserWarning: [33mWARN: The environment SuperMarioBros-2-3-v0 is out of date. You should consider upgrading to version `v3`.[0m
  logger.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/envs/registration.py:555: UserWarning: [33mWARN: The environment SuperMarioBros-2-3-v0 is out of date. You should consider upgrading to version `v3`.[0m
  logger.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/envs/registration.py:555: UserWarning: [33mWARN: The environment SuperMarioBros-2-3-v0 is out of date. You should consider upgrading to version `v3`.[0m
  logger.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/envs/registration.py:555: UserWarning: [33mWARN: The environment SuperMarioBros-2-3-v0 is out of date. You should consider upgrading to version `v3`.[0m
  logger.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/envs/registration.py:555: UserWarning: [33mWARN: The environment SuperMarioBros-2-3-v0 is out of date. You should consider upgrading to version `v3`.[0m
  logger.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/envs/registration.py:555: UserWarning: [33mWARN: The environment SuperMarioBros-2-3-v0 is out of date. You should consider upgrading to version `v3`.[0m
  logger.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/envs/registration.py:555: UserWarning: [33mWARN: The environment SuperMarioBros-2-3-v0 is out of date. You should consider upgrading to version `v3`.[0m
  logger.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/envs/registration.py:555: UserWarning: [33mWARN: The environment SuperMarioBros-2-3-v0 is out of date. You should consider upgrading to version `v3`.[0m
  logger.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/envs/registration.py:555: UserWarning: [33mWARN: The environment SuperMarioBros-2-3-v0 is out of date. You should consider upgrading to version `v3`.[0m
  logger.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/envs/registration.py:555: UserWarning: [33mWARN: The environment SuperMarioBros-2-3-v0 is out of date. You should consider upgrading to version `v3`.[0m
  logger.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/envs/registration.py:555: UserWarning: [33mWARN: The environment SuperMarioBros-2-3-v0 is out of date. You should consider upgrading to version `v3`.[0m
  logger.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/envs/registration.py:555: UserWarning: [33mWARN: The environment SuperMarioBros-2-3-v0 is out of date. You should consider upgrading to version `v3`.[0m
  logger.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/envs/registration.py:555: UserWarning: [33mWARN: The environment SuperMarioBros-2-3-v0 is out of date. You should consider upgrading to version `v3`.[0m
  logger.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/envs/registration.py:555: UserWarning: [33mWARN: The environment SuperMarioBros-2-3-v0 is out of date. You should consider upgrading to version `v3`.[0m
  logger.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/envs/registration.py:555: UserWarning: [33mWARN: The environment SuperMarioBros-2-3-v0 is out of date. You should consider upgrading to version `v3`.[0m
  logger.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.
  warnings.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.
  warnings.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.
  warnings.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.
  warnings.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.
  warnings.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.
  warnings.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.
  warnings.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.
  warnings.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.
  warnings.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.
  warnings.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.
  warnings.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.
  warnings.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.
  warnings.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.
  warnings.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.
  warnings.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.
  warnings.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.
  warnings.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.
  warnings.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.
  warnings.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.
  warnings.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.
  warnings.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.
  warnings.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.
  warnings.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.
  warnings.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/stable_baselines3/common/callbacks.py:403: UserWarning: Training and eval env are not of the same type<stable_baselines3.common.vec_env.vec_transpose.VecTransposeImage object at 0x14649d8b72b0> != <stable_baselines3.common.vec_env.vec_monitor.VecMonitor object at 0x14649d8b5ab0>
  warnings.warn("Training and eval env are not of the same type" f"{self.training_env} != {self.eval_env}")
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(terminated, (bool, np.bool8)):
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(terminated, (bool, np.bool8)):
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(terminated, (bool, np.bool8)):
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(terminated, (bool, np.bool8)):
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(terminated, (bool, np.bool8)):
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(terminated, (bool, np.bool8)):
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(terminated, (bool, np.bool8)):
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(terminated, (bool, np.bool8)):
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(terminated, (bool, np.bool8)):
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(terminated, (bool, np.bool8)):
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(terminated, (bool, np.bool8)):
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(terminated, (bool, np.bool8)):
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(terminated, (bool, np.bool8)):
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(terminated, (bool, np.bool8)):
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(terminated, (bool, np.bool8)):
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(terminated, (bool, np.bool8)):
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(terminated, (bool, np.bool8)):
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(terminated, (bool, np.bool8)):
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(terminated, (bool, np.bool8)):
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(terminated, (bool, np.bool8)):
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(terminated, (bool, np.bool8)):
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(terminated, (bool, np.bool8)):
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(terminated, (bool, np.bool8)):
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(terminated, (bool, np.bool8)):
Training model!
World: 2
Stage: 3
Vectors: 24
Steps: 10000000
Learning rate: 0.0003
Eval num_timesteps=24000, episode_reward=-203.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
New best mean reward!
Eval num_timesteps=48000, episode_reward=-203.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=72000, episode_reward=980.00 +/- 0.00
Episode length: 217.00 +/- 0.00
New best mean reward!
Eval num_timesteps=96000, episode_reward=980.00 +/- 0.00
Episode length: 217.00 +/- 0.00
Eval num_timesteps=120000, episode_reward=645.00 +/- 0.00
Episode length: 66.00 +/- 0.00
Eval num_timesteps=144000, episode_reward=645.00 +/- 0.00
Episode length: 66.00 +/- 0.00
Eval num_timesteps=168000, episode_reward=590.00 +/- 0.00
Episode length: 66.00 +/- 0.00
Eval num_timesteps=192000, episode_reward=590.00 +/- 0.00
Episode length: 66.00 +/- 0.00
Eval num_timesteps=216000, episode_reward=-94.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=240000, episode_reward=-94.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=264000, episode_reward=-94.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=288000, episode_reward=-94.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=312000, episode_reward=-94.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=336000, episode_reward=-94.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=360000, episode_reward=-94.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=384000, episode_reward=-94.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=408000, episode_reward=-94.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=432000, episode_reward=-94.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=456000, episode_reward=-94.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=480000, episode_reward=-94.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=504000, episode_reward=-94.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=528000, episode_reward=-94.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=552000, episode_reward=-94.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=576000, episode_reward=-94.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=600000, episode_reward=-94.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=624000, episode_reward=-94.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=648000, episode_reward=-94.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=672000, episode_reward=-94.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=696000, episode_reward=-94.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=720000, episode_reward=-94.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=744000, episode_reward=-94.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=768000, episode_reward=-94.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=792000, episode_reward=-94.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=816000, episode_reward=-94.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=840000, episode_reward=-94.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=864000, episode_reward=-94.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=888000, episode_reward=-94.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=912000, episode_reward=-94.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=936000, episode_reward=-94.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=960000, episode_reward=-94.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=984000, episode_reward=-94.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=1008000, episode_reward=-94.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=1032000, episode_reward=-94.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=1056000, episode_reward=-94.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=1080000, episode_reward=-94.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=1104000, episode_reward=-94.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=1128000, episode_reward=-94.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=1152000, episode_reward=-94.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=1176000, episode_reward=-94.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=1200000, episode_reward=-94.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=1224000, episode_reward=-94.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=1248000, episode_reward=-94.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=1272000, episode_reward=-94.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=1296000, episode_reward=-78.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=1320000, episode_reward=-78.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=1344000, episode_reward=-94.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=1368000, episode_reward=-94.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=1392000, episode_reward=-94.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=1416000, episode_reward=-94.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=1440000, episode_reward=-94.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=1464000, episode_reward=-94.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=1488000, episode_reward=993.00 +/- 0.00
Episode length: 152.00 +/- 0.00
New best mean reward!
Eval num_timesteps=1512000, episode_reward=993.00 +/- 0.00
Episode length: 152.00 +/- 0.00
Eval num_timesteps=1536000, episode_reward=108.00 +/- 0.00
Episode length: 79.00 +/- 0.00
Eval num_timesteps=1560000, episode_reward=108.00 +/- 0.00
Episode length: 79.00 +/- 0.00
Eval num_timesteps=1584000, episode_reward=1083.00 +/- 0.00
Episode length: 108.00 +/- 0.00
New best mean reward!
Eval num_timesteps=1608000, episode_reward=1083.00 +/- 0.00
Episode length: 108.00 +/- 0.00
Eval num_timesteps=1632000, episode_reward=108.00 +/- 0.00
Episode length: 79.00 +/- 0.00
Eval num_timesteps=1656000, episode_reward=108.00 +/- 0.00
Episode length: 79.00 +/- 0.00
Eval num_timesteps=1680000, episode_reward=999.00 +/- 0.00
Episode length: 126.00 +/- 0.00
Eval num_timesteps=1704000, episode_reward=999.00 +/- 0.00
Episode length: 126.00 +/- 0.00
Eval num_timesteps=1728000, episode_reward=1248.00 +/- 0.00
Episode length: 162.00 +/- 0.00
New best mean reward!
Eval num_timesteps=1752000, episode_reward=1248.00 +/- 0.00
Episode length: 162.00 +/- 0.00
Eval num_timesteps=1776000, episode_reward=1487.00 +/- 0.00
Episode length: 166.00 +/- 0.00
New best mean reward!
Eval num_timesteps=1800000, episode_reward=1487.00 +/- 0.00
Episode length: 166.00 +/- 0.00
Eval num_timesteps=1824000, episode_reward=-94.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=1848000, episode_reward=-94.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=1872000, episode_reward=-94.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=1896000, episode_reward=-94.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=1920000, episode_reward=-94.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=1944000, episode_reward=-94.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=1968000, episode_reward=-78.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=1992000, episode_reward=-78.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=2016000, episode_reward=1253.00 +/- 0.00
Episode length: 140.00 +/- 0.00
Eval num_timesteps=2040000, episode_reward=1253.00 +/- 0.00
Episode length: 140.00 +/- 0.00
Eval num_timesteps=2064000, episode_reward=1253.00 +/- 0.00
Episode length: 140.00 +/- 0.00
Eval num_timesteps=2088000, episode_reward=1693.00 +/- 0.00
Episode length: 184.00 +/- 0.00
New best mean reward!
Eval num_timesteps=2112000, episode_reward=1693.00 +/- 0.00
Episode length: 184.00 +/- 0.00
Eval num_timesteps=2136000, episode_reward=1700.00 +/- 0.00
Episode length: 181.00 +/- 0.00
New best mean reward!
Eval num_timesteps=2160000, episode_reward=1700.00 +/- 0.00
Episode length: 181.00 +/- 0.00
Eval num_timesteps=2184000, episode_reward=1253.00 +/- 0.00
Episode length: 140.00 +/- 0.00
Eval num_timesteps=2208000, episode_reward=1253.00 +/- 0.00
Episode length: 140.00 +/- 0.00
Eval num_timesteps=2232000, episode_reward=1253.00 +/- 0.00
Episode length: 140.00 +/- 0.00
Eval num_timesteps=2256000, episode_reward=1253.00 +/- 0.00
Episode length: 140.00 +/- 0.00
Eval num_timesteps=2280000, episode_reward=1253.00 +/- 0.00
Episode length: 140.00 +/- 0.00
Eval num_timesteps=2304000, episode_reward=1253.00 +/- 0.00
Episode length: 140.00 +/- 0.00
Eval num_timesteps=2328000, episode_reward=577.00 +/- 0.00
Episode length: 80.00 +/- 0.00
Eval num_timesteps=2352000, episode_reward=577.00 +/- 0.00
Episode length: 80.00 +/- 0.00
Eval num_timesteps=2376000, episode_reward=998.00 +/- 0.00
Episode length: 129.00 +/- 0.00
Eval num_timesteps=2400000, episode_reward=998.00 +/- 0.00
Episode length: 129.00 +/- 0.00
Eval num_timesteps=2424000, episode_reward=489.00 +/- 0.00
Episode length: 74.00 +/- 0.00
Eval num_timesteps=2448000, episode_reward=489.00 +/- 0.00
Episode length: 74.00 +/- 0.00
Eval num_timesteps=2472000, episode_reward=1002.00 +/- 0.00
Episode length: 119.00 +/- 0.00
Eval num_timesteps=2496000, episode_reward=1002.00 +/- 0.00
Episode length: 119.00 +/- 0.00
Eval num_timesteps=2520000, episode_reward=997.00 +/- 0.00
Episode length: 143.00 +/- 0.00
Eval num_timesteps=2544000, episode_reward=997.00 +/- 0.00
Episode length: 143.00 +/- 0.00
Eval num_timesteps=2568000, episode_reward=998.00 +/- 0.00
Episode length: 132.00 +/- 0.00
Eval num_timesteps=2592000, episode_reward=998.00 +/- 0.00
Episode length: 132.00 +/- 0.00
Eval num_timesteps=2616000, episode_reward=996.00 +/- 0.00
Episode length: 141.00 +/- 0.00
Eval num_timesteps=2640000, episode_reward=996.00 +/- 0.00
Episode length: 141.00 +/- 0.00
Eval num_timesteps=2664000, episode_reward=996.00 +/- 0.00
Episode length: 134.00 +/- 0.00
Eval num_timesteps=2688000, episode_reward=996.00 +/- 0.00
Episode length: 134.00 +/- 0.00
Eval num_timesteps=2712000, episode_reward=-78.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=2736000, episode_reward=-78.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=2760000, episode_reward=-94.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=2784000, episode_reward=-94.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=2808000, episode_reward=999.00 +/- 0.00
Episode length: 130.00 +/- 0.00
Eval num_timesteps=2832000, episode_reward=999.00 +/- 0.00
Episode length: 130.00 +/- 0.00
Eval num_timesteps=2856000, episode_reward=-94.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=2880000, episode_reward=-94.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=2904000, episode_reward=-94.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=2928000, episode_reward=-94.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=2952000, episode_reward=-94.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=2976000, episode_reward=-94.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=3000000, episode_reward=-94.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=3024000, episode_reward=-94.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=3048000, episode_reward=-94.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=3072000, episode_reward=-94.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=3096000, episode_reward=-94.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=3120000, episode_reward=-94.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=3144000, episode_reward=-94.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=3168000, episode_reward=-94.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=3192000, episode_reward=-94.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=3216000, episode_reward=109.00 +/- 0.00
Episode length: 73.00 +/- 0.00
Eval num_timesteps=3240000, episode_reward=109.00 +/- 0.00
Episode length: 73.00 +/- 0.00
Eval num_timesteps=3264000, episode_reward=-94.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=3288000, episode_reward=-94.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=3312000, episode_reward=916.00 +/- 0.00
Episode length: 175.00 +/- 0.00
Eval num_timesteps=3336000, episode_reward=916.00 +/- 0.00
Episode length: 175.00 +/- 0.00
Eval num_timesteps=3360000, episode_reward=-78.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=3384000, episode_reward=-78.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=3408000, episode_reward=677.00 +/- 0.00
Episode length: 162.00 +/- 0.00
Eval num_timesteps=3432000, episode_reward=677.00 +/- 0.00
Episode length: 162.00 +/- 0.00
Eval num_timesteps=3456000, episode_reward=984.00 +/- 0.00
Episode length: 203.00 +/- 0.00
Eval num_timesteps=3480000, episode_reward=984.00 +/- 0.00
Episode length: 203.00 +/- 0.00
Eval num_timesteps=3504000, episode_reward=985.00 +/- 0.00
Episode length: 194.00 +/- 0.00
Eval num_timesteps=3528000, episode_reward=985.00 +/- 0.00
Episode length: 194.00 +/- 0.00
Eval num_timesteps=3552000, episode_reward=987.00 +/- 0.00
Episode length: 187.00 +/- 0.00
Eval num_timesteps=3576000, episode_reward=987.00 +/- 0.00
Episode length: 187.00 +/- 0.00
Eval num_timesteps=3600000, episode_reward=-94.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=3624000, episode_reward=-94.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=3648000, episode_reward=-94.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=3672000, episode_reward=-94.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=3696000, episode_reward=-94.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=3720000, episode_reward=-94.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=3744000, episode_reward=-94.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=3768000, episode_reward=-94.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=3792000, episode_reward=-94.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=3816000, episode_reward=-94.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=3840000, episode_reward=-94.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=3864000, episode_reward=-94.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=3888000, episode_reward=-94.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=3912000, episode_reward=-94.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=3936000, episode_reward=96.00 +/- 0.00
Episode length: 138.00 +/- 0.00
Eval num_timesteps=3960000, episode_reward=96.00 +/- 0.00
Episode length: 138.00 +/- 0.00
Eval num_timesteps=3984000, episode_reward=991.00 +/- 0.00
Episode length: 168.00 +/- 0.00
Eval num_timesteps=4008000, episode_reward=991.00 +/- 0.00
Episode length: 168.00 +/- 0.00
Eval num_timesteps=4032000, episode_reward=993.00 +/- 0.00
Episode length: 158.00 +/- 0.00
Eval num_timesteps=4056000, episode_reward=993.00 +/- 0.00
Episode length: 158.00 +/- 0.00
Eval num_timesteps=4080000, episode_reward=994.00 +/- 0.00
Episode length: 152.00 +/- 0.00
Eval num_timesteps=4104000, episode_reward=994.00 +/- 0.00
Episode length: 152.00 +/- 0.00
Eval num_timesteps=4128000, episode_reward=994.00 +/- 0.00
Episode length: 152.00 +/- 0.00
Eval num_timesteps=4152000, episode_reward=986.00 +/- 0.00
Episode length: 198.00 +/- 0.00
Eval num_timesteps=4176000, episode_reward=986.00 +/- 0.00
Episode length: 198.00 +/- 0.00
Eval num_timesteps=4200000, episode_reward=999.00 +/- 0.00
Episode length: 130.00 +/- 0.00
Eval num_timesteps=4224000, episode_reward=999.00 +/- 0.00
Episode length: 130.00 +/- 0.00
Eval num_timesteps=4248000, episode_reward=1000.00 +/- 0.00
Episode length: 130.00 +/- 0.00
Eval num_timesteps=4272000, episode_reward=1000.00 +/- 0.00
Episode length: 130.00 +/- 0.00
Eval num_timesteps=4296000, episode_reward=1248.00 +/- 0.00
Episode length: 157.00 +/- 0.00
Eval num_timesteps=4320000, episode_reward=1248.00 +/- 0.00
Episode length: 157.00 +/- 0.00
Eval num_timesteps=4344000, episode_reward=998.00 +/- 0.00
Episode length: 132.00 +/- 0.00
Eval num_timesteps=4368000, episode_reward=998.00 +/- 0.00
Episode length: 132.00 +/- 0.00
Eval num_timesteps=4392000, episode_reward=1180.00 +/- 0.00
Episode length: 148.00 +/- 0.00
Eval num_timesteps=4416000, episode_reward=1180.00 +/- 0.00
Episode length: 148.00 +/- 0.00
Eval num_timesteps=4440000, episode_reward=1252.00 +/- 0.00
Episode length: 146.00 +/- 0.00
Eval num_timesteps=4464000, episode_reward=1252.00 +/- 0.00
Episode length: 146.00 +/- 0.00
Eval num_timesteps=4488000, episode_reward=115.00 +/- 0.00
Episode length: 42.00 +/- 0.00
Eval num_timesteps=4512000, episode_reward=115.00 +/- 0.00
Episode length: 42.00 +/- 0.00
Eval num_timesteps=4536000, episode_reward=985.00 +/- 0.00
Episode length: 193.00 +/- 0.00
Eval num_timesteps=4560000, episode_reward=985.00 +/- 0.00
Episode length: 193.00 +/- 0.00
Eval num_timesteps=4584000, episode_reward=1491.00 +/- 0.00
Episode length: 148.00 +/- 0.00
Eval num_timesteps=4608000, episode_reward=1491.00 +/- 0.00
Episode length: 148.00 +/- 0.00
Eval num_timesteps=4632000, episode_reward=1273.00 +/- 0.00
Episode length: 125.00 +/- 0.00
Eval num_timesteps=4656000, episode_reward=1273.00 +/- 0.00
Episode length: 125.00 +/- 0.00
Eval num_timesteps=4680000, episode_reward=1254.00 +/- 0.00
Episode length: 126.00 +/- 0.00
Eval num_timesteps=4704000, episode_reward=1254.00 +/- 0.00
Episode length: 126.00 +/- 0.00
Eval num_timesteps=4728000, episode_reward=1492.00 +/- 0.00
Episode length: 146.00 +/- 0.00
Eval num_timesteps=4752000, episode_reward=1492.00 +/- 0.00
Episode length: 146.00 +/- 0.00
Eval num_timesteps=4776000, episode_reward=934.00 +/- 0.00
Episode length: 95.00 +/- 0.00
Eval num_timesteps=4800000, episode_reward=934.00 +/- 0.00
Episode length: 95.00 +/- 0.00
Eval num_timesteps=4824000, episode_reward=1492.00 +/- 0.00
Episode length: 146.00 +/- 0.00
Eval num_timesteps=4848000, episode_reward=1492.00 +/- 0.00
Episode length: 146.00 +/- 0.00
Eval num_timesteps=4872000, episode_reward=768.00 +/- 0.00
Episode length: 81.00 +/- 0.00
Eval num_timesteps=4896000, episode_reward=768.00 +/- 0.00
Episode length: 81.00 +/- 0.00
Eval num_timesteps=4920000, episode_reward=336.00 +/- 0.00
Episode length: 89.00 +/- 0.00
Eval num_timesteps=4944000, episode_reward=336.00 +/- 0.00
Episode length: 89.00 +/- 0.00
Eval num_timesteps=4968000, episode_reward=687.00 +/- 0.00
Episode length: 74.00 +/- 0.00
Eval num_timesteps=4992000, episode_reward=687.00 +/- 0.00
Episode length: 74.00 +/- 0.00
Eval num_timesteps=5016000, episode_reward=-94.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=5040000, episode_reward=-94.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=5064000, episode_reward=-94.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=5088000, episode_reward=-94.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=5112000, episode_reward=-94.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=5136000, episode_reward=-94.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=5160000, episode_reward=-94.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=5184000, episode_reward=-94.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=5208000, episode_reward=-94.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=5232000, episode_reward=-94.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=5256000, episode_reward=-94.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=5280000, episode_reward=-94.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=5304000, episode_reward=-94.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=5328000, episode_reward=-94.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=5352000, episode_reward=-94.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=5376000, episode_reward=-94.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=5400000, episode_reward=-94.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=5424000, episode_reward=-94.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=5448000, episode_reward=-94.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=5472000, episode_reward=1003.00 +/- 0.00
Episode length: 104.00 +/- 0.00
Eval num_timesteps=5496000, episode_reward=1003.00 +/- 0.00
Episode length: 104.00 +/- 0.00
Eval num_timesteps=5520000, episode_reward=1703.00 +/- 0.00
Episode length: 161.00 +/- 0.00
New best mean reward!
Eval num_timesteps=5544000, episode_reward=1703.00 +/- 0.00
Episode length: 161.00 +/- 0.00
Eval num_timesteps=5568000, episode_reward=1703.00 +/- 0.00
Episode length: 161.00 +/- 0.00
Eval num_timesteps=5592000, episode_reward=1703.00 +/- 0.00
Episode length: 161.00 +/- 0.00
Eval num_timesteps=5616000, episode_reward=1695.00 +/- 0.00
Episode length: 160.00 +/- 0.00
Eval num_timesteps=5640000, episode_reward=1695.00 +/- 0.00
Episode length: 160.00 +/- 0.00
Eval num_timesteps=5664000, episode_reward=1884.00 +/- 0.00
Episode length: 181.00 +/- 0.00
New best mean reward!
Eval num_timesteps=5688000, episode_reward=1884.00 +/- 0.00
Episode length: 181.00 +/- 0.00
Eval num_timesteps=5712000, episode_reward=2435.00 +/- 0.00
Episode length: 225.00 +/- 0.00
New best mean reward!
Eval num_timesteps=5736000, episode_reward=2435.00 +/- 0.00
Episode length: 225.00 +/- 0.00
Eval num_timesteps=5760000, episode_reward=1886.00 +/- 0.00
Episode length: 176.00 +/- 0.00
Eval num_timesteps=5784000, episode_reward=1886.00 +/- 0.00
Episode length: 176.00 +/- 0.00
Eval num_timesteps=5808000, episode_reward=1935.00 +/- 0.00
Episode length: 185.00 +/- 0.00
Eval num_timesteps=5832000, episode_reward=1935.00 +/- 0.00
Episode length: 185.00 +/- 0.00
Eval num_timesteps=5856000, episode_reward=2435.00 +/- 0.00
Episode length: 228.00 +/- 0.00
Eval num_timesteps=5880000, episode_reward=2435.00 +/- 0.00
Episode length: 228.00 +/- 0.00
Eval num_timesteps=5904000, episode_reward=1935.00 +/- 0.00
Episode length: 185.00 +/- 0.00
Eval num_timesteps=5928000, episode_reward=1935.00 +/- 0.00
Episode length: 185.00 +/- 0.00
Eval num_timesteps=5952000, episode_reward=1724.00 +/- 0.00
Episode length: 162.00 +/- 0.00
Eval num_timesteps=5976000, episode_reward=1724.00 +/- 0.00
Episode length: 162.00 +/- 0.00
Eval num_timesteps=6000000, episode_reward=1256.00 +/- 0.00
Episode length: 125.00 +/- 0.00
Eval num_timesteps=6024000, episode_reward=1256.00 +/- 0.00
Episode length: 125.00 +/- 0.00
Eval num_timesteps=6048000, episode_reward=1256.00 +/- 0.00
Episode length: 125.00 +/- 0.00
Eval num_timesteps=6072000, episode_reward=1256.00 +/- 0.00
Episode length: 125.00 +/- 0.00
Eval num_timesteps=6096000, episode_reward=768.00 +/- 0.00
Episode length: 81.00 +/- 0.00
Eval num_timesteps=6120000, episode_reward=768.00 +/- 0.00
Episode length: 81.00 +/- 0.00
Eval num_timesteps=6144000, episode_reward=768.00 +/- 0.00
Episode length: 81.00 +/- 0.00
Eval num_timesteps=6168000, episode_reward=-94.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=6192000, episode_reward=-94.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=6216000, episode_reward=-94.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=6240000, episode_reward=-94.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=6264000, episode_reward=-94.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=6288000, episode_reward=-94.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=6312000, episode_reward=-94.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=6336000, episode_reward=-94.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=6360000, episode_reward=-94.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=6384000, episode_reward=-94.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=6408000, episode_reward=-94.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=6432000, episode_reward=-94.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=6456000, episode_reward=969.00 +/- 0.00
Episode length: 271.00 +/- 0.00
Eval num_timesteps=6480000, episode_reward=969.00 +/- 0.00
Episode length: 271.00 +/- 0.00
Eval num_timesteps=6504000, episode_reward=-94.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=6528000, episode_reward=-94.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=6552000, episode_reward=95.00 +/- 0.00
Episode length: 144.00 +/- 0.00
Eval num_timesteps=6576000, episode_reward=95.00 +/- 0.00
Episode length: 144.00 +/- 0.00
Eval num_timesteps=6600000, episode_reward=961.00 +/- 0.00
Episode length: 314.00 +/- 0.00
Eval num_timesteps=6624000, episode_reward=961.00 +/- 0.00
Episode length: 314.00 +/- 0.00
Eval num_timesteps=6648000, episode_reward=1239.00 +/- 0.00
Episode length: 201.00 +/- 0.00
Eval num_timesteps=6672000, episode_reward=1239.00 +/- 0.00
Episode length: 201.00 +/- 0.00
Eval num_timesteps=6696000, episode_reward=95.00 +/- 0.00
Episode length: 144.00 +/- 0.00
Eval num_timesteps=6720000, episode_reward=95.00 +/- 0.00
Episode length: 144.00 +/- 0.00
Eval num_timesteps=6744000, episode_reward=802.00 +/- 0.00
Episode length: 527.00 +/- 0.00
Eval num_timesteps=6768000, episode_reward=802.00 +/- 0.00
Episode length: 527.00 +/- 0.00
Eval num_timesteps=6792000, episode_reward=1065.00 +/- 0.00
Episode length: 192.00 +/- 0.00
Eval num_timesteps=6816000, episode_reward=1065.00 +/- 0.00
Episode length: 192.00 +/- 0.00
Eval num_timesteps=6840000, episode_reward=991.00 +/- 0.00
Episode length: 165.00 +/- 0.00
Eval num_timesteps=6864000, episode_reward=991.00 +/- 0.00
Episode length: 165.00 +/- 0.00
Eval num_timesteps=6888000, episode_reward=644.00 +/- 0.00
Episode length: 133.00 +/- 0.00
Eval num_timesteps=6912000, episode_reward=644.00 +/- 0.00
Episode length: 133.00 +/- 0.00
Eval num_timesteps=6936000, episode_reward=644.00 +/- 0.00
Episode length: 133.00 +/- 0.00
Eval num_timesteps=6960000, episode_reward=644.00 +/- 0.00
Episode length: 133.00 +/- 0.00
Eval num_timesteps=6984000, episode_reward=1481.00 +/- 0.00
Episode length: 217.00 +/- 0.00
Eval num_timesteps=7008000, episode_reward=1481.00 +/- 0.00
Episode length: 217.00 +/- 0.00
Eval num_timesteps=7032000, episode_reward=1691.00 +/- 0.00
Episode length: 217.00 +/- 0.00
Eval num_timesteps=7056000, episode_reward=1691.00 +/- 0.00
Episode length: 217.00 +/- 0.00
Eval num_timesteps=7080000, episode_reward=1240.00 +/- 0.00
Episode length: 185.00 +/- 0.00
Eval num_timesteps=7104000, episode_reward=1240.00 +/- 0.00
Episode length: 185.00 +/- 0.00
Eval num_timesteps=7128000, episode_reward=745.00 +/- 0.00
Episode length: 128.00 +/- 0.00
Eval num_timesteps=7152000, episode_reward=745.00 +/- 0.00
Episode length: 128.00 +/- 0.00
Eval num_timesteps=7176000, episode_reward=745.00 +/- 0.00
Episode length: 128.00 +/- 0.00
Eval num_timesteps=7200000, episode_reward=994.00 +/- 0.00
Episode length: 150.00 +/- 0.00
Eval num_timesteps=7224000, episode_reward=994.00 +/- 0.00
Episode length: 150.00 +/- 0.00
Eval num_timesteps=7248000, episode_reward=1003.00 +/- 0.00
Episode length: 107.00 +/- 0.00
Eval num_timesteps=7272000, episode_reward=1003.00 +/- 0.00
Episode length: 107.00 +/- 0.00
Eval num_timesteps=7296000, episode_reward=637.00 +/- 0.00
Episode length: 69.00 +/- 0.00
Eval num_timesteps=7320000, episode_reward=637.00 +/- 0.00
Episode length: 69.00 +/- 0.00
Eval num_timesteps=7344000, episode_reward=596.00 +/- 0.00
Episode length: 69.00 +/- 0.00
Eval num_timesteps=7368000, episode_reward=596.00 +/- 0.00
Episode length: 69.00 +/- 0.00
Eval num_timesteps=7392000, episode_reward=601.00 +/- 0.00
Episode length: 69.00 +/- 0.00
Eval num_timesteps=7416000, episode_reward=601.00 +/- 0.00
Episode length: 69.00 +/- 0.00
Eval num_timesteps=7440000, episode_reward=596.00 +/- 0.00
Episode length: 69.00 +/- 0.00
Eval num_timesteps=7464000, episode_reward=596.00 +/- 0.00
Episode length: 69.00 +/- 0.00
Eval num_timesteps=7488000, episode_reward=596.00 +/- 0.00
Episode length: 69.00 +/- 0.00
Eval num_timesteps=7512000, episode_reward=596.00 +/- 0.00
Episode length: 69.00 +/- 0.00
Eval num_timesteps=7536000, episode_reward=1003.00 +/- 0.00
Episode length: 107.00 +/- 0.00
Eval num_timesteps=7560000, episode_reward=1003.00 +/- 0.00
Episode length: 107.00 +/- 0.00
Eval num_timesteps=7584000, episode_reward=768.00 +/- 0.00
Episode length: 95.00 +/- 0.00
Eval num_timesteps=7608000, episode_reward=768.00 +/- 0.00
Episode length: 95.00 +/- 0.00
Eval num_timesteps=7632000, episode_reward=1003.00 +/- 0.00
Episode length: 107.00 +/- 0.00
Eval num_timesteps=7656000, episode_reward=1003.00 +/- 0.00
Episode length: 107.00 +/- 0.00
Eval num_timesteps=7680000, episode_reward=1003.00 +/- 0.00
Episode length: 107.00 +/- 0.00
Eval num_timesteps=7704000, episode_reward=1003.00 +/- 0.00
Episode length: 107.00 +/- 0.00
Eval num_timesteps=7728000, episode_reward=846.00 +/- 0.00
Episode length: 115.00 +/- 0.00
Eval num_timesteps=7752000, episode_reward=846.00 +/- 0.00
Episode length: 115.00 +/- 0.00
Eval num_timesteps=7776000, episode_reward=638.00 +/- 0.00
Episode length: 96.00 +/- 0.00
Eval num_timesteps=7800000, episode_reward=638.00 +/- 0.00
Episode length: 96.00 +/- 0.00
Eval num_timesteps=7824000, episode_reward=713.00 +/- 0.00
Episode length: 100.00 +/- 0.00
Eval num_timesteps=7848000, episode_reward=713.00 +/- 0.00
Episode length: 100.00 +/- 0.00
Eval num_timesteps=7872000, episode_reward=-62.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=7896000, episode_reward=-62.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=7920000, episode_reward=-78.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=7944000, episode_reward=-78.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=7968000, episode_reward=845.00 +/- 0.00
Episode length: 115.00 +/- 0.00
Eval num_timesteps=7992000, episode_reward=845.00 +/- 0.00
Episode length: 115.00 +/- 0.00
Eval num_timesteps=8016000, episode_reward=1000.00 +/- 0.00
Episode length: 122.00 +/- 0.00
Eval num_timesteps=8040000, episode_reward=1000.00 +/- 0.00
Episode length: 122.00 +/- 0.00
Eval num_timesteps=8064000, episode_reward=1000.00 +/- 0.00
Episode length: 122.00 +/- 0.00
Eval num_timesteps=8088000, episode_reward=1000.00 +/- 0.00
Episode length: 122.00 +/- 0.00
Eval num_timesteps=8112000, episode_reward=-94.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=8136000, episode_reward=-94.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=8160000, episode_reward=-94.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=8184000, episode_reward=-94.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=8208000, episode_reward=-94.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=8232000, episode_reward=-94.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=8256000, episode_reward=-94.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=8280000, episode_reward=-94.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=8304000, episode_reward=-94.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=8328000, episode_reward=-94.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=8352000, episode_reward=-94.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=8376000, episode_reward=-94.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=8400000, episode_reward=-94.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=8424000, episode_reward=-94.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=8448000, episode_reward=-94.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=8472000, episode_reward=-78.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=8496000, episode_reward=-78.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=8520000, episode_reward=737.00 +/- 0.00
Episode length: 113.00 +/- 0.00
Eval num_timesteps=8544000, episode_reward=737.00 +/- 0.00
Episode length: 113.00 +/- 0.00
Eval num_timesteps=8568000, episode_reward=733.00 +/- 0.00
Episode length: 113.00 +/- 0.00
Eval num_timesteps=8592000, episode_reward=733.00 +/- 0.00
Episode length: 113.00 +/- 0.00
Eval num_timesteps=8616000, episode_reward=733.00 +/- 0.00
Episode length: 113.00 +/- 0.00
Eval num_timesteps=8640000, episode_reward=733.00 +/- 0.00
Episode length: 113.00 +/- 0.00
Eval num_timesteps=8664000, episode_reward=654.00 +/- 0.00
Episode length: 73.00 +/- 0.00
Eval num_timesteps=8688000, episode_reward=654.00 +/- 0.00
Episode length: 73.00 +/- 0.00
Eval num_timesteps=8712000, episode_reward=-94.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=8736000, episode_reward=-94.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=8760000, episode_reward=654.00 +/- 0.00
Episode length: 73.00 +/- 0.00
Eval num_timesteps=8784000, episode_reward=654.00 +/- 0.00
Episode length: 73.00 +/- 0.00
Eval num_timesteps=8808000, episode_reward=654.00 +/- 0.00
Episode length: 73.00 +/- 0.00
Eval num_timesteps=8832000, episode_reward=654.00 +/- 0.00
Episode length: 73.00 +/- 0.00
Eval num_timesteps=8856000, episode_reward=1003.00 +/- 0.00
Episode length: 106.00 +/- 0.00
Eval num_timesteps=8880000, episode_reward=1003.00 +/- 0.00
Episode length: 106.00 +/- 0.00
Eval num_timesteps=8904000, episode_reward=1003.00 +/- 0.00
Episode length: 106.00 +/- 0.00
Eval num_timesteps=8928000, episode_reward=1003.00 +/- 0.00
Episode length: 106.00 +/- 0.00
Eval num_timesteps=8952000, episode_reward=1003.00 +/- 0.00
Episode length: 106.00 +/- 0.00
Eval num_timesteps=8976000, episode_reward=1003.00 +/- 0.00
Episode length: 106.00 +/- 0.00
Eval num_timesteps=9000000, episode_reward=1003.00 +/- 0.00
Episode length: 106.00 +/- 0.00
Eval num_timesteps=9024000, episode_reward=1003.00 +/- 0.00
Episode length: 106.00 +/- 0.00
Eval num_timesteps=9048000, episode_reward=1003.00 +/- 0.00
Episode length: 106.00 +/- 0.00
Eval num_timesteps=9072000, episode_reward=1003.00 +/- 0.00
Episode length: 106.00 +/- 0.00
Eval num_timesteps=9096000, episode_reward=1003.00 +/- 0.00
Episode length: 106.00 +/- 0.00
Eval num_timesteps=9120000, episode_reward=1003.00 +/- 0.00
Episode length: 106.00 +/- 0.00
Eval num_timesteps=9144000, episode_reward=-94.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=9168000, episode_reward=-94.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=9192000, episode_reward=447.00 +/- 0.00
Episode length: 58.00 +/- 0.00
Eval num_timesteps=9216000, episode_reward=447.00 +/- 0.00
Episode length: 58.00 +/- 0.00
Eval num_timesteps=9240000, episode_reward=447.00 +/- 0.00
Episode length: 58.00 +/- 0.00
Eval num_timesteps=9264000, episode_reward=447.00 +/- 0.00
Episode length: 58.00 +/- 0.00
Eval num_timesteps=9288000, episode_reward=447.00 +/- 0.00
Episode length: 58.00 +/- 0.00
Eval num_timesteps=9312000, episode_reward=728.00 +/- 0.00
Episode length: 81.00 +/- 0.00
Eval num_timesteps=9336000, episode_reward=728.00 +/- 0.00
Episode length: 81.00 +/- 0.00
Eval num_timesteps=9360000, episode_reward=728.00 +/- 0.00
Episode length: 81.00 +/- 0.00
Eval num_timesteps=9384000, episode_reward=728.00 +/- 0.00
Episode length: 81.00 +/- 0.00
Eval num_timesteps=9408000, episode_reward=725.00 +/- 0.00
Episode length: 81.00 +/- 0.00
Eval num_timesteps=9432000, episode_reward=725.00 +/- 0.00
Episode length: 81.00 +/- 0.00
Eval num_timesteps=9456000, episode_reward=1004.00 +/- 0.00
Episode length: 113.00 +/- 0.00
Eval num_timesteps=9480000, episode_reward=1004.00 +/- 0.00
Episode length: 113.00 +/- 0.00
Eval num_timesteps=9504000, episode_reward=1004.00 +/- 0.00
Episode length: 113.00 +/- 0.00
Eval num_timesteps=9528000, episode_reward=1004.00 +/- 0.00
Episode length: 113.00 +/- 0.00
Eval num_timesteps=9552000, episode_reward=1004.00 +/- 0.00
Episode length: 113.00 +/- 0.00
Eval num_timesteps=9576000, episode_reward=1004.00 +/- 0.00
Episode length: 113.00 +/- 0.00
Eval num_timesteps=9600000, episode_reward=1004.00 +/- 0.00
Episode length: 113.00 +/- 0.00
Eval num_timesteps=9624000, episode_reward=1004.00 +/- 0.00
Episode length: 113.00 +/- 0.00
Eval num_timesteps=9648000, episode_reward=1004.00 +/- 0.00
Episode length: 109.00 +/- 0.00
Eval num_timesteps=9672000, episode_reward=1004.00 +/- 0.00
Episode length: 109.00 +/- 0.00
Eval num_timesteps=9696000, episode_reward=1003.00 +/- 0.00
Episode length: 106.00 +/- 0.00
Eval num_timesteps=9720000, episode_reward=1003.00 +/- 0.00
Episode length: 106.00 +/- 0.00
Eval num_timesteps=9744000, episode_reward=-94.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=9768000, episode_reward=-94.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=9792000, episode_reward=-94.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=9816000, episode_reward=-94.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=9840000, episode_reward=-94.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=9864000, episode_reward=-94.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=9888000, episode_reward=-94.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=9912000, episode_reward=-94.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=9936000, episode_reward=-94.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=9960000, episode_reward=-94.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=9984000, episode_reward=-94.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=10008000, episode_reward=-94.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
 100% ━━━━━━━━━━━━━━━━━━ 10,027,008/10,00… [ 1 day, 9:35:59 < 0:00:00 , ? it/s ]
