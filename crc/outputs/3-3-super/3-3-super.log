/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/envs/registration.py:555: UserWarning: [33mWARN: The environment SuperMarioBros-3-3-v0 is out of date. You should consider upgrading to version `v3`.[0m
  logger.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/envs/registration.py:555: UserWarning: [33mWARN: The environment SuperMarioBros-3-3-v0 is out of date. You should consider upgrading to version `v3`.[0m
  logger.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/envs/registration.py:555: UserWarning: [33mWARN: The environment SuperMarioBros-3-3-v0 is out of date. You should consider upgrading to version `v3`.[0m
  logger.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/envs/registration.py:555: UserWarning: [33mWARN: The environment SuperMarioBros-3-3-v0 is out of date. You should consider upgrading to version `v3`.[0m
  logger.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/envs/registration.py:555: UserWarning: [33mWARN: The environment SuperMarioBros-3-3-v0 is out of date. You should consider upgrading to version `v3`.[0m
  logger.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/envs/registration.py:555: UserWarning: [33mWARN: The environment SuperMarioBros-3-3-v0 is out of date. You should consider upgrading to version `v3`.[0m
  logger.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/envs/registration.py:555: UserWarning: [33mWARN: The environment SuperMarioBros-3-3-v0 is out of date. You should consider upgrading to version `v3`.[0m
  logger.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/envs/registration.py:555: UserWarning: [33mWARN: The environment SuperMarioBros-3-3-v0 is out of date. You should consider upgrading to version `v3`.[0m
  logger.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/envs/registration.py:555: UserWarning: [33mWARN: The environment SuperMarioBros-3-3-v0 is out of date. You should consider upgrading to version `v3`.[0m
  logger.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/envs/registration.py:555: UserWarning: [33mWARN: The environment SuperMarioBros-3-3-v0 is out of date. You should consider upgrading to version `v3`.[0m
  logger.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/envs/registration.py:555: UserWarning: [33mWARN: The environment SuperMarioBros-3-3-v0 is out of date. You should consider upgrading to version `v3`.[0m
  logger.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/envs/registration.py:555: UserWarning: [33mWARN: The environment SuperMarioBros-3-3-v0 is out of date. You should consider upgrading to version `v3`.[0m
  logger.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/envs/registration.py:555: UserWarning: [33mWARN: The environment SuperMarioBros-3-3-v0 is out of date. You should consider upgrading to version `v3`.[0m
  logger.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/envs/registration.py:555: UserWarning: [33mWARN: The environment SuperMarioBros-3-3-v0 is out of date. You should consider upgrading to version `v3`.[0m
  logger.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/envs/registration.py:555: UserWarning: [33mWARN: The environment SuperMarioBros-3-3-v0 is out of date. You should consider upgrading to version `v3`.[0m
  logger.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/envs/registration.py:555: UserWarning: [33mWARN: The environment SuperMarioBros-3-3-v0 is out of date. You should consider upgrading to version `v3`.[0m
  logger.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/envs/registration.py:555: UserWarning: [33mWARN: The environment SuperMarioBros-3-3-v0 is out of date. You should consider upgrading to version `v3`.[0m
  logger.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/envs/registration.py:555: UserWarning: [33mWARN: The environment SuperMarioBros-3-3-v0 is out of date. You should consider upgrading to version `v3`.[0m
  logger.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/envs/registration.py:555: UserWarning: [33mWARN: The environment SuperMarioBros-3-3-v0 is out of date. You should consider upgrading to version `v3`.[0m
  logger.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/envs/registration.py:555: UserWarning: [33mWARN: The environment SuperMarioBros-3-3-v0 is out of date. You should consider upgrading to version `v3`.[0m
  logger.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/envs/registration.py:555: UserWarning: [33mWARN: The environment SuperMarioBros-3-3-v0 is out of date. You should consider upgrading to version `v3`.[0m
  logger.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/envs/registration.py:555: UserWarning: [33mWARN: The environment SuperMarioBros-3-3-v0 is out of date. You should consider upgrading to version `v3`.[0m
  logger.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/envs/registration.py:555: UserWarning: [33mWARN: The environment SuperMarioBros-3-3-v0 is out of date. You should consider upgrading to version `v3`.[0m
  logger.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/envs/registration.py:555: UserWarning: [33mWARN: The environment SuperMarioBros-3-3-v0 is out of date. You should consider upgrading to version `v3`.[0m
  logger.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.
  warnings.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.
  warnings.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.
  warnings.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.
  warnings.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.
  warnings.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.
  warnings.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.
  warnings.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.
  warnings.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.
  warnings.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.
  warnings.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.
  warnings.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.
  warnings.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.
  warnings.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.
  warnings.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.
  warnings.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.
  warnings.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.
  warnings.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.
  warnings.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.
  warnings.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.
  warnings.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.
  warnings.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.
  warnings.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.
  warnings.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.
  warnings.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/stable_baselines3/common/callbacks.py:403: UserWarning: Training and eval env are not of the same type<stable_baselines3.common.vec_env.vec_transpose.VecTransposeImage object at 0x14d6b4e9f280> != <stable_baselines3.common.vec_env.vec_monitor.VecMonitor object at 0x14d6b4e9da80>
  warnings.warn("Training and eval env are not of the same type" f"{self.training_env} != {self.eval_env}")
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(terminated, (bool, np.bool8)):
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(terminated, (bool, np.bool8)):
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(terminated, (bool, np.bool8)):
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(terminated, (bool, np.bool8)):
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(terminated, (bool, np.bool8)):
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(terminated, (bool, np.bool8)):
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(terminated, (bool, np.bool8)):
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(terminated, (bool, np.bool8)):
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(terminated, (bool, np.bool8)):
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(terminated, (bool, np.bool8)):
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(terminated, (bool, np.bool8)):
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(terminated, (bool, np.bool8)):
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(terminated, (bool, np.bool8)):
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(terminated, (bool, np.bool8)):
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(terminated, (bool, np.bool8)):
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(terminated, (bool, np.bool8)):
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(terminated, (bool, np.bool8)):
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(terminated, (bool, np.bool8)):
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(terminated, (bool, np.bool8)):
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(terminated, (bool, np.bool8)):
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(terminated, (bool, np.bool8)):
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(terminated, (bool, np.bool8)):
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(terminated, (bool, np.bool8)):
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(terminated, (bool, np.bool8)):
Training model!
World: 3
Stage: 3
Vectors: 24
Steps: 10000000
Learning rate: 0.0003
Eval num_timesteps=24000, episode_reward=258.00 +/- 0.00
Episode length: 27.00 +/- 0.00
New best mean reward!
Eval num_timesteps=48000, episode_reward=258.00 +/- 0.00
Episode length: 27.00 +/- 0.00
Eval num_timesteps=72000, episode_reward=252.00 +/- 0.00
Episode length: 31.00 +/- 0.00
Eval num_timesteps=96000, episode_reward=252.00 +/- 0.00
Episode length: 31.00 +/- 0.00
Eval num_timesteps=120000, episode_reward=253.00 +/- 0.00
Episode length: 31.00 +/- 0.00
Eval num_timesteps=144000, episode_reward=253.00 +/- 0.00
Episode length: 31.00 +/- 0.00
Eval num_timesteps=168000, episode_reward=253.00 +/- 0.00
Episode length: 31.00 +/- 0.00
Eval num_timesteps=192000, episode_reward=253.00 +/- 0.00
Episode length: 31.00 +/- 0.00
Eval num_timesteps=216000, episode_reward=253.00 +/- 0.00
Episode length: 31.00 +/- 0.00
Eval num_timesteps=240000, episode_reward=253.00 +/- 0.00
Episode length: 31.00 +/- 0.00
Eval num_timesteps=264000, episode_reward=383.00 +/- 0.00
Episode length: 46.00 +/- 0.00
New best mean reward!
Eval num_timesteps=288000, episode_reward=383.00 +/- 0.00
Episode length: 46.00 +/- 0.00
Eval num_timesteps=312000, episode_reward=386.00 +/- 0.00
Episode length: 46.00 +/- 0.00
New best mean reward!
Eval num_timesteps=336000, episode_reward=386.00 +/- 0.00
Episode length: 46.00 +/- 0.00
Eval num_timesteps=360000, episode_reward=389.00 +/- 0.00
Episode length: 41.00 +/- 0.00
New best mean reward!
Eval num_timesteps=384000, episode_reward=389.00 +/- 0.00
Episode length: 41.00 +/- 0.00
Eval num_timesteps=408000, episode_reward=241.00 +/- 0.00
Episode length: 63.00 +/- 0.00
Eval num_timesteps=432000, episode_reward=241.00 +/- 0.00
Episode length: 63.00 +/- 0.00
Eval num_timesteps=456000, episode_reward=377.00 +/- 0.00
Episode length: 50.00 +/- 0.00
Eval num_timesteps=480000, episode_reward=377.00 +/- 0.00
Episode length: 50.00 +/- 0.00
Eval num_timesteps=504000, episode_reward=389.00 +/- 0.00
Episode length: 41.00 +/- 0.00
Eval num_timesteps=528000, episode_reward=389.00 +/- 0.00
Episode length: 41.00 +/- 0.00
Eval num_timesteps=552000, episode_reward=389.00 +/- 0.00
Episode length: 40.00 +/- 0.00
Eval num_timesteps=576000, episode_reward=389.00 +/- 0.00
Episode length: 40.00 +/- 0.00
Eval num_timesteps=600000, episode_reward=390.00 +/- 0.00
Episode length: 40.00 +/- 0.00
New best mean reward!
Eval num_timesteps=624000, episode_reward=390.00 +/- 0.00
Episode length: 40.00 +/- 0.00
Eval num_timesteps=648000, episode_reward=391.00 +/- 0.00
Episode length: 39.00 +/- 0.00
New best mean reward!
Eval num_timesteps=672000, episode_reward=391.00 +/- 0.00
Episode length: 39.00 +/- 0.00
Eval num_timesteps=696000, episode_reward=253.00 +/- 0.00
Episode length: 31.00 +/- 0.00
Eval num_timesteps=720000, episode_reward=253.00 +/- 0.00
Episode length: 31.00 +/- 0.00
Eval num_timesteps=744000, episode_reward=251.00 +/- 0.00
Episode length: 47.00 +/- 0.00
Eval num_timesteps=768000, episode_reward=251.00 +/- 0.00
Episode length: 47.00 +/- 0.00
Eval num_timesteps=792000, episode_reward=253.00 +/- 0.00
Episode length: 31.00 +/- 0.00
Eval num_timesteps=816000, episode_reward=253.00 +/- 0.00
Episode length: 31.00 +/- 0.00
Eval num_timesteps=840000, episode_reward=390.00 +/- 0.00
Episode length: 42.00 +/- 0.00
Eval num_timesteps=864000, episode_reward=390.00 +/- 0.00
Episode length: 42.00 +/- 0.00
Eval num_timesteps=888000, episode_reward=253.00 +/- 0.00
Episode length: 31.00 +/- 0.00
Eval num_timesteps=912000, episode_reward=253.00 +/- 0.00
Episode length: 31.00 +/- 0.00
Eval num_timesteps=936000, episode_reward=248.00 +/- 0.00
Episode length: 36.00 +/- 0.00
Eval num_timesteps=960000, episode_reward=248.00 +/- 0.00
Episode length: 36.00 +/- 0.00
Eval num_timesteps=984000, episode_reward=253.00 +/- 0.00
Episode length: 31.00 +/- 0.00
Eval num_timesteps=1008000, episode_reward=253.00 +/- 0.00
Episode length: 31.00 +/- 0.00
Eval num_timesteps=1032000, episode_reward=253.00 +/- 0.00
Episode length: 31.00 +/- 0.00
Eval num_timesteps=1056000, episode_reward=390.00 +/- 0.00
Episode length: 42.00 +/- 0.00
Eval num_timesteps=1080000, episode_reward=390.00 +/- 0.00
Episode length: 42.00 +/- 0.00
Eval num_timesteps=1104000, episode_reward=253.00 +/- 0.00
Episode length: 31.00 +/- 0.00
Eval num_timesteps=1128000, episode_reward=253.00 +/- 0.00
Episode length: 31.00 +/- 0.00
Eval num_timesteps=1152000, episode_reward=253.00 +/- 0.00
Episode length: 31.00 +/- 0.00
Eval num_timesteps=1176000, episode_reward=253.00 +/- 0.00
Episode length: 31.00 +/- 0.00
Eval num_timesteps=1200000, episode_reward=253.00 +/- 0.00
Episode length: 31.00 +/- 0.00
Eval num_timesteps=1224000, episode_reward=253.00 +/- 0.00
Episode length: 31.00 +/- 0.00
Eval num_timesteps=1248000, episode_reward=253.00 +/- 0.00
Episode length: 31.00 +/- 0.00
Eval num_timesteps=1272000, episode_reward=253.00 +/- 0.00
Episode length: 31.00 +/- 0.00
Eval num_timesteps=1296000, episode_reward=253.00 +/- 0.00
Episode length: 31.00 +/- 0.00
Eval num_timesteps=1320000, episode_reward=253.00 +/- 0.00
Episode length: 31.00 +/- 0.00
Eval num_timesteps=1344000, episode_reward=253.00 +/- 0.00
Episode length: 31.00 +/- 0.00
Eval num_timesteps=1368000, episode_reward=253.00 +/- 0.00
Episode length: 31.00 +/- 0.00
Eval num_timesteps=1392000, episode_reward=253.00 +/- 0.00
Episode length: 31.00 +/- 0.00
Eval num_timesteps=1416000, episode_reward=253.00 +/- 0.00
Episode length: 31.00 +/- 0.00
Eval num_timesteps=1440000, episode_reward=253.00 +/- 0.00
Episode length: 31.00 +/- 0.00
Eval num_timesteps=1464000, episode_reward=253.00 +/- 0.00
Episode length: 31.00 +/- 0.00
Eval num_timesteps=1488000, episode_reward=253.00 +/- 0.00
Episode length: 31.00 +/- 0.00
Eval num_timesteps=1512000, episode_reward=253.00 +/- 0.00
Episode length: 31.00 +/- 0.00
Eval num_timesteps=1536000, episode_reward=253.00 +/- 0.00
Episode length: 31.00 +/- 0.00
Eval num_timesteps=1560000, episode_reward=253.00 +/- 0.00
Episode length: 31.00 +/- 0.00
Eval num_timesteps=1584000, episode_reward=390.00 +/- 0.00
Episode length: 43.00 +/- 0.00
Eval num_timesteps=1608000, episode_reward=390.00 +/- 0.00
Episode length: 43.00 +/- 0.00
Eval num_timesteps=1632000, episode_reward=253.00 +/- 0.00
Episode length: 31.00 +/- 0.00
Eval num_timesteps=1656000, episode_reward=253.00 +/- 0.00
Episode length: 31.00 +/- 0.00
Eval num_timesteps=1680000, episode_reward=252.00 +/- 0.00
Episode length: 38.00 +/- 0.00
Eval num_timesteps=1704000, episode_reward=252.00 +/- 0.00
Episode length: 38.00 +/- 0.00
Eval num_timesteps=1728000, episode_reward=250.00 +/- 0.00
Episode length: 39.00 +/- 0.00
Eval num_timesteps=1752000, episode_reward=250.00 +/- 0.00
Episode length: 39.00 +/- 0.00
Eval num_timesteps=1776000, episode_reward=391.00 +/- 0.00
Episode length: 57.00 +/- 0.00
Eval num_timesteps=1800000, episode_reward=391.00 +/- 0.00
Episode length: 57.00 +/- 0.00
Eval num_timesteps=1824000, episode_reward=514.00 +/- 0.00
Episode length: 72.00 +/- 0.00
New best mean reward!
Eval num_timesteps=1848000, episode_reward=514.00 +/- 0.00
Episode length: 72.00 +/- 0.00
Eval num_timesteps=1872000, episode_reward=384.00 +/- 0.00
Episode length: 47.00 +/- 0.00
Eval num_timesteps=1896000, episode_reward=384.00 +/- 0.00
Episode length: 47.00 +/- 0.00
Eval num_timesteps=1920000, episode_reward=518.00 +/- 0.00
Episode length: 69.00 +/- 0.00
New best mean reward!
Eval num_timesteps=1944000, episode_reward=518.00 +/- 0.00
Episode length: 69.00 +/- 0.00
Eval num_timesteps=1968000, episode_reward=683.00 +/- 0.00
Episode length: 83.00 +/- 0.00
New best mean reward!
Eval num_timesteps=1992000, episode_reward=683.00 +/- 0.00
Episode length: 83.00 +/- 0.00
Eval num_timesteps=2016000, episode_reward=683.00 +/- 0.00
Episode length: 83.00 +/- 0.00
Eval num_timesteps=2040000, episode_reward=683.00 +/- 0.00
Episode length: 83.00 +/- 0.00
Eval num_timesteps=2064000, episode_reward=683.00 +/- 0.00
Episode length: 83.00 +/- 0.00
Eval num_timesteps=2088000, episode_reward=893.00 +/- 0.00
Episode length: 101.00 +/- 0.00
New best mean reward!
Eval num_timesteps=2112000, episode_reward=893.00 +/- 0.00
Episode length: 101.00 +/- 0.00
Eval num_timesteps=2136000, episode_reward=752.00 +/- 0.00
Episode length: 80.00 +/- 0.00
Eval num_timesteps=2160000, episode_reward=752.00 +/- 0.00
Episode length: 80.00 +/- 0.00
Eval num_timesteps=2184000, episode_reward=253.00 +/- 0.00
Episode length: 31.00 +/- 0.00
Eval num_timesteps=2208000, episode_reward=253.00 +/- 0.00
Episode length: 31.00 +/- 0.00
Eval num_timesteps=2232000, episode_reward=518.00 +/- 0.00
Episode length: 60.00 +/- 0.00
Eval num_timesteps=2256000, episode_reward=518.00 +/- 0.00
Episode length: 60.00 +/- 0.00
Eval num_timesteps=2280000, episode_reward=-89.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=2304000, episode_reward=-89.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=2328000, episode_reward=-89.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=2352000, episode_reward=-89.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=2376000, episode_reward=752.00 +/- 0.00
Episode length: 80.00 +/- 0.00
Eval num_timesteps=2400000, episode_reward=752.00 +/- 0.00
Episode length: 80.00 +/- 0.00
Eval num_timesteps=2424000, episode_reward=682.00 +/- 0.00
Episode length: 74.00 +/- 0.00
Eval num_timesteps=2448000, episode_reward=682.00 +/- 0.00
Episode length: 74.00 +/- 0.00
Eval num_timesteps=2472000, episode_reward=897.00 +/- 0.00
Episode length: 93.00 +/- 0.00
New best mean reward!
Eval num_timesteps=2496000, episode_reward=897.00 +/- 0.00
Episode length: 93.00 +/- 0.00
Eval num_timesteps=2520000, episode_reward=-200.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=2544000, episode_reward=-200.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=2568000, episode_reward=-200.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=2592000, episode_reward=-200.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=2616000, episode_reward=-200.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=2640000, episode_reward=-200.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=2664000, episode_reward=-200.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=2688000, episode_reward=-200.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=2712000, episode_reward=-200.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=2736000, episode_reward=-200.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=2760000, episode_reward=-200.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=2784000, episode_reward=-200.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=2808000, episode_reward=-200.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=2832000, episode_reward=-200.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=2856000, episode_reward=-200.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=2880000, episode_reward=-200.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=2904000, episode_reward=-200.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=2928000, episode_reward=-200.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=2952000, episode_reward=-200.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=2976000, episode_reward=-200.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=3000000, episode_reward=-200.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=3024000, episode_reward=-200.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=3048000, episode_reward=-200.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=3072000, episode_reward=-200.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=3096000, episode_reward=-200.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=3120000, episode_reward=-200.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=3144000, episode_reward=-200.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=3168000, episode_reward=-200.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=3192000, episode_reward=-200.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=3216000, episode_reward=-200.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=3240000, episode_reward=-200.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=3264000, episode_reward=-200.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=3288000, episode_reward=-200.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=3312000, episode_reward=-200.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=3336000, episode_reward=-200.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=3360000, episode_reward=-200.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=3384000, episode_reward=-200.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=3408000, episode_reward=-200.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=3432000, episode_reward=-200.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=3456000, episode_reward=-200.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=3480000, episode_reward=-200.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=3504000, episode_reward=-200.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=3528000, episode_reward=-200.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=3552000, episode_reward=-175.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=3576000, episode_reward=-175.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=3600000, episode_reward=42.00 +/- 0.00
Episode length: 831.00 +/- 0.00
Eval num_timesteps=3624000, episode_reward=42.00 +/- 0.00
Episode length: 831.00 +/- 0.00
Eval num_timesteps=3648000, episode_reward=175.00 +/- 0.00
Episode length: 167.00 +/- 0.00
Eval num_timesteps=3672000, episode_reward=175.00 +/- 0.00
Episode length: 167.00 +/- 0.00
Eval num_timesteps=3696000, episode_reward=217.00 +/- 0.00
Episode length: 56.00 +/- 0.00
Eval num_timesteps=3720000, episode_reward=217.00 +/- 0.00
Episode length: 56.00 +/- 0.00
Eval num_timesteps=3744000, episode_reward=248.00 +/- 0.00
Episode length: 37.00 +/- 0.00
Eval num_timesteps=3768000, episode_reward=248.00 +/- 0.00
Episode length: 37.00 +/- 0.00
Eval num_timesteps=3792000, episode_reward=270.00 +/- 0.00
Episode length: 66.00 +/- 0.00
Eval num_timesteps=3816000, episode_reward=270.00 +/- 0.00
Episode length: 66.00 +/- 0.00
Eval num_timesteps=3840000, episode_reward=213.00 +/- 0.00
Episode length: 41.00 +/- 0.00
Eval num_timesteps=3864000, episode_reward=213.00 +/- 0.00
Episode length: 41.00 +/- 0.00
Eval num_timesteps=3888000, episode_reward=235.00 +/- 0.00
Episode length: 38.00 +/- 0.00
Eval num_timesteps=3912000, episode_reward=235.00 +/- 0.00
Episode length: 38.00 +/- 0.00
Eval num_timesteps=3936000, episode_reward=383.00 +/- 0.00
Episode length: 42.00 +/- 0.00
Eval num_timesteps=3960000, episode_reward=383.00 +/- 0.00
Episode length: 42.00 +/- 0.00
Eval num_timesteps=3984000, episode_reward=390.00 +/- 0.00
Episode length: 42.00 +/- 0.00
Eval num_timesteps=4008000, episode_reward=390.00 +/- 0.00
Episode length: 42.00 +/- 0.00
Eval num_timesteps=4032000, episode_reward=295.00 +/- 0.00
Episode length: 42.00 +/- 0.00
Eval num_timesteps=4056000, episode_reward=295.00 +/- 0.00
Episode length: 42.00 +/- 0.00
Eval num_timesteps=4080000, episode_reward=681.00 +/- 0.00
Episode length: 80.00 +/- 0.00
Eval num_timesteps=4104000, episode_reward=681.00 +/- 0.00
Episode length: 80.00 +/- 0.00
Eval num_timesteps=4128000, episode_reward=681.00 +/- 0.00
Episode length: 80.00 +/- 0.00
Eval num_timesteps=4152000, episode_reward=399.00 +/- 0.00
Episode length: 43.00 +/- 0.00
Eval num_timesteps=4176000, episode_reward=399.00 +/- 0.00
Episode length: 43.00 +/- 0.00
Eval num_timesteps=4200000, episode_reward=511.00 +/- 0.00
Episode length: 53.00 +/- 0.00
Eval num_timesteps=4224000, episode_reward=511.00 +/- 0.00
Episode length: 53.00 +/- 0.00
Eval num_timesteps=4248000, episode_reward=684.00 +/- 0.00
Episode length: 79.00 +/- 0.00
Eval num_timesteps=4272000, episode_reward=684.00 +/- 0.00
Episode length: 79.00 +/- 0.00
Eval num_timesteps=4296000, episode_reward=896.00 +/- 0.00
Episode length: 85.00 +/- 0.00
Eval num_timesteps=4320000, episode_reward=896.00 +/- 0.00
Episode length: 85.00 +/- 0.00
Eval num_timesteps=4344000, episode_reward=755.00 +/- 0.00
Episode length: 74.00 +/- 0.00
Eval num_timesteps=4368000, episode_reward=755.00 +/- 0.00
Episode length: 74.00 +/- 0.00
Eval num_timesteps=4392000, episode_reward=885.00 +/- 0.00
Episode length: 86.00 +/- 0.00
Eval num_timesteps=4416000, episode_reward=885.00 +/- 0.00
Episode length: 86.00 +/- 0.00
Eval num_timesteps=4440000, episode_reward=895.00 +/- 0.00
Episode length: 86.00 +/- 0.00
Eval num_timesteps=4464000, episode_reward=895.00 +/- 0.00
Episode length: 86.00 +/- 0.00
Eval num_timesteps=4488000, episode_reward=896.00 +/- 0.00
Episode length: 86.00 +/- 0.00
Eval num_timesteps=4512000, episode_reward=896.00 +/- 0.00
Episode length: 86.00 +/- 0.00
Eval num_timesteps=4536000, episode_reward=966.00 +/- 0.00
Episode length: 92.00 +/- 0.00
New best mean reward!
Eval num_timesteps=4560000, episode_reward=966.00 +/- 0.00
Episode length: 92.00 +/- 0.00
Eval num_timesteps=4584000, episode_reward=1273.00 +/- 0.00
Episode length: 123.00 +/- 0.00
New best mean reward!
Eval num_timesteps=4608000, episode_reward=1273.00 +/- 0.00
Episode length: 123.00 +/- 0.00
Eval num_timesteps=4632000, episode_reward=1273.00 +/- 0.00
Episode length: 123.00 +/- 0.00
Eval num_timesteps=4656000, episode_reward=1273.00 +/- 0.00
Episode length: 123.00 +/- 0.00
Eval num_timesteps=4680000, episode_reward=1276.00 +/- 0.00
Episode length: 124.00 +/- 0.00
New best mean reward!
Eval num_timesteps=4704000, episode_reward=1276.00 +/- 0.00
Episode length: 124.00 +/- 0.00
Eval num_timesteps=4728000, episode_reward=1271.00 +/- 0.00
Episode length: 125.00 +/- 0.00
Eval num_timesteps=4752000, episode_reward=1271.00 +/- 0.00
Episode length: 125.00 +/- 0.00
Eval num_timesteps=4776000, episode_reward=253.00 +/- 0.00
Episode length: 31.00 +/- 0.00
Eval num_timesteps=4800000, episode_reward=253.00 +/- 0.00
Episode length: 31.00 +/- 0.00
Eval num_timesteps=4824000, episode_reward=253.00 +/- 0.00
Episode length: 31.00 +/- 0.00
Eval num_timesteps=4848000, episode_reward=253.00 +/- 0.00
Episode length: 31.00 +/- 0.00
Eval num_timesteps=4872000, episode_reward=253.00 +/- 0.00
Episode length: 31.00 +/- 0.00
Eval num_timesteps=4896000, episode_reward=253.00 +/- 0.00
Episode length: 31.00 +/- 0.00
Eval num_timesteps=4920000, episode_reward=388.00 +/- 0.00
Episode length: 47.00 +/- 0.00
Eval num_timesteps=4944000, episode_reward=388.00 +/- 0.00
Episode length: 47.00 +/- 0.00
Eval num_timesteps=4968000, episode_reward=389.00 +/- 0.00
Episode length: 43.00 +/- 0.00
Eval num_timesteps=4992000, episode_reward=389.00 +/- 0.00
Episode length: 43.00 +/- 0.00
Eval num_timesteps=5016000, episode_reward=389.00 +/- 0.00
Episode length: 43.00 +/- 0.00
Eval num_timesteps=5040000, episode_reward=389.00 +/- 0.00
Episode length: 43.00 +/- 0.00
Eval num_timesteps=5064000, episode_reward=389.00 +/- 0.00
Episode length: 42.00 +/- 0.00
Eval num_timesteps=5088000, episode_reward=389.00 +/- 0.00
Episode length: 42.00 +/- 0.00
Eval num_timesteps=5112000, episode_reward=684.00 +/- 0.00
Episode length: 68.00 +/- 0.00
Eval num_timesteps=5136000, episode_reward=684.00 +/- 0.00
Episode length: 68.00 +/- 0.00
Eval num_timesteps=5160000, episode_reward=684.00 +/- 0.00
Episode length: 68.00 +/- 0.00
Eval num_timesteps=5184000, episode_reward=896.00 +/- 0.00
Episode length: 93.00 +/- 0.00
Eval num_timesteps=5208000, episode_reward=896.00 +/- 0.00
Episode length: 93.00 +/- 0.00
Eval num_timesteps=5232000, episode_reward=896.00 +/- 0.00
Episode length: 93.00 +/- 0.00
Eval num_timesteps=5256000, episode_reward=896.00 +/- 0.00
Episode length: 93.00 +/- 0.00
Eval num_timesteps=5280000, episode_reward=1040.00 +/- 0.00
Episode length: 110.00 +/- 0.00
Eval num_timesteps=5304000, episode_reward=1040.00 +/- 0.00
Episode length: 110.00 +/- 0.00
Eval num_timesteps=5328000, episode_reward=1289.00 +/- 0.00
Episode length: 131.00 +/- 0.00
New best mean reward!
Eval num_timesteps=5352000, episode_reward=1289.00 +/- 0.00
Episode length: 131.00 +/- 0.00
Eval num_timesteps=5376000, episode_reward=1271.00 +/- 0.00
Episode length: 130.00 +/- 0.00
Eval num_timesteps=5400000, episode_reward=1271.00 +/- 0.00
Episode length: 130.00 +/- 0.00
Eval num_timesteps=5424000, episode_reward=1272.00 +/- 0.00
Episode length: 129.00 +/- 0.00
Eval num_timesteps=5448000, episode_reward=1272.00 +/- 0.00
Episode length: 129.00 +/- 0.00
Eval num_timesteps=5472000, episode_reward=1272.00 +/- 0.00
Episode length: 129.00 +/- 0.00
Eval num_timesteps=5496000, episode_reward=1272.00 +/- 0.00
Episode length: 129.00 +/- 0.00
Eval num_timesteps=5520000, episode_reward=1480.00 +/- 0.00
Episode length: 150.00 +/- 0.00
New best mean reward!
Eval num_timesteps=5544000, episode_reward=1480.00 +/- 0.00
Episode length: 150.00 +/- 0.00
Eval num_timesteps=5568000, episode_reward=1515.00 +/- 0.00
Episode length: 145.00 +/- 0.00
New best mean reward!
Eval num_timesteps=5592000, episode_reward=1515.00 +/- 0.00
Episode length: 145.00 +/- 0.00
Eval num_timesteps=5616000, episode_reward=1515.00 +/- 0.00
Episode length: 145.00 +/- 0.00
Eval num_timesteps=5640000, episode_reward=1515.00 +/- 0.00
Episode length: 145.00 +/- 0.00
Eval num_timesteps=5664000, episode_reward=1470.00 +/- 0.00
Episode length: 147.00 +/- 0.00
Eval num_timesteps=5688000, episode_reward=1470.00 +/- 0.00
Episode length: 147.00 +/- 0.00
Eval num_timesteps=5712000, episode_reward=1480.00 +/- 0.00
Episode length: 147.00 +/- 0.00
Eval num_timesteps=5736000, episode_reward=1480.00 +/- 0.00
Episode length: 147.00 +/- 0.00
Eval num_timesteps=5760000, episode_reward=1645.00 +/- 0.00
Episode length: 159.00 +/- 0.00
New best mean reward!
Eval num_timesteps=5784000, episode_reward=1645.00 +/- 0.00
Episode length: 159.00 +/- 0.00
Eval num_timesteps=5808000, episode_reward=1478.00 +/- 0.00
Episode length: 148.00 +/- 0.00
Eval num_timesteps=5832000, episode_reward=1478.00 +/- 0.00
Episode length: 148.00 +/- 0.00
Eval num_timesteps=5856000, episode_reward=253.00 +/- 0.00
Episode length: 31.00 +/- 0.00
Eval num_timesteps=5880000, episode_reward=253.00 +/- 0.00
Episode length: 31.00 +/- 0.00
Eval num_timesteps=5904000, episode_reward=253.00 +/- 0.00
Episode length: 31.00 +/- 0.00
Eval num_timesteps=5928000, episode_reward=253.00 +/- 0.00
Episode length: 31.00 +/- 0.00
Eval num_timesteps=5952000, episode_reward=-200.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=5976000, episode_reward=-200.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=6000000, episode_reward=-200.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=6024000, episode_reward=-200.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=6048000, episode_reward=-200.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=6072000, episode_reward=-200.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=6096000, episode_reward=-200.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=6120000, episode_reward=-200.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=6144000, episode_reward=-200.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=6168000, episode_reward=-200.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=6192000, episode_reward=-200.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=6216000, episode_reward=-200.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=6240000, episode_reward=-200.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=6264000, episode_reward=-200.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=6288000, episode_reward=-200.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=6312000, episode_reward=-200.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=6336000, episode_reward=-200.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=6360000, episode_reward=-200.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=6384000, episode_reward=-200.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=6408000, episode_reward=-200.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=6432000, episode_reward=-200.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=6456000, episode_reward=-188.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=6480000, episode_reward=-188.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=6504000, episode_reward=-200.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=6528000, episode_reward=-200.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=6552000, episode_reward=111.00 +/- 0.00
Episode length: 707.00 +/- 0.00
Eval num_timesteps=6576000, episode_reward=111.00 +/- 0.00
Episode length: 707.00 +/- 0.00
Eval num_timesteps=6600000, episode_reward=361.00 +/- 0.00
Episode length: 183.00 +/- 0.00
Eval num_timesteps=6624000, episode_reward=361.00 +/- 0.00
Episode length: 183.00 +/- 0.00
Eval num_timesteps=6648000, episode_reward=238.00 +/- 0.00
Episode length: 114.00 +/- 0.00
Eval num_timesteps=6672000, episode_reward=238.00 +/- 0.00
Episode length: 114.00 +/- 0.00
Eval num_timesteps=6696000, episode_reward=376.00 +/- 0.00
Episode length: 119.00 +/- 0.00
Eval num_timesteps=6720000, episode_reward=376.00 +/- 0.00
Episode length: 119.00 +/- 0.00
Eval num_timesteps=6744000, episode_reward=671.00 +/- 0.00
Episode length: 133.00 +/- 0.00
Eval num_timesteps=6768000, episode_reward=671.00 +/- 0.00
Episode length: 133.00 +/- 0.00
Eval num_timesteps=6792000, episode_reward=515.00 +/- 0.00
Episode length: 65.00 +/- 0.00
Eval num_timesteps=6816000, episode_reward=515.00 +/- 0.00
Episode length: 65.00 +/- 0.00
Eval num_timesteps=6840000, episode_reward=253.00 +/- 0.00
Episode length: 50.00 +/- 0.00
Eval num_timesteps=6864000, episode_reward=253.00 +/- 0.00
Episode length: 50.00 +/- 0.00
Eval num_timesteps=6888000, episode_reward=517.00 +/- 0.00
Episode length: 64.00 +/- 0.00
Eval num_timesteps=6912000, episode_reward=517.00 +/- 0.00
Episode length: 64.00 +/- 0.00
Eval num_timesteps=6936000, episode_reward=250.00 +/- 0.00
Episode length: 48.00 +/- 0.00
Eval num_timesteps=6960000, episode_reward=250.00 +/- 0.00
Episode length: 48.00 +/- 0.00
Eval num_timesteps=6984000, episode_reward=250.00 +/- 0.00
Episode length: 46.00 +/- 0.00
Eval num_timesteps=7008000, episode_reward=250.00 +/- 0.00
Episode length: 46.00 +/- 0.00
Eval num_timesteps=7032000, episode_reward=342.00 +/- 0.00
Episode length: 66.00 +/- 0.00
Eval num_timesteps=7056000, episode_reward=342.00 +/- 0.00
Episode length: 66.00 +/- 0.00
Eval num_timesteps=7080000, episode_reward=683.00 +/- 0.00
Episode length: 80.00 +/- 0.00
Eval num_timesteps=7104000, episode_reward=683.00 +/- 0.00
Episode length: 80.00 +/- 0.00
Eval num_timesteps=7128000, episode_reward=291.00 +/- 0.00
Episode length: 59.00 +/- 0.00
Eval num_timesteps=7152000, episode_reward=291.00 +/- 0.00
Episode length: 59.00 +/- 0.00
Eval num_timesteps=7176000, episode_reward=291.00 +/- 0.00
Episode length: 59.00 +/- 0.00
Eval num_timesteps=7200000, episode_reward=502.00 +/- 0.00
Episode length: 86.00 +/- 0.00
Eval num_timesteps=7224000, episode_reward=502.00 +/- 0.00
Episode length: 86.00 +/- 0.00
Eval num_timesteps=7248000, episode_reward=893.00 +/- 0.00
Episode length: 106.00 +/- 0.00
Eval num_timesteps=7272000, episode_reward=893.00 +/- 0.00
Episode length: 106.00 +/- 0.00
Eval num_timesteps=7296000, episode_reward=1038.00 +/- 0.00
Episode length: 128.00 +/- 0.00
Eval num_timesteps=7320000, episode_reward=1038.00 +/- 0.00
Episode length: 128.00 +/- 0.00
Eval num_timesteps=7344000, episode_reward=689.00 +/- 0.00
Episode length: 97.00 +/- 0.00
Eval num_timesteps=7368000, episode_reward=689.00 +/- 0.00
Episode length: 97.00 +/- 0.00
Eval num_timesteps=7392000, episode_reward=686.00 +/- 0.00
Episode length: 112.00 +/- 0.00
Eval num_timesteps=7416000, episode_reward=686.00 +/- 0.00
Episode length: 112.00 +/- 0.00
Eval num_timesteps=7440000, episode_reward=895.00 +/- 0.00
Episode length: 102.00 +/- 0.00
Eval num_timesteps=7464000, episode_reward=895.00 +/- 0.00
Episode length: 102.00 +/- 0.00
Eval num_timesteps=7488000, episode_reward=895.00 +/- 0.00
Episode length: 102.00 +/- 0.00
Eval num_timesteps=7512000, episode_reward=895.00 +/- 0.00
Episode length: 102.00 +/- 0.00
Eval num_timesteps=7536000, episode_reward=1267.00 +/- 0.00
Episode length: 141.00 +/- 0.00
Eval num_timesteps=7560000, episode_reward=1267.00 +/- 0.00
Episode length: 141.00 +/- 0.00
Eval num_timesteps=7584000, episode_reward=1271.00 +/- 0.00
Episode length: 135.00 +/- 0.00
Eval num_timesteps=7608000, episode_reward=1271.00 +/- 0.00
Episode length: 135.00 +/- 0.00
Eval num_timesteps=7632000, episode_reward=1269.00 +/- 0.00
Episode length: 140.00 +/- 0.00
Eval num_timesteps=7656000, episode_reward=1269.00 +/- 0.00
Episode length: 140.00 +/- 0.00
Eval num_timesteps=7680000, episode_reward=893.00 +/- 0.00
Episode length: 103.00 +/- 0.00
Eval num_timesteps=7704000, episode_reward=893.00 +/- 0.00
Episode length: 103.00 +/- 0.00
Eval num_timesteps=7728000, episode_reward=892.00 +/- 0.00
Episode length: 108.00 +/- 0.00
Eval num_timesteps=7752000, episode_reward=892.00 +/- 0.00
Episode length: 108.00 +/- 0.00
Eval num_timesteps=7776000, episode_reward=1270.00 +/- 0.00
Episode length: 135.00 +/- 0.00
Eval num_timesteps=7800000, episode_reward=1270.00 +/- 0.00
Episode length: 135.00 +/- 0.00
Eval num_timesteps=7824000, episode_reward=245.00 +/- 0.00
Episode length: 31.00 +/- 0.00
Eval num_timesteps=7848000, episode_reward=245.00 +/- 0.00
Episode length: 31.00 +/- 0.00
Eval num_timesteps=7872000, episode_reward=894.00 +/- 0.00
Episode length: 101.00 +/- 0.00
Eval num_timesteps=7896000, episode_reward=894.00 +/- 0.00
Episode length: 101.00 +/- 0.00
Eval num_timesteps=7920000, episode_reward=915.00 +/- 0.00
Episode length: 104.00 +/- 0.00
Eval num_timesteps=7944000, episode_reward=915.00 +/- 0.00
Episode length: 104.00 +/- 0.00
Eval num_timesteps=7968000, episode_reward=1251.00 +/- 0.00
Episode length: 181.00 +/- 0.00
Eval num_timesteps=7992000, episode_reward=1251.00 +/- 0.00
Episode length: 181.00 +/- 0.00
Eval num_timesteps=8016000, episode_reward=337.00 +/- 0.00
Episode length: 110.00 +/- 0.00
Eval num_timesteps=8040000, episode_reward=337.00 +/- 0.00
Episode length: 110.00 +/- 0.00
Eval num_timesteps=8064000, episode_reward=880.00 +/- 0.00
Episode length: 170.00 +/- 0.00
Eval num_timesteps=8088000, episode_reward=880.00 +/- 0.00
Episode length: 170.00 +/- 0.00
Eval num_timesteps=8112000, episode_reward=-162.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=8136000, episode_reward=-162.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=8160000, episode_reward=199.00 +/- 0.00
Episode length: 102.00 +/- 0.00
Eval num_timesteps=8184000, episode_reward=199.00 +/- 0.00
Episode length: 102.00 +/- 0.00
Eval num_timesteps=8208000, episode_reward=199.00 +/- 0.00
Episode length: 102.00 +/- 0.00
Eval num_timesteps=8232000, episode_reward=249.00 +/- 0.00
Episode length: 94.00 +/- 0.00
Eval num_timesteps=8256000, episode_reward=249.00 +/- 0.00
Episode length: 94.00 +/- 0.00
Eval num_timesteps=8280000, episode_reward=731.00 +/- 0.00
Episode length: 157.00 +/- 0.00
Eval num_timesteps=8304000, episode_reward=731.00 +/- 0.00
Episode length: 157.00 +/- 0.00
Eval num_timesteps=8328000, episode_reward=-124.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=8352000, episode_reward=-124.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=8376000, episode_reward=240.00 +/- 0.00
Episode length: 90.00 +/- 0.00
Eval num_timesteps=8400000, episode_reward=240.00 +/- 0.00
Episode length: 90.00 +/- 0.00
Eval num_timesteps=8424000, episode_reward=924.00 +/- 0.00
Episode length: 172.00 +/- 0.00
Eval num_timesteps=8448000, episode_reward=924.00 +/- 0.00
Episode length: 172.00 +/- 0.00
Eval num_timesteps=8472000, episode_reward=-115.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=8496000, episode_reward=-115.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=8520000, episode_reward=251.00 +/- 0.00
Episode length: 48.00 +/- 0.00
Eval num_timesteps=8544000, episode_reward=251.00 +/- 0.00
Episode length: 48.00 +/- 0.00
Eval num_timesteps=8568000, episode_reward=882.00 +/- 0.00
Episode length: 147.00 +/- 0.00
Eval num_timesteps=8592000, episode_reward=882.00 +/- 0.00
Episode length: 147.00 +/- 0.00
Eval num_timesteps=8616000, episode_reward=251.00 +/- 0.00
Episode length: 46.00 +/- 0.00
Eval num_timesteps=8640000, episode_reward=251.00 +/- 0.00
Episode length: 46.00 +/- 0.00
Eval num_timesteps=8664000, episode_reward=284.00 +/- 0.00
Episode length: 134.00 +/- 0.00
Eval num_timesteps=8688000, episode_reward=284.00 +/- 0.00
Episode length: 134.00 +/- 0.00
Eval num_timesteps=8712000, episode_reward=-104.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=8736000, episode_reward=-104.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=8760000, episode_reward=244.00 +/- 0.00
Episode length: 71.00 +/- 0.00
Eval num_timesteps=8784000, episode_reward=244.00 +/- 0.00
Episode length: 71.00 +/- 0.00
Eval num_timesteps=8808000, episode_reward=387.00 +/- 0.00
Episode length: 52.00 +/- 0.00
Eval num_timesteps=8832000, episode_reward=387.00 +/- 0.00
Episode length: 52.00 +/- 0.00
Eval num_timesteps=8856000, episode_reward=391.00 +/- 0.00
Episode length: 43.00 +/- 0.00
Eval num_timesteps=8880000, episode_reward=391.00 +/- 0.00
Episode length: 43.00 +/- 0.00
Eval num_timesteps=8904000, episode_reward=240.00 +/- 0.00
Episode length: 31.00 +/- 0.00
Eval num_timesteps=8928000, episode_reward=240.00 +/- 0.00
Episode length: 31.00 +/- 0.00
Eval num_timesteps=8952000, episode_reward=752.00 +/- 0.00
Episode length: 80.00 +/- 0.00
Eval num_timesteps=8976000, episode_reward=752.00 +/- 0.00
Episode length: 80.00 +/- 0.00
Eval num_timesteps=9000000, episode_reward=898.00 +/- 0.00
Episode length: 88.00 +/- 0.00
Eval num_timesteps=9024000, episode_reward=898.00 +/- 0.00
Episode length: 88.00 +/- 0.00
Eval num_timesteps=9048000, episode_reward=967.00 +/- 0.00
Episode length: 93.00 +/- 0.00
Eval num_timesteps=9072000, episode_reward=967.00 +/- 0.00
Episode length: 93.00 +/- 0.00
Eval num_timesteps=9096000, episode_reward=900.00 +/- 0.00
Episode length: 93.00 +/- 0.00
Eval num_timesteps=9120000, episode_reward=900.00 +/- 0.00
Episode length: 93.00 +/- 0.00
Eval num_timesteps=9144000, episode_reward=1406.00 +/- 0.00
Episode length: 138.00 +/- 0.00
Eval num_timesteps=9168000, episode_reward=1406.00 +/- 0.00
Episode length: 138.00 +/- 0.00
Eval num_timesteps=9192000, episode_reward=754.00 +/- 0.00
Episode length: 74.00 +/- 0.00
Eval num_timesteps=9216000, episode_reward=754.00 +/- 0.00
Episode length: 74.00 +/- 0.00
Eval num_timesteps=9240000, episode_reward=754.00 +/- 0.00
Episode length: 74.00 +/- 0.00
Eval num_timesteps=9264000, episode_reward=861.00 +/- 0.00
Episode length: 92.00 +/- 0.00
Eval num_timesteps=9288000, episode_reward=861.00 +/- 0.00
Episode length: 92.00 +/- 0.00
Eval num_timesteps=9312000, episode_reward=1260.00 +/- 0.00
Episode length: 150.00 +/- 0.00
Eval num_timesteps=9336000, episode_reward=1260.00 +/- 0.00
Episode length: 150.00 +/- 0.00
Eval num_timesteps=9360000, episode_reward=1289.00 +/- 0.00
Episode length: 130.00 +/- 0.00
Eval num_timesteps=9384000, episode_reward=1289.00 +/- 0.00
Episode length: 130.00 +/- 0.00
Eval num_timesteps=9408000, episode_reward=1337.00 +/- 0.00
Episode length: 147.00 +/- 0.00
Eval num_timesteps=9432000, episode_reward=1337.00 +/- 0.00
Episode length: 147.00 +/- 0.00
Eval num_timesteps=9456000, episode_reward=250.00 +/- 0.00
Episode length: 31.00 +/- 0.00
Eval num_timesteps=9480000, episode_reward=250.00 +/- 0.00
Episode length: 31.00 +/- 0.00
Eval num_timesteps=9504000, episode_reward=388.00 +/- 0.00
Episode length: 47.00 +/- 0.00
Eval num_timesteps=9528000, episode_reward=388.00 +/- 0.00
Episode length: 47.00 +/- 0.00
Eval num_timesteps=9552000, episode_reward=388.00 +/- 0.00
Episode length: 47.00 +/- 0.00
Eval num_timesteps=9576000, episode_reward=388.00 +/- 0.00
Episode length: 47.00 +/- 0.00
Eval num_timesteps=9600000, episode_reward=724.00 +/- 0.00
Episode length: 72.00 +/- 0.00
Eval num_timesteps=9624000, episode_reward=724.00 +/- 0.00
Episode length: 72.00 +/- 0.00
Eval num_timesteps=9648000, episode_reward=903.00 +/- 0.00
Episode length: 91.00 +/- 0.00
Eval num_timesteps=9672000, episode_reward=903.00 +/- 0.00
Episode length: 91.00 +/- 0.00
Eval num_timesteps=9696000, episode_reward=388.00 +/- 0.00
Episode length: 48.00 +/- 0.00
Eval num_timesteps=9720000, episode_reward=388.00 +/- 0.00
Episode length: 48.00 +/- 0.00
Eval num_timesteps=9744000, episode_reward=933.00 +/- 0.00
Episode length: 92.00 +/- 0.00
Eval num_timesteps=9768000, episode_reward=933.00 +/- 0.00
Episode length: 92.00 +/- 0.00
Eval num_timesteps=9792000, episode_reward=750.00 +/- 0.00
Episode length: 76.00 +/- 0.00
Eval num_timesteps=9816000, episode_reward=750.00 +/- 0.00
Episode length: 76.00 +/- 0.00
Eval num_timesteps=9840000, episode_reward=753.00 +/- 0.00
Episode length: 75.00 +/- 0.00
Eval num_timesteps=9864000, episode_reward=753.00 +/- 0.00
Episode length: 75.00 +/- 0.00
Eval num_timesteps=9888000, episode_reward=888.00 +/- 0.00
Episode length: 97.00 +/- 0.00
Eval num_timesteps=9912000, episode_reward=888.00 +/- 0.00
Episode length: 97.00 +/- 0.00
Eval num_timesteps=9936000, episode_reward=887.00 +/- 0.00
Episode length: 85.00 +/- 0.00
Eval num_timesteps=9960000, episode_reward=887.00 +/- 0.00
Episode length: 85.00 +/- 0.00
Eval num_timesteps=9984000, episode_reward=682.00 +/- 0.00
Episode length: 68.00 +/- 0.00
Eval num_timesteps=10008000, episode_reward=682.00 +/- 0.00
Episode length: 68.00 +/- 0.00
 100% ━━━━━━━━━━━━━━━━━━ 10,027,008/10,00… [ 1 day, 8:24:01 < 0:00:00 , ? it/s ]
