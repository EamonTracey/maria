/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/envs/registration.py:555: UserWarning: [33mWARN: The environment SuperMarioBros-4-1-v0 is out of date. You should consider upgrading to version `v3`.[0m
  logger.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/envs/registration.py:555: UserWarning: [33mWARN: The environment SuperMarioBros-4-1-v0 is out of date. You should consider upgrading to version `v3`.[0m
  logger.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/envs/registration.py:555: UserWarning: [33mWARN: The environment SuperMarioBros-4-1-v0 is out of date. You should consider upgrading to version `v3`.[0m
  logger.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/envs/registration.py:555: UserWarning: [33mWARN: The environment SuperMarioBros-4-1-v0 is out of date. You should consider upgrading to version `v3`.[0m
  logger.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/envs/registration.py:555: UserWarning: [33mWARN: The environment SuperMarioBros-4-1-v0 is out of date. You should consider upgrading to version `v3`.[0m
  logger.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/envs/registration.py:555: UserWarning: [33mWARN: The environment SuperMarioBros-4-1-v0 is out of date. You should consider upgrading to version `v3`.[0m
  logger.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/envs/registration.py:555: UserWarning: [33mWARN: The environment SuperMarioBros-4-1-v0 is out of date. You should consider upgrading to version `v3`.[0m
  logger.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/envs/registration.py:555: UserWarning: [33mWARN: The environment SuperMarioBros-4-1-v0 is out of date. You should consider upgrading to version `v3`.[0m
  logger.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/envs/registration.py:555: UserWarning: [33mWARN: The environment SuperMarioBros-4-1-v0 is out of date. You should consider upgrading to version `v3`.[0m
  logger.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/envs/registration.py:555: UserWarning: [33mWARN: The environment SuperMarioBros-4-1-v0 is out of date. You should consider upgrading to version `v3`.[0m
  logger.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/envs/registration.py:555: UserWarning: [33mWARN: The environment SuperMarioBros-4-1-v0 is out of date. You should consider upgrading to version `v3`.[0m
  logger.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/envs/registration.py:555: UserWarning: [33mWARN: The environment SuperMarioBros-4-1-v0 is out of date. You should consider upgrading to version `v3`.[0m
  logger.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/envs/registration.py:555: UserWarning: [33mWARN: The environment SuperMarioBros-4-1-v0 is out of date. You should consider upgrading to version `v3`.[0m
  logger.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/envs/registration.py:555: UserWarning: [33mWARN: The environment SuperMarioBros-4-1-v0 is out of date. You should consider upgrading to version `v3`.[0m
  logger.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/envs/registration.py:555: UserWarning: [33mWARN: The environment SuperMarioBros-4-1-v0 is out of date. You should consider upgrading to version `v3`.[0m
  logger.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/envs/registration.py:555: UserWarning: [33mWARN: The environment SuperMarioBros-4-1-v0 is out of date. You should consider upgrading to version `v3`.[0m
  logger.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/envs/registration.py:555: UserWarning: [33mWARN: The environment SuperMarioBros-4-1-v0 is out of date. You should consider upgrading to version `v3`.[0m
  logger.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/envs/registration.py:555: UserWarning: [33mWARN: The environment SuperMarioBros-4-1-v0 is out of date. You should consider upgrading to version `v3`.[0m
  logger.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/envs/registration.py:555: UserWarning: [33mWARN: The environment SuperMarioBros-4-1-v0 is out of date. You should consider upgrading to version `v3`.[0m
  logger.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/envs/registration.py:555: UserWarning: [33mWARN: The environment SuperMarioBros-4-1-v0 is out of date. You should consider upgrading to version `v3`.[0m
  logger.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/envs/registration.py:555: UserWarning: [33mWARN: The environment SuperMarioBros-4-1-v0 is out of date. You should consider upgrading to version `v3`.[0m
  logger.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/envs/registration.py:555: UserWarning: [33mWARN: The environment SuperMarioBros-4-1-v0 is out of date. You should consider upgrading to version `v3`.[0m
  logger.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/envs/registration.py:555: UserWarning: [33mWARN: The environment SuperMarioBros-4-1-v0 is out of date. You should consider upgrading to version `v3`.[0m
  logger.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/envs/registration.py:555: UserWarning: [33mWARN: The environment SuperMarioBros-4-1-v0 is out of date. You should consider upgrading to version `v3`.[0m
  logger.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.
  warnings.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.
  warnings.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.
  warnings.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.
  warnings.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.
  warnings.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.
  warnings.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.
  warnings.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.
  warnings.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.
  warnings.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.
  warnings.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.
  warnings.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.
  warnings.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.
  warnings.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.
  warnings.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.
  warnings.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.
  warnings.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.
  warnings.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.
  warnings.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.
  warnings.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.
  warnings.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.
  warnings.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.
  warnings.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.
  warnings.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.
  warnings.warn(
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/stable_baselines3/common/callbacks.py:403: UserWarning: Training and eval env are not of the same type<stable_baselines3.common.vec_env.vec_transpose.VecTransposeImage object at 0x145fd0e6b250> != <stable_baselines3.common.vec_env.vec_monitor.VecMonitor object at 0x145fd0e69a50>
  warnings.warn("Training and eval env are not of the same type" f"{self.training_env} != {self.eval_env}")
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(terminated, (bool, np.bool8)):
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(terminated, (bool, np.bool8)):
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(terminated, (bool, np.bool8)):
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(terminated, (bool, np.bool8)):
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(terminated, (bool, np.bool8)):
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(terminated, (bool, np.bool8)):
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(terminated, (bool, np.bool8)):
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(terminated, (bool, np.bool8)):
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(terminated, (bool, np.bool8)):
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(terminated, (bool, np.bool8)):
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(terminated, (bool, np.bool8)):
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(terminated, (bool, np.bool8)):
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(terminated, (bool, np.bool8)):
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(terminated, (bool, np.bool8)):
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(terminated, (bool, np.bool8)):
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(terminated, (bool, np.bool8)):
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(terminated, (bool, np.bool8)):
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(terminated, (bool, np.bool8)):
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(terminated, (bool, np.bool8)):
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(terminated, (bool, np.bool8)):
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(terminated, (bool, np.bool8)):
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(terminated, (bool, np.bool8)):
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(terminated, (bool, np.bool8)):
/afs/crc.nd.edu/user/e/etracey/ai/maria/venv/lib/python3.10/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)
  if not isinstance(terminated, (bool, np.bool8)):
Training model!
World: 4
Stage: 1
Vectors: 24
Steps: 10000000
Learning rate: 0.0003
Eval num_timesteps=24000, episode_reward=-240.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
New best mean reward!
Eval num_timesteps=48000, episode_reward=-240.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=72000, episode_reward=225.00 +/- 0.00
Episode length: 213.00 +/- 0.00
New best mean reward!
Eval num_timesteps=96000, episode_reward=225.00 +/- 0.00
Episode length: 213.00 +/- 0.00
Eval num_timesteps=120000, episode_reward=225.00 +/- 0.00
Episode length: 213.00 +/- 0.00
Eval num_timesteps=144000, episode_reward=225.00 +/- 0.00
Episode length: 213.00 +/- 0.00
Eval num_timesteps=168000, episode_reward=348.00 +/- 0.00
Episode length: 66.00 +/- 0.00
New best mean reward!
Eval num_timesteps=192000, episode_reward=348.00 +/- 0.00
Episode length: 66.00 +/- 0.00
Eval num_timesteps=216000, episode_reward=329.00 +/- 0.00
Episode length: 98.00 +/- 0.00
Eval num_timesteps=240000, episode_reward=329.00 +/- 0.00
Episode length: 98.00 +/- 0.00
Eval num_timesteps=264000, episode_reward=470.00 +/- 0.00
Episode length: 52.00 +/- 0.00
New best mean reward!
Eval num_timesteps=288000, episode_reward=470.00 +/- 0.00
Episode length: 52.00 +/- 0.00
Eval num_timesteps=312000, episode_reward=470.00 +/- 0.00
Episode length: 52.00 +/- 0.00
Eval num_timesteps=336000, episode_reward=470.00 +/- 0.00
Episode length: 52.00 +/- 0.00
Eval num_timesteps=360000, episode_reward=470.00 +/- 0.00
Episode length: 52.00 +/- 0.00
Eval num_timesteps=384000, episode_reward=470.00 +/- 0.00
Episode length: 52.00 +/- 0.00
Eval num_timesteps=408000, episode_reward=1989.00 +/- 0.00
Episode length: 275.00 +/- 0.00
New best mean reward!
Eval num_timesteps=432000, episode_reward=1989.00 +/- 0.00
Episode length: 275.00 +/- 0.00
Eval num_timesteps=456000, episode_reward=1227.00 +/- 0.00
Episode length: 113.00 +/- 0.00
Eval num_timesteps=480000, episode_reward=1227.00 +/- 0.00
Episode length: 113.00 +/- 0.00
Eval num_timesteps=504000, episode_reward=470.00 +/- 0.00
Episode length: 52.00 +/- 0.00
Eval num_timesteps=528000, episode_reward=470.00 +/- 0.00
Episode length: 52.00 +/- 0.00
Eval num_timesteps=552000, episode_reward=470.00 +/- 0.00
Episode length: 52.00 +/- 0.00
Eval num_timesteps=576000, episode_reward=470.00 +/- 0.00
Episode length: 52.00 +/- 0.00
Eval num_timesteps=600000, episode_reward=1227.00 +/- 0.00
Episode length: 113.00 +/- 0.00
Eval num_timesteps=624000, episode_reward=1227.00 +/- 0.00
Episode length: 113.00 +/- 0.00
Eval num_timesteps=648000, episode_reward=225.00 +/- 0.00
Episode length: 213.00 +/- 0.00
Eval num_timesteps=672000, episode_reward=225.00 +/- 0.00
Episode length: 213.00 +/- 0.00
Eval num_timesteps=696000, episode_reward=225.00 +/- 0.00
Episode length: 213.00 +/- 0.00
Eval num_timesteps=720000, episode_reward=225.00 +/- 0.00
Episode length: 213.00 +/- 0.00
Eval num_timesteps=744000, episode_reward=356.00 +/- 0.00
Episode length: 172.00 +/- 0.00
Eval num_timesteps=768000, episode_reward=356.00 +/- 0.00
Episode length: 172.00 +/- 0.00
Eval num_timesteps=792000, episode_reward=225.00 +/- 0.00
Episode length: 213.00 +/- 0.00
Eval num_timesteps=816000, episode_reward=225.00 +/- 0.00
Episode length: 213.00 +/- 0.00
Eval num_timesteps=840000, episode_reward=225.00 +/- 0.00
Episode length: 213.00 +/- 0.00
Eval num_timesteps=864000, episode_reward=225.00 +/- 0.00
Episode length: 213.00 +/- 0.00
Eval num_timesteps=888000, episode_reward=225.00 +/- 0.00
Episode length: 213.00 +/- 0.00
Eval num_timesteps=912000, episode_reward=225.00 +/- 0.00
Episode length: 213.00 +/- 0.00
Eval num_timesteps=936000, episode_reward=253.00 +/- 0.00
Episode length: 196.00 +/- 0.00
Eval num_timesteps=960000, episode_reward=253.00 +/- 0.00
Episode length: 196.00 +/- 0.00
Eval num_timesteps=984000, episode_reward=225.00 +/- 0.00
Episode length: 213.00 +/- 0.00
Eval num_timesteps=1008000, episode_reward=225.00 +/- 0.00
Episode length: 213.00 +/- 0.00
Eval num_timesteps=1032000, episode_reward=225.00 +/- 0.00
Episode length: 213.00 +/- 0.00
Eval num_timesteps=1056000, episode_reward=394.00 +/- 0.00
Episode length: 56.00 +/- 0.00
Eval num_timesteps=1080000, episode_reward=394.00 +/- 0.00
Episode length: 56.00 +/- 0.00
Eval num_timesteps=1104000, episode_reward=225.00 +/- 0.00
Episode length: 213.00 +/- 0.00
Eval num_timesteps=1128000, episode_reward=225.00 +/- 0.00
Episode length: 213.00 +/- 0.00
Eval num_timesteps=1152000, episode_reward=437.00 +/- 0.00
Episode length: 213.00 +/- 0.00
Eval num_timesteps=1176000, episode_reward=437.00 +/- 0.00
Episode length: 213.00 +/- 0.00
Eval num_timesteps=1200000, episode_reward=225.00 +/- 0.00
Episode length: 213.00 +/- 0.00
Eval num_timesteps=1224000, episode_reward=225.00 +/- 0.00
Episode length: 213.00 +/- 0.00
Eval num_timesteps=1248000, episode_reward=470.00 +/- 0.00
Episode length: 52.00 +/- 0.00
Eval num_timesteps=1272000, episode_reward=470.00 +/- 0.00
Episode length: 52.00 +/- 0.00
Eval num_timesteps=1296000, episode_reward=225.00 +/- 0.00
Episode length: 213.00 +/- 0.00
Eval num_timesteps=1320000, episode_reward=225.00 +/- 0.00
Episode length: 213.00 +/- 0.00
Eval num_timesteps=1344000, episode_reward=420.00 +/- 0.00
Episode length: 50.00 +/- 0.00
Eval num_timesteps=1368000, episode_reward=420.00 +/- 0.00
Episode length: 50.00 +/- 0.00
Eval num_timesteps=1392000, episode_reward=470.00 +/- 0.00
Episode length: 52.00 +/- 0.00
Eval num_timesteps=1416000, episode_reward=470.00 +/- 0.00
Episode length: 52.00 +/- 0.00
Eval num_timesteps=1440000, episode_reward=225.00 +/- 0.00
Episode length: 213.00 +/- 0.00
Eval num_timesteps=1464000, episode_reward=225.00 +/- 0.00
Episode length: 213.00 +/- 0.00
Eval num_timesteps=1488000, episode_reward=225.00 +/- 0.00
Episode length: 213.00 +/- 0.00
Eval num_timesteps=1512000, episode_reward=225.00 +/- 0.00
Episode length: 213.00 +/- 0.00
Eval num_timesteps=1536000, episode_reward=469.00 +/- 0.00
Episode length: 57.00 +/- 0.00
Eval num_timesteps=1560000, episode_reward=469.00 +/- 0.00
Episode length: 57.00 +/- 0.00
Eval num_timesteps=1584000, episode_reward=1227.00 +/- 0.00
Episode length: 113.00 +/- 0.00
Eval num_timesteps=1608000, episode_reward=1227.00 +/- 0.00
Episode length: 113.00 +/- 0.00
Eval num_timesteps=1632000, episode_reward=1227.00 +/- 0.00
Episode length: 113.00 +/- 0.00
Eval num_timesteps=1656000, episode_reward=1227.00 +/- 0.00
Episode length: 113.00 +/- 0.00
Eval num_timesteps=1680000, episode_reward=225.00 +/- 0.00
Episode length: 213.00 +/- 0.00
Eval num_timesteps=1704000, episode_reward=225.00 +/- 0.00
Episode length: 213.00 +/- 0.00
Eval num_timesteps=1728000, episode_reward=225.00 +/- 0.00
Episode length: 213.00 +/- 0.00
Eval num_timesteps=1752000, episode_reward=225.00 +/- 0.00
Episode length: 213.00 +/- 0.00
Eval num_timesteps=1776000, episode_reward=225.00 +/- 0.00
Episode length: 213.00 +/- 0.00
Eval num_timesteps=1800000, episode_reward=225.00 +/- 0.00
Episode length: 213.00 +/- 0.00
Eval num_timesteps=1824000, episode_reward=225.00 +/- 0.00
Episode length: 213.00 +/- 0.00
Eval num_timesteps=1848000, episode_reward=225.00 +/- 0.00
Episode length: 213.00 +/- 0.00
Eval num_timesteps=1872000, episode_reward=225.00 +/- 0.00
Episode length: 213.00 +/- 0.00
Eval num_timesteps=1896000, episode_reward=225.00 +/- 0.00
Episode length: 213.00 +/- 0.00
Eval num_timesteps=1920000, episode_reward=225.00 +/- 0.00
Episode length: 213.00 +/- 0.00
Eval num_timesteps=1944000, episode_reward=225.00 +/- 0.00
Episode length: 213.00 +/- 0.00
Eval num_timesteps=1968000, episode_reward=225.00 +/- 0.00
Episode length: 213.00 +/- 0.00
Eval num_timesteps=1992000, episode_reward=225.00 +/- 0.00
Episode length: 213.00 +/- 0.00
Eval num_timesteps=2016000, episode_reward=225.00 +/- 0.00
Episode length: 213.00 +/- 0.00
Eval num_timesteps=2040000, episode_reward=225.00 +/- 0.00
Episode length: 213.00 +/- 0.00
Eval num_timesteps=2064000, episode_reward=225.00 +/- 0.00
Episode length: 213.00 +/- 0.00
Eval num_timesteps=2088000, episode_reward=225.00 +/- 0.00
Episode length: 214.00 +/- 0.00
Eval num_timesteps=2112000, episode_reward=225.00 +/- 0.00
Episode length: 214.00 +/- 0.00
Eval num_timesteps=2136000, episode_reward=1194.00 +/- 0.00
Episode length: 267.00 +/- 0.00
Eval num_timesteps=2160000, episode_reward=1194.00 +/- 0.00
Episode length: 267.00 +/- 0.00
Eval num_timesteps=2184000, episode_reward=225.00 +/- 0.00
Episode length: 213.00 +/- 0.00
Eval num_timesteps=2208000, episode_reward=225.00 +/- 0.00
Episode length: 213.00 +/- 0.00
Eval num_timesteps=2232000, episode_reward=344.00 +/- 0.00
Episode length: 76.00 +/- 0.00
Eval num_timesteps=2256000, episode_reward=344.00 +/- 0.00
Episode length: 76.00 +/- 0.00
Eval num_timesteps=2280000, episode_reward=225.00 +/- 0.00
Episode length: 213.00 +/- 0.00
Eval num_timesteps=2304000, episode_reward=225.00 +/- 0.00
Episode length: 213.00 +/- 0.00
Eval num_timesteps=2328000, episode_reward=225.00 +/- 0.00
Episode length: 213.00 +/- 0.00
Eval num_timesteps=2352000, episode_reward=225.00 +/- 0.00
Episode length: 213.00 +/- 0.00
Eval num_timesteps=2376000, episode_reward=225.00 +/- 0.00
Episode length: 213.00 +/- 0.00
Eval num_timesteps=2400000, episode_reward=225.00 +/- 0.00
Episode length: 213.00 +/- 0.00
Eval num_timesteps=2424000, episode_reward=333.00 +/- 0.00
Episode length: 83.00 +/- 0.00
Eval num_timesteps=2448000, episode_reward=333.00 +/- 0.00
Episode length: 83.00 +/- 0.00
Eval num_timesteps=2472000, episode_reward=329.00 +/- 0.00
Episode length: 85.00 +/- 0.00
Eval num_timesteps=2496000, episode_reward=329.00 +/- 0.00
Episode length: 85.00 +/- 0.00
Eval num_timesteps=2520000, episode_reward=225.00 +/- 0.00
Episode length: 213.00 +/- 0.00
Eval num_timesteps=2544000, episode_reward=225.00 +/- 0.00
Episode length: 213.00 +/- 0.00
Eval num_timesteps=2568000, episode_reward=212.00 +/- 0.00
Episode length: 213.00 +/- 0.00
Eval num_timesteps=2592000, episode_reward=212.00 +/- 0.00
Episode length: 213.00 +/- 0.00
Eval num_timesteps=2616000, episode_reward=469.00 +/- 0.00
Episode length: 57.00 +/- 0.00
Eval num_timesteps=2640000, episode_reward=469.00 +/- 0.00
Episode length: 57.00 +/- 0.00
Eval num_timesteps=2664000, episode_reward=1231.00 +/- 0.00
Episode length: 125.00 +/- 0.00
Eval num_timesteps=2688000, episode_reward=1231.00 +/- 0.00
Episode length: 125.00 +/- 0.00
Eval num_timesteps=2712000, episode_reward=1531.00 +/- 0.00
Episode length: 243.00 +/- 0.00
Eval num_timesteps=2736000, episode_reward=1531.00 +/- 0.00
Episode length: 243.00 +/- 0.00
Eval num_timesteps=2760000, episode_reward=-95.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=2784000, episode_reward=-95.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=2808000, episode_reward=1224.00 +/- 0.00
Episode length: 113.00 +/- 0.00
Eval num_timesteps=2832000, episode_reward=1224.00 +/- 0.00
Episode length: 113.00 +/- 0.00
Eval num_timesteps=2856000, episode_reward=225.00 +/- 0.00
Episode length: 213.00 +/- 0.00
Eval num_timesteps=2880000, episode_reward=225.00 +/- 0.00
Episode length: 213.00 +/- 0.00
Eval num_timesteps=2904000, episode_reward=-113.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=2928000, episode_reward=-113.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=2952000, episode_reward=-240.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=2976000, episode_reward=-240.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=3000000, episode_reward=-240.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=3024000, episode_reward=-240.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=3048000, episode_reward=-240.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=3072000, episode_reward=-240.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=3096000, episode_reward=-240.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=3120000, episode_reward=-240.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=3144000, episode_reward=-240.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=3168000, episode_reward=-240.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=3192000, episode_reward=-240.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=3216000, episode_reward=-240.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=3240000, episode_reward=-240.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=3264000, episode_reward=-240.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=3288000, episode_reward=-240.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=3312000, episode_reward=-240.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=3336000, episode_reward=-240.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=3360000, episode_reward=-240.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=3384000, episode_reward=-240.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=3408000, episode_reward=-240.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=3432000, episode_reward=-240.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=3456000, episode_reward=-240.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=3480000, episode_reward=-240.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=3504000, episode_reward=-240.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=3528000, episode_reward=-240.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=3552000, episode_reward=-240.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=3576000, episode_reward=-240.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=3600000, episode_reward=-205.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=3624000, episode_reward=-205.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=3648000, episode_reward=-205.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=3672000, episode_reward=-205.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=3696000, episode_reward=-205.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=3720000, episode_reward=-205.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=3744000, episode_reward=-205.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=3768000, episode_reward=-205.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=3792000, episode_reward=-205.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=3816000, episode_reward=-205.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=3840000, episode_reward=-205.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=3864000, episode_reward=-205.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=3888000, episode_reward=-205.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=3912000, episode_reward=-205.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=3936000, episode_reward=-205.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=3960000, episode_reward=-205.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=3984000, episode_reward=-181.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=4008000, episode_reward=-181.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=4032000, episode_reward=-97.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=4056000, episode_reward=-97.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=4080000, episode_reward=303.00 +/- 0.00
Episode length: 209.00 +/- 0.00
Eval num_timesteps=4104000, episode_reward=303.00 +/- 0.00
Episode length: 209.00 +/- 0.00
Eval num_timesteps=4128000, episode_reward=303.00 +/- 0.00
Episode length: 209.00 +/- 0.00
Eval num_timesteps=4152000, episode_reward=261.00 +/- 0.00
Episode length: 141.00 +/- 0.00
Eval num_timesteps=4176000, episode_reward=261.00 +/- 0.00
Episode length: 141.00 +/- 0.00
Eval num_timesteps=4200000, episode_reward=303.00 +/- 0.00
Episode length: 837.00 +/- 0.00
Eval num_timesteps=4224000, episode_reward=303.00 +/- 0.00
Episode length: 837.00 +/- 0.00
Eval num_timesteps=4248000, episode_reward=371.00 +/- 0.00
Episode length: 160.00 +/- 0.00
Eval num_timesteps=4272000, episode_reward=371.00 +/- 0.00
Episode length: 160.00 +/- 0.00
Eval num_timesteps=4296000, episode_reward=399.00 +/- 0.00
Episode length: 70.00 +/- 0.00
Eval num_timesteps=4320000, episode_reward=399.00 +/- 0.00
Episode length: 70.00 +/- 0.00
Eval num_timesteps=4344000, episode_reward=472.00 +/- 0.00
Episode length: 71.00 +/- 0.00
Eval num_timesteps=4368000, episode_reward=472.00 +/- 0.00
Episode length: 71.00 +/- 0.00
Eval num_timesteps=4392000, episode_reward=458.00 +/- 0.00
Episode length: 90.00 +/- 0.00
Eval num_timesteps=4416000, episode_reward=458.00 +/- 0.00
Episode length: 90.00 +/- 0.00
Eval num_timesteps=4440000, episode_reward=458.00 +/- 0.00
Episode length: 95.00 +/- 0.00
Eval num_timesteps=4464000, episode_reward=458.00 +/- 0.00
Episode length: 95.00 +/- 0.00
Eval num_timesteps=4488000, episode_reward=1201.00 +/- 0.00
Episode length: 121.00 +/- 0.00
Eval num_timesteps=4512000, episode_reward=1201.00 +/- 0.00
Episode length: 121.00 +/- 0.00
Eval num_timesteps=4536000, episode_reward=1623.00 +/- 0.00
Episode length: 290.00 +/- 0.00
Eval num_timesteps=4560000, episode_reward=1623.00 +/- 0.00
Episode length: 290.00 +/- 0.00
Eval num_timesteps=4584000, episode_reward=1225.00 +/- 0.00
Episode length: 117.00 +/- 0.00
Eval num_timesteps=4608000, episode_reward=1225.00 +/- 0.00
Episode length: 117.00 +/- 0.00
Eval num_timesteps=4632000, episode_reward=1284.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=4656000, episode_reward=1284.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=4680000, episode_reward=1372.00 +/- 0.00
Episode length: 171.00 +/- 0.00
Eval num_timesteps=4704000, episode_reward=1372.00 +/- 0.00
Episode length: 171.00 +/- 0.00
Eval num_timesteps=4728000, episode_reward=1356.00 +/- 0.00
Episode length: 162.00 +/- 0.00
Eval num_timesteps=4752000, episode_reward=1356.00 +/- 0.00
Episode length: 162.00 +/- 0.00
Eval num_timesteps=4776000, episode_reward=954.00 +/- 0.00
Episode length: 133.00 +/- 0.00
Eval num_timesteps=4800000, episode_reward=954.00 +/- 0.00
Episode length: 133.00 +/- 0.00
Eval num_timesteps=4824000, episode_reward=1020.00 +/- 0.00
Episode length: 227.00 +/- 0.00
Eval num_timesteps=4848000, episode_reward=1020.00 +/- 0.00
Episode length: 227.00 +/- 0.00
Eval num_timesteps=4872000, episode_reward=965.00 +/- 0.00
Episode length: 139.00 +/- 0.00
Eval num_timesteps=4896000, episode_reward=965.00 +/- 0.00
Episode length: 139.00 +/- 0.00
Eval num_timesteps=4920000, episode_reward=985.00 +/- 0.00
Episode length: 194.00 +/- 0.00
Eval num_timesteps=4944000, episode_reward=985.00 +/- 0.00
Episode length: 194.00 +/- 0.00
Eval num_timesteps=4968000, episode_reward=1192.00 +/- 0.00
Episode length: 121.00 +/- 0.00
Eval num_timesteps=4992000, episode_reward=1192.00 +/- 0.00
Episode length: 121.00 +/- 0.00
Eval num_timesteps=5016000, episode_reward=225.00 +/- 0.00
Episode length: 213.00 +/- 0.00
Eval num_timesteps=5040000, episode_reward=225.00 +/- 0.00
Episode length: 213.00 +/- 0.00
Eval num_timesteps=5064000, episode_reward=223.00 +/- 0.00
Episode length: 221.00 +/- 0.00
Eval num_timesteps=5088000, episode_reward=223.00 +/- 0.00
Episode length: 221.00 +/- 0.00
Eval num_timesteps=5112000, episode_reward=225.00 +/- 0.00
Episode length: 213.00 +/- 0.00
Eval num_timesteps=5136000, episode_reward=225.00 +/- 0.00
Episode length: 213.00 +/- 0.00
Eval num_timesteps=5160000, episode_reward=225.00 +/- 0.00
Episode length: 213.00 +/- 0.00
Eval num_timesteps=5184000, episode_reward=439.00 +/- 0.00
Episode length: 214.00 +/- 0.00
Eval num_timesteps=5208000, episode_reward=439.00 +/- 0.00
Episode length: 214.00 +/- 0.00
Eval num_timesteps=5232000, episode_reward=307.00 +/- 0.00
Episode length: 122.00 +/- 0.00
Eval num_timesteps=5256000, episode_reward=307.00 +/- 0.00
Episode length: 122.00 +/- 0.00
Eval num_timesteps=5280000, episode_reward=440.00 +/- 0.00
Episode length: 210.00 +/- 0.00
Eval num_timesteps=5304000, episode_reward=440.00 +/- 0.00
Episode length: 210.00 +/- 0.00
Eval num_timesteps=5328000, episode_reward=372.00 +/- 0.00
Episode length: 178.00 +/- 0.00
Eval num_timesteps=5352000, episode_reward=372.00 +/- 0.00
Episode length: 178.00 +/- 0.00
Eval num_timesteps=5376000, episode_reward=225.00 +/- 0.00
Episode length: 213.00 +/- 0.00
Eval num_timesteps=5400000, episode_reward=225.00 +/- 0.00
Episode length: 213.00 +/- 0.00
Eval num_timesteps=5424000, episode_reward=225.00 +/- 0.00
Episode length: 213.00 +/- 0.00
Eval num_timesteps=5448000, episode_reward=225.00 +/- 0.00
Episode length: 213.00 +/- 0.00
Eval num_timesteps=5472000, episode_reward=1227.00 +/- 0.00
Episode length: 126.00 +/- 0.00
Eval num_timesteps=5496000, episode_reward=1227.00 +/- 0.00
Episode length: 126.00 +/- 0.00
Eval num_timesteps=5520000, episode_reward=225.00 +/- 0.00
Episode length: 213.00 +/- 0.00
Eval num_timesteps=5544000, episode_reward=225.00 +/- 0.00
Episode length: 213.00 +/- 0.00
Eval num_timesteps=5568000, episode_reward=381.00 +/- 0.00
Episode length: 71.00 +/- 0.00
Eval num_timesteps=5592000, episode_reward=381.00 +/- 0.00
Episode length: 71.00 +/- 0.00
Eval num_timesteps=5616000, episode_reward=223.00 +/- 0.00
Episode length: 220.00 +/- 0.00
Eval num_timesteps=5640000, episode_reward=223.00 +/- 0.00
Episode length: 220.00 +/- 0.00
Eval num_timesteps=5664000, episode_reward=1226.00 +/- 0.00
Episode length: 118.00 +/- 0.00
Eval num_timesteps=5688000, episode_reward=1226.00 +/- 0.00
Episode length: 118.00 +/- 0.00
Eval num_timesteps=5712000, episode_reward=461.00 +/- 0.00
Episode length: 56.00 +/- 0.00
Eval num_timesteps=5736000, episode_reward=461.00 +/- 0.00
Episode length: 56.00 +/- 0.00
Eval num_timesteps=5760000, episode_reward=225.00 +/- 0.00
Episode length: 213.00 +/- 0.00
Eval num_timesteps=5784000, episode_reward=225.00 +/- 0.00
Episode length: 213.00 +/- 0.00
Eval num_timesteps=5808000, episode_reward=225.00 +/- 0.00
Episode length: 213.00 +/- 0.00
Eval num_timesteps=5832000, episode_reward=225.00 +/- 0.00
Episode length: 213.00 +/- 0.00
Eval num_timesteps=5856000, episode_reward=225.00 +/- 0.00
Episode length: 213.00 +/- 0.00
Eval num_timesteps=5880000, episode_reward=225.00 +/- 0.00
Episode length: 213.00 +/- 0.00
Eval num_timesteps=5904000, episode_reward=225.00 +/- 0.00
Episode length: 213.00 +/- 0.00
Eval num_timesteps=5928000, episode_reward=225.00 +/- 0.00
Episode length: 213.00 +/- 0.00
Eval num_timesteps=5952000, episode_reward=225.00 +/- 0.00
Episode length: 213.00 +/- 0.00
Eval num_timesteps=5976000, episode_reward=225.00 +/- 0.00
Episode length: 213.00 +/- 0.00
Eval num_timesteps=6000000, episode_reward=225.00 +/- 0.00
Episode length: 213.00 +/- 0.00
Eval num_timesteps=6024000, episode_reward=225.00 +/- 0.00
Episode length: 213.00 +/- 0.00
Eval num_timesteps=6048000, episode_reward=225.00 +/- 0.00
Episode length: 213.00 +/- 0.00
Eval num_timesteps=6072000, episode_reward=225.00 +/- 0.00
Episode length: 213.00 +/- 0.00
Eval num_timesteps=6096000, episode_reward=225.00 +/- 0.00
Episode length: 213.00 +/- 0.00
Eval num_timesteps=6120000, episode_reward=225.00 +/- 0.00
Episode length: 213.00 +/- 0.00
Eval num_timesteps=6144000, episode_reward=225.00 +/- 0.00
Episode length: 213.00 +/- 0.00
Eval num_timesteps=6168000, episode_reward=1222.00 +/- 0.00
Episode length: 136.00 +/- 0.00
Eval num_timesteps=6192000, episode_reward=1222.00 +/- 0.00
Episode length: 136.00 +/- 0.00
Eval num_timesteps=6216000, episode_reward=1225.00 +/- 0.00
Episode length: 123.00 +/- 0.00
Eval num_timesteps=6240000, episode_reward=1225.00 +/- 0.00
Episode length: 123.00 +/- 0.00
Eval num_timesteps=6264000, episode_reward=1024.00 +/- 0.00
Episode length: 187.00 +/- 0.00
Eval num_timesteps=6288000, episode_reward=1024.00 +/- 0.00
Episode length: 187.00 +/- 0.00
Eval num_timesteps=6312000, episode_reward=1216.00 +/- 0.00
Episode length: 127.00 +/- 0.00
Eval num_timesteps=6336000, episode_reward=1216.00 +/- 0.00
Episode length: 127.00 +/- 0.00
Eval num_timesteps=6360000, episode_reward=982.00 +/- 0.00
Episode length: 198.00 +/- 0.00
Eval num_timesteps=6384000, episode_reward=982.00 +/- 0.00
Episode length: 198.00 +/- 0.00
Eval num_timesteps=6408000, episode_reward=1015.00 +/- 0.00
Episode length: 191.00 +/- 0.00
Eval num_timesteps=6432000, episode_reward=1015.00 +/- 0.00
Episode length: 191.00 +/- 0.00
Eval num_timesteps=6456000, episode_reward=1071.00 +/- 0.00
Episode length: 166.00 +/- 0.00
Eval num_timesteps=6480000, episode_reward=1071.00 +/- 0.00
Episode length: 166.00 +/- 0.00
Eval num_timesteps=6504000, episode_reward=989.00 +/- 0.00
Episode length: 194.00 +/- 0.00
Eval num_timesteps=6528000, episode_reward=989.00 +/- 0.00
Episode length: 194.00 +/- 0.00
Eval num_timesteps=6552000, episode_reward=1432.00 +/- 0.00
Episode length: 298.00 +/- 0.00
Eval num_timesteps=6576000, episode_reward=1432.00 +/- 0.00
Episode length: 298.00 +/- 0.00
Eval num_timesteps=6600000, episode_reward=1737.00 +/- 0.00
Episode length: 252.00 +/- 0.00
Eval num_timesteps=6624000, episode_reward=1737.00 +/- 0.00
Episode length: 252.00 +/- 0.00
Eval num_timesteps=6648000, episode_reward=1493.00 +/- 0.00
Episode length: 187.00 +/- 0.00
Eval num_timesteps=6672000, episode_reward=1493.00 +/- 0.00
Episode length: 187.00 +/- 0.00
Eval num_timesteps=6696000, episode_reward=1225.00 +/- 0.00
Episode length: 122.00 +/- 0.00
Eval num_timesteps=6720000, episode_reward=1225.00 +/- 0.00
Episode length: 122.00 +/- 0.00
Eval num_timesteps=6744000, episode_reward=1225.00 +/- 0.00
Episode length: 122.00 +/- 0.00
Eval num_timesteps=6768000, episode_reward=1225.00 +/- 0.00
Episode length: 122.00 +/- 0.00
Eval num_timesteps=6792000, episode_reward=1225.00 +/- 0.00
Episode length: 122.00 +/- 0.00
Eval num_timesteps=6816000, episode_reward=1225.00 +/- 0.00
Episode length: 122.00 +/- 0.00
Eval num_timesteps=6840000, episode_reward=470.00 +/- 0.00
Episode length: 63.00 +/- 0.00
Eval num_timesteps=6864000, episode_reward=470.00 +/- 0.00
Episode length: 63.00 +/- 0.00
Eval num_timesteps=6888000, episode_reward=225.00 +/- 0.00
Episode length: 213.00 +/- 0.00
Eval num_timesteps=6912000, episode_reward=225.00 +/- 0.00
Episode length: 213.00 +/- 0.00
Eval num_timesteps=6936000, episode_reward=225.00 +/- 0.00
Episode length: 213.00 +/- 0.00
Eval num_timesteps=6960000, episode_reward=225.00 +/- 0.00
Episode length: 213.00 +/- 0.00
Eval num_timesteps=6984000, episode_reward=-200.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=7008000, episode_reward=-200.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=7032000, episode_reward=-200.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=7056000, episode_reward=-200.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=7080000, episode_reward=-200.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=7104000, episode_reward=-200.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=7128000, episode_reward=302.00 +/- 0.00
Episode length: 560.00 +/- 0.00
Eval num_timesteps=7152000, episode_reward=302.00 +/- 0.00
Episode length: 560.00 +/- 0.00
Eval num_timesteps=7176000, episode_reward=302.00 +/- 0.00
Episode length: 560.00 +/- 0.00
Eval num_timesteps=7200000, episode_reward=285.00 +/- 0.00
Episode length: 651.00 +/- 0.00
Eval num_timesteps=7224000, episode_reward=285.00 +/- 0.00
Episode length: 651.00 +/- 0.00
Eval num_timesteps=7248000, episode_reward=389.00 +/- 0.00
Episode length: 118.00 +/- 0.00
Eval num_timesteps=7272000, episode_reward=389.00 +/- 0.00
Episode length: 118.00 +/- 0.00
Eval num_timesteps=7296000, episode_reward=1224.00 +/- 0.00
Episode length: 129.00 +/- 0.00
Eval num_timesteps=7320000, episode_reward=1224.00 +/- 0.00
Episode length: 129.00 +/- 0.00
Eval num_timesteps=7344000, episode_reward=470.00 +/- 0.00
Episode length: 53.00 +/- 0.00
Eval num_timesteps=7368000, episode_reward=470.00 +/- 0.00
Episode length: 53.00 +/- 0.00
Eval num_timesteps=7392000, episode_reward=487.00 +/- 0.00
Episode length: 70.00 +/- 0.00
Eval num_timesteps=7416000, episode_reward=487.00 +/- 0.00
Episode length: 70.00 +/- 0.00
Eval num_timesteps=7440000, episode_reward=398.00 +/- 0.00
Episode length: 55.00 +/- 0.00
Eval num_timesteps=7464000, episode_reward=398.00 +/- 0.00
Episode length: 55.00 +/- 0.00
Eval num_timesteps=7488000, episode_reward=404.00 +/- 0.00
Episode length: 49.00 +/- 0.00
Eval num_timesteps=7512000, episode_reward=404.00 +/- 0.00
Episode length: 49.00 +/- 0.00
Eval num_timesteps=7536000, episode_reward=1225.00 +/- 0.00
Episode length: 124.00 +/- 0.00
Eval num_timesteps=7560000, episode_reward=1225.00 +/- 0.00
Episode length: 124.00 +/- 0.00
Eval num_timesteps=7584000, episode_reward=1220.00 +/- 0.00
Episode length: 135.00 +/- 0.00
Eval num_timesteps=7608000, episode_reward=1220.00 +/- 0.00
Episode length: 135.00 +/- 0.00
Eval num_timesteps=7632000, episode_reward=1225.00 +/- 0.00
Episode length: 131.00 +/- 0.00
Eval num_timesteps=7656000, episode_reward=1225.00 +/- 0.00
Episode length: 131.00 +/- 0.00
Eval num_timesteps=7680000, episode_reward=463.00 +/- 0.00
Episode length: 88.00 +/- 0.00
Eval num_timesteps=7704000, episode_reward=463.00 +/- 0.00
Episode length: 88.00 +/- 0.00
Eval num_timesteps=7728000, episode_reward=351.00 +/- 0.00
Episode length: 76.00 +/- 0.00
Eval num_timesteps=7752000, episode_reward=351.00 +/- 0.00
Episode length: 76.00 +/- 0.00
Eval num_timesteps=7776000, episode_reward=444.00 +/- 0.00
Episode length: 184.00 +/- 0.00
Eval num_timesteps=7800000, episode_reward=444.00 +/- 0.00
Episode length: 184.00 +/- 0.00
Eval num_timesteps=7824000, episode_reward=272.00 +/- 0.00
Episode length: 74.00 +/- 0.00
Eval num_timesteps=7848000, episode_reward=272.00 +/- 0.00
Episode length: 74.00 +/- 0.00
Eval num_timesteps=7872000, episode_reward=176.00 +/- 0.00
Episode length: 459.00 +/- 0.00
Eval num_timesteps=7896000, episode_reward=176.00 +/- 0.00
Episode length: 459.00 +/- 0.00
Eval num_timesteps=7920000, episode_reward=232.00 +/- 0.00
Episode length: 179.00 +/- 0.00
Eval num_timesteps=7944000, episode_reward=232.00 +/- 0.00
Episode length: 179.00 +/- 0.00
Eval num_timesteps=7968000, episode_reward=-200.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=7992000, episode_reward=-200.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=8016000, episode_reward=-200.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=8040000, episode_reward=-200.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=8064000, episode_reward=1096.00 +/- 0.00
Episode length: 755.00 +/- 0.00
Eval num_timesteps=8088000, episode_reward=1096.00 +/- 0.00
Episode length: 755.00 +/- 0.00
Eval num_timesteps=8112000, episode_reward=311.00 +/- 0.00
Episode length: 488.00 +/- 0.00
Eval num_timesteps=8136000, episode_reward=311.00 +/- 0.00
Episode length: 488.00 +/- 0.00
Eval num_timesteps=8160000, episode_reward=228.00 +/- 0.00
Episode length: 298.00 +/- 0.00
Eval num_timesteps=8184000, episode_reward=228.00 +/- 0.00
Episode length: 298.00 +/- 0.00
Eval num_timesteps=8208000, episode_reward=228.00 +/- 0.00
Episode length: 298.00 +/- 0.00
Eval num_timesteps=8232000, episode_reward=-200.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=8256000, episode_reward=-200.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=8280000, episode_reward=344.00 +/- 0.00
Episode length: 313.00 +/- 0.00
Eval num_timesteps=8304000, episode_reward=344.00 +/- 0.00
Episode length: 313.00 +/- 0.00
Eval num_timesteps=8328000, episode_reward=334.00 +/- 0.00
Episode length: 319.00 +/- 0.00
Eval num_timesteps=8352000, episode_reward=334.00 +/- 0.00
Episode length: 319.00 +/- 0.00
Eval num_timesteps=8376000, episode_reward=232.00 +/- 0.00
Episode length: 296.00 +/- 0.00
Eval num_timesteps=8400000, episode_reward=232.00 +/- 0.00
Episode length: 296.00 +/- 0.00
Eval num_timesteps=8424000, episode_reward=414.00 +/- 0.00
Episode length: 306.00 +/- 0.00
Eval num_timesteps=8448000, episode_reward=414.00 +/- 0.00
Episode length: 306.00 +/- 0.00
Eval num_timesteps=8472000, episode_reward=287.00 +/- 0.00
Episode length: 692.00 +/- 0.00
Eval num_timesteps=8496000, episode_reward=287.00 +/- 0.00
Episode length: 692.00 +/- 0.00
Eval num_timesteps=8520000, episode_reward=13.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=8544000, episode_reward=13.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=8568000, episode_reward=177.00 +/- 0.00
Episode length: 548.00 +/- 0.00
Eval num_timesteps=8592000, episode_reward=177.00 +/- 0.00
Episode length: 548.00 +/- 0.00
Eval num_timesteps=8616000, episode_reward=239.00 +/- 0.00
Episode length: 290.00 +/- 0.00
Eval num_timesteps=8640000, episode_reward=239.00 +/- 0.00
Episode length: 290.00 +/- 0.00
Eval num_timesteps=8664000, episode_reward=335.00 +/- 0.00
Episode length: 410.00 +/- 0.00
Eval num_timesteps=8688000, episode_reward=335.00 +/- 0.00
Episode length: 410.00 +/- 0.00
Eval num_timesteps=8712000, episode_reward=171.00 +/- 0.00
Episode length: 482.00 +/- 0.00
Eval num_timesteps=8736000, episode_reward=171.00 +/- 0.00
Episode length: 482.00 +/- 0.00
Eval num_timesteps=8760000, episode_reward=309.00 +/- 0.00
Episode length: 439.00 +/- 0.00
Eval num_timesteps=8784000, episode_reward=309.00 +/- 0.00
Episode length: 439.00 +/- 0.00
Eval num_timesteps=8808000, episode_reward=227.00 +/- 0.00
Episode length: 296.00 +/- 0.00
Eval num_timesteps=8832000, episode_reward=227.00 +/- 0.00
Episode length: 296.00 +/- 0.00
Eval num_timesteps=8856000, episode_reward=353.00 +/- 0.00
Episode length: 296.00 +/- 0.00
Eval num_timesteps=8880000, episode_reward=353.00 +/- 0.00
Episode length: 296.00 +/- 0.00
Eval num_timesteps=8904000, episode_reward=222.00 +/- 0.00
Episode length: 288.00 +/- 0.00
Eval num_timesteps=8928000, episode_reward=222.00 +/- 0.00
Episode length: 288.00 +/- 0.00
Eval num_timesteps=8952000, episode_reward=408.00 +/- 0.00
Episode length: 305.00 +/- 0.00
Eval num_timesteps=8976000, episode_reward=408.00 +/- 0.00
Episode length: 305.00 +/- 0.00
Eval num_timesteps=9000000, episode_reward=177.00 +/- 0.00
Episode length: 454.00 +/- 0.00
Eval num_timesteps=9024000, episode_reward=177.00 +/- 0.00
Episode length: 454.00 +/- 0.00
Eval num_timesteps=9048000, episode_reward=20.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=9072000, episode_reward=20.00 +/- 0.00
Episode length: 1000.00 +/- 0.00
Eval num_timesteps=9096000, episode_reward=178.00 +/- 0.00
Episode length: 448.00 +/- 0.00
Eval num_timesteps=9120000, episode_reward=178.00 +/- 0.00
Episode length: 448.00 +/- 0.00
Eval num_timesteps=9144000, episode_reward=90.00 +/- 0.00
Episode length: 889.00 +/- 0.00
Eval num_timesteps=9168000, episode_reward=90.00 +/- 0.00
Episode length: 889.00 +/- 0.00
Eval num_timesteps=9192000, episode_reward=352.00 +/- 0.00
Episode length: 209.00 +/- 0.00
Eval num_timesteps=9216000, episode_reward=352.00 +/- 0.00
Episode length: 209.00 +/- 0.00
Eval num_timesteps=9240000, episode_reward=352.00 +/- 0.00
Episode length: 209.00 +/- 0.00
Eval num_timesteps=9264000, episode_reward=113.00 +/- 0.00
Episode length: 772.00 +/- 0.00
Eval num_timesteps=9288000, episode_reward=113.00 +/- 0.00
Episode length: 772.00 +/- 0.00
Eval num_timesteps=9312000, episode_reward=222.00 +/- 0.00
Episode length: 228.00 +/- 0.00
Eval num_timesteps=9336000, episode_reward=222.00 +/- 0.00
Episode length: 228.00 +/- 0.00
Eval num_timesteps=9360000, episode_reward=139.00 +/- 0.00
Episode length: 641.00 +/- 0.00
Eval num_timesteps=9384000, episode_reward=139.00 +/- 0.00
Episode length: 641.00 +/- 0.00
Eval num_timesteps=9408000, episode_reward=223.00 +/- 0.00
Episode length: 224.00 +/- 0.00
Eval num_timesteps=9432000, episode_reward=223.00 +/- 0.00
Episode length: 224.00 +/- 0.00
Eval num_timesteps=9456000, episode_reward=1535.00 +/- 0.00
Episode length: 223.00 +/- 0.00
Eval num_timesteps=9480000, episode_reward=1535.00 +/- 0.00
Episode length: 223.00 +/- 0.00
Eval num_timesteps=9504000, episode_reward=222.00 +/- 0.00
Episode length: 226.00 +/- 0.00
Eval num_timesteps=9528000, episode_reward=222.00 +/- 0.00
Episode length: 226.00 +/- 0.00
Eval num_timesteps=9552000, episode_reward=400.00 +/- 0.00
Episode length: 64.00 +/- 0.00
Eval num_timesteps=9576000, episode_reward=400.00 +/- 0.00
Episode length: 64.00 +/- 0.00
Eval num_timesteps=9600000, episode_reward=466.00 +/- 0.00
Episode length: 61.00 +/- 0.00
Eval num_timesteps=9624000, episode_reward=466.00 +/- 0.00
Episode length: 61.00 +/- 0.00
Eval num_timesteps=9648000, episode_reward=470.00 +/- 0.00
Episode length: 60.00 +/- 0.00
Eval num_timesteps=9672000, episode_reward=470.00 +/- 0.00
Episode length: 60.00 +/- 0.00
Eval num_timesteps=9696000, episode_reward=224.00 +/- 0.00
Episode length: 217.00 +/- 0.00
Eval num_timesteps=9720000, episode_reward=224.00 +/- 0.00
Episode length: 217.00 +/- 0.00
Eval num_timesteps=9744000, episode_reward=208.00 +/- 0.00
Episode length: 296.00 +/- 0.00
Eval num_timesteps=9768000, episode_reward=208.00 +/- 0.00
Episode length: 296.00 +/- 0.00
Eval num_timesteps=9792000, episode_reward=221.00 +/- 0.00
Episode length: 232.00 +/- 0.00
Eval num_timesteps=9816000, episode_reward=221.00 +/- 0.00
Episode length: 232.00 +/- 0.00
Eval num_timesteps=9840000, episode_reward=233.00 +/- 0.00
Episode length: 171.00 +/- 0.00
Eval num_timesteps=9864000, episode_reward=233.00 +/- 0.00
Episode length: 171.00 +/- 0.00
Eval num_timesteps=9888000, episode_reward=224.00 +/- 0.00
Episode length: 216.00 +/- 0.00
Eval num_timesteps=9912000, episode_reward=224.00 +/- 0.00
Episode length: 216.00 +/- 0.00
Eval num_timesteps=9936000, episode_reward=471.00 +/- 0.00
Episode length: 55.00 +/- 0.00
Eval num_timesteps=9960000, episode_reward=471.00 +/- 0.00
Episode length: 55.00 +/- 0.00
Eval num_timesteps=9984000, episode_reward=224.00 +/- 0.00
Episode length: 216.00 +/- 0.00
Eval num_timesteps=10008000, episode_reward=224.00 +/- 0.00
Episode length: 216.00 +/- 0.00
 100% ━━━━━━━━━━━━━━━━━━ 10,027,008/10,00… [ 1 day, 8:05:04 < 0:00:00 , ? it/s ]
